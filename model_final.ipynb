{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show nvidia card info\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import zipfile\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collecting and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alinezhad.f'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### downloading the data (should only need to do this once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(\"data_project/\", exist_ok=True)\n",
    "# url = \"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/STMVL-Release.zip\"\n",
    "# urlData = requests.get(url).content\n",
    "# filename = \"data_project/STMVL-Release.zip\"\n",
    "# with open(filename, mode=\"wb\") as f:\n",
    "#     f.write(urlData)\n",
    "# with zipfile.ZipFile(filename) as z:\n",
    "#     z.extractall(\"data_project/pm25\")\n",
    "        \n",
    "def create_normalizer_pm25():\n",
    "    df = pd.read_csv(\n",
    "        \"/home/alinezhad.f/data_project/pm25/STMVL-Release/Code/STMVL/SampleData/pm25_ground.txt\",\n",
    "        index_col=\"datetime\",\n",
    "        parse_dates=True,\n",
    "    )\n",
    "    test_month = [3, 6, 9, 12]\n",
    "    for i in test_month:\n",
    "        df = df[df.index.month != i]\n",
    "    mean = df.describe().loc[\"mean\"].values\n",
    "    std = df.describe().loc[\"std\"].values\n",
    "    path = \"./data_project/pm25/pm25_meanstd.pk\"\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump([mean, std], f)\n",
    "create_normalizer_pm25()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PM25_Dataset(Dataset):\n",
    "    def __init__(self, eval_length=36, target_dim=36, mode=\"train\", validindex=0):\n",
    "        self.eval_length = eval_length\n",
    "        self.target_dim = target_dim\n",
    "\n",
    "        path = \"./data_project/pm25/pm25_meanstd.pk\"\n",
    "        with open(path, \"rb\") as f:\n",
    "            self.train_mean, self.train_std = pickle.load(f)\n",
    "        if mode == \"train\":\n",
    "            month_list = [1, 2, 4, 5, 7, 8, 10, 11]\n",
    "            # 1st,4th,7th,10th months are excluded from histmask (since the months are used for creating missing patterns in test dataset)\n",
    "            flag_for_histmask = [0, 1, 0, 1, 0, 1, 0, 1] \n",
    "            month_list.pop(validindex)\n",
    "            flag_for_histmask.pop(validindex)\n",
    "        elif mode == \"valid\":\n",
    "            month_list = [1, 2, 4, 5, 7, 8, 10, 11]\n",
    "            month_list = month_list[validindex : validindex + 1]\n",
    "        elif mode == \"test\":\n",
    "            month_list = [3, 6, 9, 12]\n",
    "        self.month_list = month_list\n",
    "\n",
    "        # create data for batch\n",
    "        self.observed_data = []  # values (separated into each month)\n",
    "        self.observed_mask = []  # masks (separated into each month)\n",
    "        self.gt_mask = []  # ground-truth masks (separated into each month)\n",
    "        self.index_month = []  # indicate month\n",
    "        self.position_in_month = []  # indicate the start position in month (length is the same as index_month)\n",
    "        self.valid_for_histmask = []  # whether the sample is used for histmask\n",
    "        self.use_index = []  # to separate train/valid/test\n",
    "        self.cut_length = []  # excluded from evaluation targets\n",
    "\n",
    "        df = pd.read_csv(\n",
    "            \"./data_project/pm25/STMVL-Release/Code/STMVL/SampleData/pm25_ground.txt\",\n",
    "            index_col=\"datetime\",\n",
    "            parse_dates=True,\n",
    "        )\n",
    "        df_gt = pd.read_csv(\n",
    "            \"./data_project/pm25/STMVL-Release/Code/STMVL/SampleData/pm25_missing.txt\",\n",
    "            index_col=\"datetime\",\n",
    "            parse_dates=True,\n",
    "        )\n",
    "        for i in range(len(month_list)):\n",
    "            current_df = df[df.index.month == month_list[i]]\n",
    "            current_df_gt = df_gt[df_gt.index.month == month_list[i]]\n",
    "            current_length = len(current_df) - eval_length + 1\n",
    "\n",
    "            last_index = len(self.index_month)\n",
    "            self.index_month += np.array([i] * current_length).tolist()\n",
    "            self.position_in_month += np.arange(current_length).tolist()\n",
    "            if mode == \"train\":\n",
    "                self.valid_for_histmask += np.array(\n",
    "                    [flag_for_histmask[i]] * current_length\n",
    "                ).tolist()\n",
    "\n",
    "            # mask values for observed indices are 1\n",
    "            c_mask = 1 - current_df.isnull().values\n",
    "            c_gt_mask = 1 - current_df_gt.isnull().values\n",
    "            c_data = (\n",
    "                (current_df.fillna(0).values - self.train_mean) / self.train_std\n",
    "            ) * c_mask\n",
    "\n",
    "            self.observed_mask.append(c_mask)\n",
    "            self.gt_mask.append(c_gt_mask)\n",
    "            self.observed_data.append(c_data)\n",
    "\n",
    "            if mode == \"test\":\n",
    "                n_sample = len(current_df) // eval_length\n",
    "                # interval size is eval_length (missing values are imputed only once)\n",
    "                c_index = np.arange(\n",
    "                    last_index, last_index + eval_length * n_sample, eval_length\n",
    "                )\n",
    "                self.use_index += c_index.tolist()\n",
    "                self.cut_length += [0] * len(c_index)\n",
    "                if len(current_df) % eval_length != 0:  # avoid double-count for the last time-series\n",
    "                    self.use_index += [len(self.index_month) - 1]\n",
    "                    self.cut_length += [eval_length - len(current_df) % eval_length]\n",
    "\n",
    "        if mode != \"test\":\n",
    "            self.use_index = np.arange(len(self.index_month))\n",
    "            self.cut_length = [0] * len(self.use_index)\n",
    "\n",
    "        # masks for 1st,4th,7th,10th months are used for creating missing patterns in test data,\n",
    "        # so these months are excluded from histmask to avoid leakage\n",
    "        if mode == \"train\":\n",
    "            ind = -1\n",
    "            self.index_month_histmask = []\n",
    "            self.position_in_month_histmask = []\n",
    "\n",
    "            for i in range(len(self.index_month)):\n",
    "                while True:\n",
    "                    ind += 1\n",
    "                    if ind == len(self.index_month):\n",
    "                        ind = 0\n",
    "                    if self.valid_for_histmask[ind] == 1:\n",
    "                        self.index_month_histmask.append(self.index_month[ind])\n",
    "                        self.position_in_month_histmask.append(\n",
    "                            self.position_in_month[ind]\n",
    "                        )\n",
    "                        break\n",
    "        else:  # dummy (histmask is only used for training)\n",
    "            self.index_month_histmask = self.index_month\n",
    "            self.position_in_month_histmask = self.position_in_month\n",
    "\n",
    "    def __getitem__(self, org_index):\n",
    "        index = self.use_index[org_index]\n",
    "        c_month = self.index_month[index]\n",
    "        c_index = self.position_in_month[index]\n",
    "        hist_month = self.index_month_histmask[index]\n",
    "        hist_index = self.position_in_month_histmask[index]\n",
    "        s = {\n",
    "            \"observed_data\": self.observed_data[c_month][\n",
    "                c_index : c_index + self.eval_length\n",
    "            ],\n",
    "            \"observed_mask\": self.observed_mask[c_month][\n",
    "                c_index : c_index + self.eval_length\n",
    "            ],\n",
    "            \"gt_mask\": self.gt_mask[c_month][\n",
    "                c_index : c_index + self.eval_length\n",
    "            ],\n",
    "            \"hist_mask\": self.observed_mask[hist_month][\n",
    "                hist_index : hist_index + self.eval_length\n",
    "            ],\n",
    "            \"timepoints\": np.arange(self.eval_length),\n",
    "            \"cut_length\": self.cut_length[org_index],\n",
    "        }\n",
    "\n",
    "        return s\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.use_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size, device, validindex=0):\n",
    "    dataset = PM25_Dataset(mode=\"train\", validindex=validindex)\n",
    "    train_loader = DataLoader(\n",
    "        dataset, batch_size=batch_size, num_workers=3, shuffle=True\n",
    "    )\n",
    "    dataset_test = PM25_Dataset(mode=\"test\", validindex=validindex)\n",
    "    test_loader = DataLoader(\n",
    "        dataset_test, batch_size=batch_size, num_workers=1, shuffle=False\n",
    "    )\n",
    "    dataset_valid = PM25_Dataset(mode=\"valid\", validindex=validindex)\n",
    "    valid_loader = DataLoader(\n",
    "        dataset_valid, batch_size=batch_size, num_workers=1, shuffle=True\n",
    "    )\n",
    "\n",
    "    scaler = torch.from_numpy(dataset.train_std).to(device).float()\n",
    "    mean_scaler = torch.from_numpy(dataset.train_mean).to(device).float()\n",
    "\n",
    "    return train_loader, valid_loader, test_loader, scaler, mean_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moded Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesSeriesAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A module that computes multi-head attention given query, key, and value tensors for time series data of shape (b, t, f, e)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "        \n",
    "        Inputs:\n",
    "        - input_dim: Dimension of the input query, key, and value. We assume they all have\n",
    "          the same dimensions. This is basically the dimension of the embedding.\n",
    "        - num_heads: Number of attention heads\n",
    "        \"\"\"\n",
    "        super(TimesSeriesAttention, self).__init__()\n",
    "\n",
    "        assert embed_dim % num_heads == 0\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dim_per_head = embed_dim // num_heads\n",
    "\n",
    "\n",
    "        self.linear_query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_value = nn.Linear(embed_dim, (self.num_heads * self.dim_per_head * self.dim_per_head))\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.softmax = nn.Softmax2d()\n",
    "\n",
    "\n",
    "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Compute the attended feature representations.\n",
    "        \n",
    "        Inputs:\n",
    "        - query: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension, \n",
    "        and E is the embedding dimension\n",
    "        - key: Tensor of the shape BxTxFXE\n",
    "        - value: Tensor of the shape BxTxFXE\n",
    "        - mask: Tensor indicating where the attention should *not* be performed\n",
    "        \"\"\"\n",
    "        b = query.shape[0]\n",
    "        t = query.shape[1]\n",
    "        f = query.shape[2]\n",
    "        e = query.shape[3]\n",
    "        d = self.dim_per_head\n",
    "        h = self.num_heads\n",
    "\n",
    "\n",
    "        query_linear = self.linear_query(query)\n",
    "        key_linear = self.linear_key(key)\n",
    "        value_linear = self.linear_value(value)\n",
    "\n",
    "        query_reshaped = query_linear.reshape(b, t, f, self.num_heads, self.dim_per_head)\n",
    "        key_reshaped = key_linear.reshape(b, t, f, self.num_heads, self.dim_per_head)\n",
    "        value_reshaped = value_linear.reshape(b, t, f, self.num_heads, self.dim_per_head, self.dim_per_head)\n",
    "\n",
    "        query_reshaped = query_reshaped.permute(0, 3, 1, 2, 4) # BxHxTxFxD\n",
    "        key_reshaped = key_reshaped.permute(0, 3, 1, 2, 4) # BxHxTxFxD\n",
    "        value_reshaped = value_reshaped.permute(0, 3, 1, 2, 4, 5) # BxHxTxFxDxD\n",
    "\n",
    "\n",
    "        kq = torch.einsum(\"bhtfd,bhxyd->bhtfxy\", key_reshaped, query_reshaped)\n",
    "\n",
    "        dot_prod_scores = kq/math.sqrt(self.dim_per_head)\n",
    "\n",
    "\n",
    "        #softmax across last 2 features (use softmax2d)\n",
    "        dot_prod_scores = dot_prod_scores.reshape(b*h, t*f, t, f)\n",
    "        dot_prod_scores = self.softmax(dot_prod_scores)\n",
    "        dot_prod_scores = dot_prod_scores.reshape(b, h, t, f, t, f)\n",
    "\n",
    "        out = torch.einsum(\"bhtfxy,bhtfdc->bhtfd\",\n",
    "                           dot_prod_scores, value_reshaped)\n",
    "        out = out.permute(0, 2, 3, 1, 4).reshape(b, t, f, e)\n",
    "        out = self.output_linear(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single cell (unit) for the Transformer encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, dropout: float):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(TransformerEncoderCell, self).__init__()\n",
    "\n",
    "        self.time_series_attention = TimesSeriesAttention(embed_dim, num_heads)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.linear2 = nn.Linear(ff_dim, embed_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \"\"\"\n",
    "\n",
    "        attention2 = self.time_series_attention(x, x, x, mask)\n",
    "        attention = x + self.dropout1(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        attention2 = self.linear2(self.dropout(self.activation(self.linear1(attention))))\n",
    "        attention = attention + self.dropout2(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A full encoder consisting of a set of TransformerEncoderCell.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, num_cells: int, dropout: float=0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - num_cells: Number of time series attention cells in the encoder\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        \n",
    "        self.norm = None\n",
    "\n",
    "        self.encoder_modules = nn.ModuleList(TransformerEncoderCell(embed_dim, num_heads, ff_dim, dropout) for _ in range(num_cells))\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor=None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \n",
    "        Return:\n",
    "        - y: Tensor of the shape BxTxFXE\n",
    "        \"\"\"\n",
    "\n",
    "        #run encoder modules and add residual connections\n",
    "        for encoder_module in self.encoder_modules:\n",
    "            x = encoder_module(x, mask)\n",
    "\n",
    "        y = x\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch_trans(num_heads=8, num_cells=1, embed_dim=128, ff_dim=512, dropout=0.1):\n",
    "    encoder_layer = nn.TransformerEncoderLayer(\n",
    "        d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim, activation=\"gelu\", dropout=dropout\n",
    "    )\n",
    "    return nn.TransformerEncoder(encoder_layer, num_layers=num_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionEmbedding(nn.Module):\n",
    "    def __init__(self, num_steps, embedding_dim, projection_dim=None):\n",
    "        super(DiffusionEmbedding, self).__init__()\n",
    "        if projection_dim is None:\n",
    "            projection_dim = embedding_dim\n",
    "        self.register_buffer(\n",
    "            \"embedding\",\n",
    "            self._build_embedding(num_steps, embedding_dim / 2),\n",
    "            persistent=False,\n",
    "        )\n",
    "        self.projection1 = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.projection2 = nn.Linear(projection_dim, embedding_dim)        \n",
    "\n",
    "    def forward(self, diffusion_step, data, device=\"cpu\"):\n",
    "        x = self.embedding[diffusion_step]\n",
    "        x = self.projection1(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.projection2(x)\n",
    "        x = F.silu(x)\n",
    "        x = torch.zeros(data.shape).to(device) + x.unsqueeze(1).unsqueeze(1)\n",
    "        return x\n",
    "\n",
    "    def _build_embedding(self, num_steps, dim=64):\n",
    "        steps = torch.arange(num_steps).unsqueeze(1)  # (T,1)\n",
    "        frequencies = 10.0 ** (torch.arange(dim) / (dim - 1) * 4.0).unsqueeze(0)  # (1,dim)\n",
    "        table = steps * frequencies  # (T,dim)\n",
    "        table = torch.cat([torch.sin(table), torch.cos(table)], dim=1)  # (T,dim*2)\n",
    "        return table\n",
    "    \n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=10000.0):\n",
    "        super(TimeEmbedding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.learnable = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, data, device=\"cpu\"):\n",
    "        b, l, f, e = data.shape\n",
    "        pe = torch.arange(l).unsqueeze(0).unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "        pe = torch.zeros(data.shape).to(device) + pe\n",
    "        \n",
    "        div_term = 1 / torch.pow(\n",
    "            self.max_len, torch.arange(0, f, 2) / f\n",
    "        ).unsqueeze(-1).to(device)\n",
    "\n",
    "        pe[:, :, 0::2] = torch.sin(pe[:, :, 0::2] * div_term)\n",
    "        pe[:, :, 1::2] = torch.cos(pe[:, :, 1::2] * div_term)\n",
    "\n",
    "        return self.learnable(pe) \n",
    "    \n",
    "class FeatureEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=10000.0):\n",
    "        super(FeatureEmbedding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.learnable = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, data, device=\"cpu\"):\n",
    "        b, l, f, e = data.shape\n",
    "        pe = torch.arange(f).unsqueeze(0).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        pe = torch.zeros(data.shape).to(device) + pe\n",
    "\n",
    "        div_term = 1 / torch.pow(\n",
    "            self.max_len, torch.arange(0, e, 2) / e\n",
    "        ).to(device)\n",
    "\n",
    "        pe[:, :, :, 0::2] = torch.sin(pe[:, :, :, 0::2] * div_term)\n",
    "        pe[:, :, :, 1::2] = torch.cos(pe[:, :, :, 1::2] * div_term)\n",
    "\n",
    "        return self.learnable(pe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1d_with_init(in_channels, out_channels, kernel_size):\n",
    "    layer = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "    nn.init.kaiming_normal_(layer.weight)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_heads=8, num_cells=1, embed_dim=128, ff_dim=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_add = nn.Sequential(\n",
    "            nn.Linear(embed_dim*4, embed_dim*4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim*4, embed_dim)\n",
    "        )\n",
    "        \n",
    "        #self.output_projection = nn.Linear(embed_dim, embed_dim*2)\n",
    "\n",
    "        self.time_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "        self.feature_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "        self.linear_time = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_feature = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.feature_and_time_transformer = TransformerEncoder(embed_dim = embed_dim,\n",
    "                                              num_heads = num_heads,\n",
    "                                              ff_dim = ff_dim,\n",
    "                                              num_cells = num_cells,\n",
    "                                              dropout = dropout)\n",
    "        \n",
    "        self.mid_projection = Conv1d_with_init(embed_dim, 2 * embed_dim, 1)#nn.Linear(embed_dim, embed_dim*2)\n",
    "        self.output_projection = Conv1d_with_init(embed_dim, 2 * embed_dim, 1)\n",
    "        \n",
    "        \n",
    "    def forward_time(self, y, base_shape):\n",
    "        b, t, f, e = base_shape\n",
    "\n",
    "        y = y.permute(0, 2, 1, 3).reshape(b * f, t, e)\n",
    "        y = self.time_layer(y)\n",
    "        y = y.reshape(b, f, t, e).permute(0, 2, 1, 3)\n",
    "        return y\n",
    "\n",
    "    def forward_feature(self, y, base_shape):\n",
    "        b, t, f, e = base_shape\n",
    "\n",
    "        y = y.reshape(b * t, f, e)\n",
    "        y = self.feature_layer(y)\n",
    "        y = y.reshape(b, t, f, e)\n",
    "        return y        \n",
    "\n",
    "\n",
    "    def forward(self, noised_data, diffusion_emb, time_emb, feature_emb):\n",
    "        b, t, f, e = noised_data.shape\n",
    "        base_shape = noised_data.shape\n",
    "        \n",
    "        y = torch.stack((noised_data, diffusion_emb, time_emb, feature_emb), dim = -1)\n",
    "        y = y.reshape(b, t, f, -1)\n",
    "        y = self.embedding_add(y)\n",
    "        y_resid = y\n",
    "        y = self.forward_time(y, base_shape)\n",
    "        y = self.linear_time(y)\n",
    "        y = y + y_resid\n",
    "        y = (y + y_resid) / math.sqrt(2.0)\n",
    "        y = self.layer_norm(y)\n",
    "        y = self.forward_feature(y, base_shape) \n",
    "        y = self.linear_feature(y)\n",
    "        y = (y + y_resid) / math.sqrt(2.0)\n",
    "        y_resid = y\n",
    "        y = self.layer_norm(y)\n",
    "        y = self.feature_and_time_transformer(y)\n",
    "        y = self.linear_time_and_feature(y)\n",
    "        y = (y + y_resid) / math.sqrt(2.0)\n",
    "        y = self.layer_norm(y)\n",
    "        y = y.permute(0, 3, 1, 2).reshape(b, e, t*f)\n",
    "        y = self.mid_projection(y)\n",
    "        #y = y.permute(0, 3, 2, 1).reshape(b, 2*e, t*f)\n",
    "\n",
    "        gate, filter = torch.chunk(y, 2, dim=1)\n",
    "        y = torch.sigmoid(gate) * torch.tanh(filter)  # (b,e,f*t)\n",
    "        #y = y.permute(0, 2, 1)\n",
    "        y = self.output_projection(y)\n",
    "        #y = y.permute(0, 2, 1)\n",
    "\n",
    "        residual, skip = torch.chunk(y, 2, dim=1)\n",
    "        residual = residual.permute(0, 2, 1)\n",
    "        skip = skip.permute(0, 2, 1)\n",
    "        residual = residual.reshape(base_shape)\n",
    "        skip = skip.reshape(base_shape)\n",
    "        return (noised_data + residual) / math.sqrt(2.0), skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLoop(nn.Module):\n",
    "    def __init__(self, embed_dim=128, diffusion_steps = 1000, num_heads=8, num_cells=1, num_residual_layers = 4, ff_dim=512, dropout=0.1, device = \"cpu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.emb_dim = embed_dim\n",
    "\n",
    "        # self.data_embedding_linear = nn.Sequential(\n",
    "        #     nn.Linear(1, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        # ) \n",
    "        # self.x_embedding = nn.Sequential(\n",
    "        #     nn.Linear(1, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        # ) \n",
    "\n",
    "        self.data_embedding_linear = Conv1d_with_init(1, self.emb_dim, 1)\n",
    "        self.x_embedding = Conv1d_with_init(2, self.emb_dim, 1)\n",
    "        \n",
    "        self.output = Conv1d_with_init(self.emb_dim, 1, 1)\n",
    "        self.output_final = Conv1d_with_init(self.emb_dim, 1, 1)\n",
    "        \n",
    "        # self.x_add = nn.Sequential(\n",
    "        #     nn.Linear(embed_dim*num_residual_layers, embed_dim*num_residual_layers),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(embed_dim*num_residual_layers, embed_dim)\n",
    "        # )\n",
    "\n",
    "        \n",
    "        self.diffusion_embedding = DiffusionEmbedding(diffusion_steps, embed_dim)\n",
    "        self.time_embedding = TimeEmbedding(embed_dim)\n",
    "        self.feature_embedding = FeatureEmbedding(embed_dim)\n",
    "\n",
    "        self.residual_layers = nn.ModuleList(\n",
    "                ResidualBlock(\n",
    "                    num_heads=num_heads,\n",
    "                    num_cells=num_cells,\n",
    "                    embed_dim=embed_dim,\n",
    "                    ff_dim=ff_dim,\n",
    "                    dropout=dropout\n",
    "                ) for _ in range(num_residual_layers)\n",
    "        )\n",
    "    \n",
    "        # self.output = nn.Sequential(\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, 1)\n",
    "        # )\n",
    "\n",
    "        # self.output_final = nn.Sequential(\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, 1)\n",
    "        # )\n",
    "\n",
    "\n",
    "    def forward(self, noised_data, noise_mask, diffusion_t):\n",
    "\n",
    "        b, t, f, a = noised_data.shape\n",
    "        \n",
    "        noised_data_reshaped = noised_data.permute(0, 3, 1, 2).reshape(b, 1, t*f)\n",
    "        noised_data_embedded = self.data_embedding_linear(noised_data_reshaped).permute(0, 2, 1).reshape(b, t, f, self.emb_dim)\n",
    "        diffusion_embedding = self.diffusion_embedding(diffusion_t, noised_data_embedded, device = self.device)\n",
    "        time_embedding = self.time_embedding(noised_data_embedded, device = self.device)\n",
    "        feature_embedding = self.feature_embedding(noised_data_embedded, device = self.device)\n",
    "\n",
    "        x = noised_data_embedded\n",
    "        skip = []\n",
    "        for layer in self.residual_layers:\n",
    "            x, skip_connection = layer(x, diffusion_embedding, time_embedding, feature_embedding)\n",
    "            skip.append(skip_connection)\n",
    "            x = x.permute(0, 3, 1, 2).reshape(b, self.emb_dim, t*f)\n",
    "            x = self.output(x).permute(0, 2, 1).reshape(b, t, f)\n",
    "            x = torch.stack((x, noised_data.squeeze(-1)), dim = -1)\n",
    "            #x = x * noise_mask + noised_data * (1 - noise_mask)\n",
    "            x = x.permute(0, 3, 1, 2).reshape(b, 2, t*f)\n",
    "            x = self.x_embedding(x).permute(0, 2, 1).reshape(b, t, f, self.emb_dim)\n",
    "\n",
    "        x = torch.sum(torch.stack(skip, dim = -1), dim=-1)/ math.sqrt(len(self.residual_layers))\n",
    "        # x = torch.stack(skip, dim = -1).reshape(b, t, f, -1)\n",
    "        #x = self.x_add(x)\n",
    "        x = x.permute(0, 3, 1, 2).reshape(b, self.emb_dim, t*f)\n",
    "        x = self.output_final(x).permute(0, 2, 1).reshape(b, t, f, 1).squeeze(-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_beta_schedule(schedule_name, num_diffusion_timesteps):\n",
    "    \"\"\"\n",
    "    Get a pre-defined beta schedule for the given name.\n",
    "\n",
    "    The beta schedule library consists of beta schedules which remain similar\n",
    "    in the limit of num_diffusion_timesteps.\n",
    "    Beta schedules may be added, but should not be removed or changed once\n",
    "    they are committed to maintain backwards compatibility.\n",
    "    \"\"\"\n",
    "    if schedule_name == \"linear\":\n",
    "        # Linear schedule from Ho et al, extended to work for any number of\n",
    "        # diffusion steps.\n",
    "        scale = 1000 / num_diffusion_timesteps\n",
    "        beta_start = scale * 0.0001\n",
    "        beta_end = scale * 0.02\n",
    "        return torch.linspace(\n",
    "            beta_start, beta_end, num_diffusion_timesteps\n",
    "        )\n",
    "    elif schedule_name == \"cosine\":\n",
    "        return betas_for_alpha_bar(\n",
    "            num_diffusion_timesteps,\n",
    "            lambda t: math.cos((t + 0.008) / 1.008 * math.pi / 2) ** 2,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f\"unknown beta schedule: {schedule_name}\")\n",
    "\n",
    "\n",
    "def betas_for_alpha_bar(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n",
    "    \"\"\"\n",
    "    Create a beta schedule that discretizes the given alpha_t_bar function,\n",
    "    which defines the cumulative product of (1-beta) over time from t = [0,1].\n",
    "\n",
    "    :param num_diffusion_timesteps: the number of betas to produce.\n",
    "    :param alpha_bar: a lambda that takes an argument t from 0 to 1 and\n",
    "                      produces the cumulative product of (1-beta) up to that\n",
    "                      part of the diffusion process.\n",
    "    :param max_beta: the maximum beta to use; use values lower than 1 to\n",
    "                     prevent singularities.\n",
    "    \"\"\"\n",
    "    betas = []\n",
    "    for i in range(num_diffusion_timesteps):\n",
    "        t1 = i / num_diffusion_timesteps\n",
    "        t2 = (i + 1) / num_diffusion_timesteps\n",
    "        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n",
    "    return torch.tensor(betas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diffusion_imputation(nn.Module):\n",
    "    def __init__(self, emb_dim,\n",
    "                #vocab_size,\n",
    "                #pad_idx= None,\n",
    "                strategy = \"random\",\n",
    "                num_residual_layers = 4,\n",
    "                features_to_impute = None,\n",
    "                missing_prp = 0.1,\n",
    "                diffusion_steps = 1000,\n",
    "                diffusion_beta_schedule = \"cosine\",\n",
    "                num_heads = 8,\n",
    "                ff_dim = 512,\n",
    "                num_cells = 2,\n",
    "                dropout = 0.1,\n",
    "                device = \"cpu\"):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "        self.device = device\n",
    "        self.emb_dim = emb_dim\n",
    "        self.strategy = strategy\n",
    "        self.features_to_impute = features_to_impute\n",
    "        self.missing_prp = missing_prp\n",
    "        self.diffusion_steps = diffusion_steps\n",
    "\n",
    "        #set device to cuda if available\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda\"\n",
    "\n",
    "        \n",
    "        self.model_loop = ModelLoop(embed_dim = self.emb_dim,\n",
    "                                    diffusion_steps = diffusion_steps,\n",
    "                                    num_heads = num_heads,\n",
    "                                    ff_dim = ff_dim,\n",
    "                                    num_cells = num_cells,\n",
    "                                    dropout = dropout,\n",
    "                                    num_residual_layers = num_residual_layers,\n",
    "                                    device = self.device)\n",
    "        \n",
    "        self.beta = get_named_beta_schedule(diffusion_beta_schedule, \n",
    "                                            diffusion_steps)\n",
    "        \n",
    "        #self.beta = torch.linspace(0.0001, 0.5, diffusion_steps)\n",
    "\n",
    "        # self.beta = torch.linspace(\n",
    "        #         0.0001 ** 0.5, 0.5 ** 0.5, diffusion_steps\n",
    "        #     ) ** 2\n",
    "        \n",
    "        self.alpha_hat = 1 - self.beta \n",
    "        self.alpha = torch.cumprod(self.alpha_hat, dim=0)\n",
    "        self.alpha_torch = torch.tensor(self.alpha).float()\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "\n",
    "    def get_mask(self, data, strategy = \"random\"):\n",
    "        \n",
    "        b = data.shape[0]\n",
    "        t = data.shape[1]\n",
    "        f = data.shape[2]\n",
    "\n",
    "        if strategy == \"forecasting\":\n",
    "            forecasted_time = torch.randint(2, t, (b, 1, 1))\n",
    "            mask = torch.zeros_like(data)\n",
    "            for i in range(b):\n",
    "                mask[i, forecasted_time[i]:, :] = 1\n",
    "\n",
    "        if strategy == \"forecasting_last_time\":\n",
    "            forecasted_time = torch.tensor([t-1]).repeat(b, 1, 1)\n",
    "            mask = torch.zeros_like(data)\n",
    "            for i in range(b):\n",
    "                mask[i, forecasted_time[i]:t, :] = 1\n",
    "        \n",
    "        # if strategy == \"random_features\":\n",
    "        #     selected_features = torch.randint(0, f, (b, 1, 1, 1))\n",
    "        #     mask = torch.zeros_like(data)\n",
    "        #     mask[:, :, selected_features, :] = 1\n",
    "        \n",
    "        # if strategy == \"selected_features\":\n",
    "        #     mask = torch.zeros_like(data)\n",
    "        #     mask[:, :, self.features_to_impute, :] = 1\n",
    "        \n",
    "        # if strategy == \"selected_features_after_time\":\n",
    "        #     selected_time = torch.randint(1, t, (b, 1, 1))\n",
    "        #     mask = torch.zeros_like(data)\n",
    "        #     mask[:, selected_time:, self.features_to_impute, :] = 1\n",
    "        \n",
    "        if strategy == \"random\":\n",
    "            mask = torch.rand(size=(b, t, f))\n",
    "            mask = mask < self.missing_prp\n",
    "            mask = mask.float()\n",
    "        return mask\n",
    "    \n",
    "    def loss_func(self, predicted_noise, noise, noise_mask):\n",
    "\n",
    "        residual = noise - predicted_noise\n",
    "        num_obs = torch.sum(noise_mask)\n",
    "        loss = (residual**2).sum() / num_obs\n",
    "        return(loss)\n",
    "    \n",
    "    def forward(self, data):\n",
    "         \n",
    "        b, t, f = data.shape\n",
    "\n",
    "        noise_mask = self.get_mask(data, self.strategy).to(self.device)\n",
    "        noise = torch.randn((b, t, f)).to(self.device)\n",
    "        noise = (noise_mask * noise)\n",
    "\n",
    "        diffusion_t = torch.randint(0, self.diffusion_steps, (b,1)).squeeze(1)\n",
    "        alpha = self.alpha_torch[diffusion_t].unsqueeze(1).unsqueeze(2).to(self.device)\n",
    "\n",
    "        noised_data = data * noise_mask\n",
    "        noised_data = noised_data * (alpha**0.5) + noise * ((1 - alpha)**0.5)\n",
    "        conditional_data = data * (1 - noise_mask)\n",
    "        noised_data = noised_data + conditional_data\n",
    "        noised_data = noised_data.float()\n",
    "\n",
    "        predicted_noise = self.model_loop(noised_data.unsqueeze(3), noise_mask.unsqueeze(3), diffusion_t)\n",
    "        predicted_noise = predicted_noise * noise_mask\n",
    "\n",
    "        return (predicted_noise, noise, noise_mask)\n",
    "    \n",
    "    def eval(self, data, imputation_mask, scale=1 , verbose = True):\n",
    "        \n",
    "        conditional_data = data * (1 - imputation_mask)\n",
    "        random_noise = torch.randn_like(data)* imputation_mask *scale\n",
    "        data_2 = (conditional_data + random_noise).unsqueeze(3)\n",
    "\n",
    "        b, ti, f, e = data_2.shape\n",
    "        imputed_samples = torch.zeros((b, ti, f)).to(self.device)\n",
    "        x = (conditional_data + random_noise)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for t in range(self.diffusion_steps - 1, -1, -1):\n",
    "\n",
    "                x = x.unsqueeze(3).float()\n",
    "                predicted_noise = self.model_loop(x, imputation_mask.unsqueeze(3), torch.tensor([t]).to(self.device))\n",
    "                predicted_noise = predicted_noise * imputation_mask\n",
    "\n",
    "                \n",
    "                coeff1 = 1 / self.alpha_hat[t] ** 0.5\n",
    "                coeff2 = (1 - self.alpha_hat[t]) / (1 - self.alpha[t]) ** 0.5\n",
    "                \n",
    "                x = x.squeeze(3)\n",
    "                x = coeff1 * (x - coeff2 * predicted_noise)\n",
    "                \n",
    "                if t > 0:\n",
    "                    noise = torch.randn_like(x)\n",
    "                    sigma = (\n",
    "                        (1.0 - self.alpha[t - 1]) / (1.0 - self.alpha[t]) * self.beta[t]\n",
    "                    ) ** 0.5\n",
    "                    x += sigma * noise\n",
    "                \n",
    "                x = data_2.squeeze(3) * (1 - imputation_mask) + x * imputation_mask\n",
    "            \n",
    "\n",
    "            imputed_samples = x.detach()\n",
    "        \n",
    "        mae = torch.mean(torch.abs(data[imputation_mask !=0] - imputed_samples[imputation_mask !=0])).item()\n",
    "        if verbose == True:\n",
    "            print(\"mae = \", mae)\n",
    "        # data_to_print = data[imputation_mask !=0]\n",
    "        # imputed_samples_to_print = imputed_samples[imputation_mask !=0]\n",
    "        # print(\"data:\", data_to_print)\n",
    "        # print(\"imputed:\", imputed_samples_to_print)\n",
    "        # print(\"absolute difference in the first 100 : \", torch.abs(data_to_print - imputed_samples_to_print)[:100])\n",
    "        # print(\"mae = \", torch.mean(torch.abs(data_to_print - imputed_samples_to_print)).item())\n",
    "\n",
    "        return(imputed_samples, data, imputation_mask, mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a train function that also shows a dynamic loss plot. It should also be batched. \n",
    "#the plot should be dynamic and show the loss for each epoch.\n",
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def train(model, data_loader, data_loader_validation, epochs, lr, loss_func, device = \"cuda\", verbose = True, validation_frequency = 1, validation_prp = 10, strategy = \"random\"):\n",
    "\n",
    "    model = model.to(device)\n",
    "    #annealing for the learning rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    epoch_loss = 0\n",
    "    epoch_loss_list = []\n",
    "    mae = 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #annealing for the learning rate (if the loss has not decreased in the last 2 epochs, divide the learning rate by 2)\n",
    "        if epoch > 3:\n",
    "            if epoch_loss >= min(epoch_loss_list[-3:]):\n",
    "                for g in optimizer.param_groups:\n",
    "                    g['lr'] = g['lr'] / 2\n",
    "\n",
    "        start = time.time()\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            predicted_noise, noise, noise_mask = model(batch[\"observed_data\"].to(device))\n",
    "            loss = loss_func(predicted_noise, noise, noise_mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "            if i % 2 == 0:       \n",
    "                ax.clear()\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.plot(loss_list)\n",
    "                #ax.text(len(loss_list) - 1, loss_list[-1], str(round(loss_list[-1], 3)))\n",
    "                #add a smooth line to the plot every 100 steps\n",
    "                if len(loss_list) > 100:\n",
    "                    ax.plot(np.convolve(loss_list, np.ones((100,))/100, mode='valid'))\n",
    "                    #show the last loss value on the plot\n",
    "                    ax.text(len(loss_list) - 1, np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1],\n",
    "                             str(round(np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1], 3)))\n",
    "                ax.text(0.1, 0.9, \"Epoch: \" + str(epoch) + \" Loss: \" + str(round(epoch_loss, 3)))\n",
    "                ax.text(0.1, 0.8, \"Learning rate: \" + str(round(optimizer.param_groups[0]['lr'], 9)))\n",
    "                ax.text(0.1, 0.7, \"Validation mae: \" + str(round(mae, 3)))\n",
    "                display(fig)\n",
    "                clear_output(wait=True)\n",
    "            #print(\"Epoch: \", epoch, \"Loss: \", loss.item())\n",
    "        end = time.time()    \n",
    "        \n",
    "        if verbose:\n",
    "            #add the epoch average loss to the plot\n",
    "            #find the number of batches in the epoch\n",
    "            num_batches = len(data_loader)\n",
    "            #find the average loss for the epoch\n",
    "            epoch_loss = sum(loss_list[-num_batches:]) / num_batches\n",
    "            epoch_loss_list.append(epoch_loss)\n",
    "        \n",
    "        #validation at the end of each n epoch\n",
    "\n",
    "        if epoch % validation_frequency == 0:\n",
    "            imputed_samples = torch.tensor([]).to(\"cuda\")\n",
    "            data = torch.tensor([]).to(\"cuda\")\n",
    "            imputation_mask = torch.tensor([]).to(\"cuda\")\n",
    "            mae_list = []\n",
    "            \n",
    "            for i, batch in enumerate(data_loader_validation):\n",
    "                if i % validation_prp == 0:\n",
    "                    test_data = batch[\"observed_data\"].to(\"cuda\")\n",
    "                    imputation_mask = diffusion_imputation.get_mask(model, test_data, strategy).to(\"cuda\")\n",
    "                    imputed_step, data_step, imputation_mask_step, mae_step = diffusion_imputation.eval(model, test_data, imputation_mask, verbose=False)\n",
    "                    imputed_samples = torch.cat((imputed_samples, imputed_step), dim = 0)\n",
    "                    data = torch.cat((data, data_step), dim = 0)\n",
    "                    imputation_mask = torch.cat((imputation_mask, imputation_mask_step), dim = 0)\n",
    "                    mae_list.append(mae_step)\n",
    "            mae = sum(mae_list) / len(mae_list)\n",
    "\n",
    "\n",
    "    return(model, loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4842\n",
      "709\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "train_set = PM25_Dataset(mode=\"train\")\n",
    "valid_set = PM25_Dataset(mode=\"valid\")\n",
    "test_set  = PM25_Dataset(mode=\"test\")\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(valid_set))\n",
    "print(len(test_set))\n",
    "\n",
    "data_loader_model = get_dataloader(12, \"cuda\")[0]\n",
    "data_loader_validation = get_dataloader(1, \"cuda\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59486/3441439131.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.alpha_torch = torch.tensor(self.alpha).float()\n"
     ]
    }
   ],
   "source": [
    "diffusion_imputer = diffusion_imputation(emb_dim = 128,\n",
    "                                         strategy='random',\n",
    "                                         num_residual_layers=4,\n",
    "                                         missing_prp= 0.1,\n",
    "                                         diffusion_steps= 50,\n",
    "                                         diffusion_beta_schedule= \"linear\",\n",
    "                                         num_heads=8,\n",
    "                                         ff_dim=4096,\n",
    "                                         num_cells = 4,\n",
    "                                         dropout=0.1,\n",
    "                                         device=\"cuda\")\n",
    "\n",
    "# data = torch.ones((10,10,10)).to(\"cuda\")\n",
    "# diffusion_imputer(data, strategy='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(\n\u001b[1;32m      2\u001b[0m     diffusion_imputer, \n\u001b[1;32m      3\u001b[0m     data_loader_model, \n\u001b[1;32m      4\u001b[0m     data_loader_validation,\n\u001b[1;32m      5\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m20\u001b[39;49m, \n\u001b[1;32m      6\u001b[0m     lr \u001b[39m=\u001b[39;49m \u001b[39m0.0001\u001b[39;49m, \n\u001b[1;32m      7\u001b[0m     loss_func \u001b[39m=\u001b[39;49m diffusion_imputer\u001b[39m.\u001b[39;49mloss_func,\n\u001b[1;32m      8\u001b[0m     validation_frequency\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     validation_prp\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     strategy \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mrandom\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[18], line 34\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, data_loader_validation, epochs, lr, loss_func, device, verbose, validation_frequency, validation_prp, strategy)\u001b[0m\n\u001b[1;32m     32\u001b[0m loss \u001b[39m=\u001b[39m loss_func(predicted_noise, noise, noise_mask)\n\u001b[1;32m     33\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 34\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     35\u001b[0m loss_list\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:       \n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/torch/optim/adam.py:107\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[39m# record the step after step update\u001b[39;00m\n\u001b[1;32m    105\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 107\u001b[0m     F\u001b[39m.\u001b[39;49madam(params_with_grad,\n\u001b[1;32m    108\u001b[0m            grads,\n\u001b[1;32m    109\u001b[0m            exp_avgs,\n\u001b[1;32m    110\u001b[0m            exp_avg_sqs,\n\u001b[1;32m    111\u001b[0m            max_exp_avg_sqs,\n\u001b[1;32m    112\u001b[0m            state_steps,\n\u001b[1;32m    113\u001b[0m            amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    114\u001b[0m            beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    115\u001b[0m            beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    116\u001b[0m            lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    117\u001b[0m            weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    118\u001b[0m            eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/torch/optim/_functional.py:98\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     94\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(bias_correction2))\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m     96\u001b[0m step_size \u001b[39m=\u001b[39m lr \u001b[39m/\u001b[39m bias_correction1\n\u001b[0;32m---> 98\u001b[0m param\u001b[39m.\u001b[39;49maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGiCAYAAADwXFzAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAACcnUlEQVR4nOzdd1hT1xsH8O9NAgmgIC6GojhxgxNx1IXirFpXrVVrrVvrqK217lpr3dZRqbaOtq7a/rRaVxXFiVvcoiKICxQHUwhJzu8PIGTvhATez/P4SG7Ovfdk3jfnvOccjjHGQAghhBDiwHiFXQFCCCGEEHNRQEMIIYQQh0cBDSGEEEIcHgU0hBBCCHF4FNAQQgghxOFRQEMIIYQQh0cBDSGEEEIcHgU0hBBCCHF4FNAQQgghxOFRQEMIIYQQh2d0QHPy5En06NEDvr6+4DgOe/bs0btPZGQkGjVqBKFQiOrVq2Pz5s0mVJUQQgghRDOjA5qMjAwEBgZi7dq1BpWPi4tDt27d0K5dO0RHR2PSpEn47LPPcPjwYaMrSwghhBCiCWfO4pQcx2H37t3o1auX1jLTpk3D/v37cfPmTfm2Dz/8EG/fvsWhQ4dMPTUhhBBCiJzA2ieIiopCaGio0rawsDBMmjRJ6z7Z2dnIzs6W35bJZHj9+jXKlCkDjuOsVVVCCCGEWBBjDGlpafD19QWPZ920XasHNImJifDy8lLa5uXlhdTUVLx79w4uLi5q+yxcuBDz5s2zdtUIIYQQYgOPHz9GxYoVrXoOqwc0ppg+fTqmTJkiv52SkoJKlSrh8ePHcHd3t+i5tl94hAX776JjnfJYMaChRY9NCCGEFGepqanw8/NDyZIlrX4uqwc03t7eSEpKUtqWlJQEd3d3ja0zACAUCiEUCtW2u7u7WzygcXUrCZ7QFU6iEhY/NiGEEEJgk3QRq89DExISgoiICKVtR44cQUhIiLVPbZi8J5nB5NxoQgghhBQyowOa9PR0REdHIzo6GkDusOzo6GgkJCQAyO0uGjJkiLz86NGj8fDhQ3z11Ve4e/cufvrpJ/z555+YPHmyZR6BmfJjRtPHehFCCCGksBkd0Fy6dAkNGzZEw4a5+SZTpkxBw4YNMXv2bADA8+fP5cENAFSpUgX79+/HkSNHEBgYiGXLluGXX35BWFiYhR6CefJbwSieIYQQQhyX0Tk0bdu2ha6pazTNAty2bVtcvXrV2FPZBJfXRkMtNIQQQojjKvZrORXkKVFEQwghhDgqCmjy/qcWGkIIIcRxUUBDOTSEEEKIw6OARp5DQyENIYQQ4qiKfUADaqEhhBBCHF6xD2goh4YQQghxfBTQyGcKJoQQQoijooAm73/KoSGEEEIcFwU01l8vixBCCCFWRgFNflIwNdAQQgghDosCGtBq24QQQoijo4CGWmgIIYQQh1fsA5p8FNAQQgghjqvYBzQFw7YpoiGEEEIcFQU0ef/fTUwr1HoQQgghxHQU0ORFNG8zc/AiNatwK0MIIYQQk1BAg4KJaO6/SC/EmhBCCCHEVBTQKEysly2RFl5FCCGEEGIyCmgU/hZLZIVWD0IIIYSYjgIapRaawg1oOI7Dnj17CrUOhBBCiCMq9gENwCF5/wo8WtQdvRpWBMdx8n+dO3cu7MqZRPEx5P/bsWOH3n3sNZhijGH27Nnw8fGBi4sLQkNDcf/+fZ37nDx5Ej169ICvr69dPzZCCCGWUewDmvwWGlGVxli7/yKeP38u/7d9+/bCrZwZNm3apPRYevXqVdhVMtnixYuxatUqhIeH4/z583Bzc0NYWBiysrSPSsvIyEBgYCDWrl1rw5oSQggpLBTQ5P8vcEIJz7Lw9vaW//P09Cwox3FYt24dunTpAhcXF1StWhV//fWX0rFu3LiB9u3bw8XFBWXKlMHIkSORnq48cmrjxo2oW7cuhEIhfHx8MH78eKX7k5OT0bt3b7i6uqJGjRrYu3evSY+rVKlSSo9FJBKZdBwAkMlk+Pbbb1GxYkUIhUIEBQXh0KFD8vvFYjHGjx8PHx8fiEQiVK5cGQsXLgSQ27oyd+5cVKpUCUKhEL6+vvj8888NPjdjDCtXrsTMmTPRs2dPNGjQAL/99huePXums9WlS5cu+O6779C7d2+THzchhBDHQQGNQhKNVKZ7tuBZs2ahT58+uHbtGgYNGoQPP/wQd+7cAZDbIhAWFgZPT09cvHgRu3btwtGjR5UClnXr1mHcuHEYOXIkbty4gb1796J69epK55g3bx769++P69evo2vXrhg0aBBev34tv9/f3x9z587V+7jGjRuHsmXLolmzZti4cSOYGWs7/Pjjj1i2bBmWLl2K69evIywsDO+//76822fVqlXYu3cv/vzzT8TExGDr1q3w9/cHAPz9999YsWIFfv75Z9y/fx979uxB/fr15ceeO3euvKwmcXFxSExMRGhoqHybh4cHgoODERUVZfJjIoQQUsQwB5CSksIAsJSUFIsf+79bicytXgcGjseELq7Mzc1N/m/BggXycgDY6NGjlfYNDg5mY8aMYYwxtn79eubp6cnS09Pl9+/fv5/xeDyWmJjIGGPM19eXzZgxQ2tdALCZM2fKb6enpzMA7ODBg/Jt7du3Z6tXr9b5mL799lt2+vRpduXKFfbDDz8woVDIfvzxR537AGC7d+/WeJ+vr6/Sc8EYY02bNmVjx45ljDE2YcIE1r59eyaTydT2XbZsGatZsyYTi8Uaj7169WrWvn17rfU6c+YMA8CePXumtL1fv36sf//+uh6SnK7HRgghxHqsef1WJSi8UMo+sLyWC1GlBpj5/TIMaFZJfl/p0qWVyoaEhKjdjo6OBgDcuXMHgYGBcHNzk9/fsmVLyGQyxMTEgOM4PHv2DB06dNBZnwYNGsj/dnNzg7u7O168eCHfFhERofcxzZo1S/53w4YNkZGRgSVLlhjV1ZMvNTUVz549Q8uWLZW2t2zZEteuXQMAfPLJJ+jYsSMCAgLQuXNndO/eHZ06dQIA9OvXDytXrkTVqlXRuXNndO3aFT169IBAkPvWGz9+vFq3GyGEEGKsYt/llI9zFqFshcqoXr26/J9qQGMOFxcXg8o5OTkp14vjIJOZN5w8ODgYT548QXZ2tlnH0aZRo0aIi4vD/Pnz8e7dO/Tv3x99+/YFAPj5+SEmJgY//fQTXFxcMHbsWLz33nvIyckx6Nje3t4AgKSkJKXtSUlJ8vsIIYQQCmgU6Emhwblz59Ru165dGwBQu3ZtXLt2DRkZGfL7z5w5Ax6Ph4CAAJQsWRL+/v4GtbBYWnR0NDw9PSEUCo3e193dHb6+vjhz5ozS9jNnzqBOnTpK5QYMGIANGzZg586d+Pvvv+W5Py4uLujRowdWrVqFyMhIREVF4caNGwadv0qVKvD29lZ63lJTU3H+/Hm1FjNCCCHFV7HvcsrHJDl4++oFEhMLuowEAgHKli0rv71r1y40adIErVq1wtatW3HhwgX8+uuvAIBBgwZhzpw5GDp0KObOnYuXL19iwoQJGDx4MLy8vADkJsCOHj0a5cuXR5cuXZCWloYzZ85gwoQJBtezQ4cO6N27t9Zumn379iEpKQnNmzeHSCTCkSNH8P3332Pq1Kl6jx0XFyfvQstXo0YNfPnll5gzZw6qVauGoKAgbNq0CdHR0di6dSsAYPny5fDx8UHDhg3B4/Gwa9cueHt7o1SpUti8eTOkUimCg4Ph6uqKP/74Ay4uLqhcuTIAYM2aNdi9e7fWQI/jOEyaNAnfffcdatSogSpVqmDWrFnw9fVVGoqu+rykp6fjwYMHao+tdOnSqFSpkuppCCGEODqrZ+lYgDWTig7ffJ6bFAyo/QsICJCXA8DWrl3LOnbsyIRCIfP392c7d+5UOtb169dZu3btmEgkYqVLl2YjRoxgaWlpSmXCw8NZQEAAc3JyYj4+PmzChAlK51BNXvXw8GCbNm2S365cuTKbM2eO1sdz8OBBFhQUxEqUKMHc3NxYYGAgCw8PZ1KpVOfzoOnxA2CnTp1iUqmUzZ07l1WoUIE5OTmxwMBApUTl9evXs6CgIObm5sbc3d1Zhw4d2JUrVxhjjO3evZsFBwczd3d35ubmxpo3b86OHj0q33fOnDmscuXKOusmk8nYrFmzmJeXFxMKhaxDhw4sJiZGqYzq83L8+HGNj2fo0KE6z0UIIcRybJkUzDFmxnheG0lNTYWHhwdSUlLg7u5u0WP/dysRI3+/DACYFFoDk0JraizHcRx2797t0BPUEUIIIbZkzeu3qmKfQ6MYzenLoSGEEEKIfSr2AY0iGUU0hBBCiEOipGAFMh29bw7QM0cIIYQUW9RCo4AaaAghhBDHRAGNAmqFIYQQQhwTBTQK9C1OSQghhBD7VOwDGsVGGQpnCCGEEMdU7AMaQgghhDg+CmgUUAoNIYQQ4pgooCGEEEKIw6OAhhBCCCEOjwIaBYzSggkhhBCHRAGNQhBDOTSEEEKIY6KARoGupQ8IIYQQYr8ooFFA8QwhhBDimCigUUAtNIQQQohjooBGAYUzhBBCiGOigEYBLU5JCCGEOKZiH9AoxjAyWeHVgxBCCCGmK/YBjSKah4YQQghxTBTQKJBRPEMIIYQ4JApoFNAoJ0IIIcQxUUCjiOIZQgghxCFRQKOAWmgIIYQQx1TsAxqm5W9CCCGEOA4KaBSHbdthROPv74+VK1cWdjUIIYQQu1bsAxoASN6/Ai/+951ddjldvHgRI0eOLOxqaPXJJ5+gV69eVjn2hg0b0Lp1a3h6esLT0xOhoaG4cOGCzn0iIyPBcZzav8TERLPrc/36dbRu3RoikQh+fn5YvHix0v2bN29WO69IJDL7vIQQQvQTFHYF7IoN45mcnBw4OTnpLVeuXDkb1EadofWzpsjISAwcOBAtWrSASCTCokWL0KlTJ9y6dQsVKlTQuW9MTAzc3d3lt8uXL29WXVJTU9GpUyeEhoYiPDwcN27cwKeffopSpUopBZzu7u6IiYmR3+Y4zqzzEkIIMQy10CjQ1kJz8+ZNdOnSBSVKlICXlxcGDx6M5ORk+f2HDh1Cq1atUKpUKZQpUwbdu3dHbGys/P74+HhwHIedO3eiTZs2EIlE2Lp1q7x1Y+nSpfDx8UGZMmUwbtw45OTkyPdV7XLiOA6//PILevfuDVdXV9SoUQN79+5Vqu/evXtRo0YNiEQitGvXDlu2bAHHcXj79q3Wx85xHNatW4f3338fbm5uWLBgAaRSKYYPH44qVarAxcUFAQEB+PHHH+X7zJ07F1u2bME///wjb5GIjIwEADx+/Bj9+/dHqVKlULp0afTs2RPx8fEGvAoFtm7dirFjxyIoKAi1atXCL7/8AplMhoiICL37li9fHt7e3vJ/PF7BW10mk2HhwoXyxxUYGIi//vpLb13EYjE2btyIunXr4sMPP8Tnn3+O5cuXK5XjOE7pvF5eXkY9ZkIIIaYp9gFN86ql5X9rCmjevn2L9u3bo2HDhrh06RIOHTqEpKQk9O/fX14mIyMDU6ZMwaVLlxAREQEej4fevXtDprKWwtdff42JEyfizp07CAsLAwAcP34csbGxOH78OLZs2YLNmzdj8+bNOus8b9489O/fH9evX0fXrl0xaNAgvH79GgAQFxeHvn37olevXrh27RpGjRqFGTNmGPRczJ07F71795a3PshkMlSsWBG7du3C7du3MXv2bHzzzTf4888/AQBTp05F//790blzZzx//hzPnz9HixYtkJOTg7CwMJQsWRKnTp3CmTNnUKJECXTu3BlisRhAQdeQMUFOZmYmcnJyULp0ab1lg4KC4OPjg44dO+LMmTNK9y1cuBC//fYbwsPDcevWLUyePBkff/wxTpw4ofV4UVFReO+99+Ds7CzfFhYWhpiYGLx580a+LT09HZUrV4afnx969uyJW7duGfz4CCGEmIE5gJSUFAaApaSkWOX4wWG9mUuN5mzElotq982fP5916tRJadvjx48ZABYTE6PxeC9fvmQA2I0bNxhjjMXFxTEAbOXKlUrlhg4dyipXrswkEol8W79+/diAAQPktytXrsxWrFghvw2AzZw5U347PT2dAWAHDx5kjDE2bdo0Vq9ePaXzzJgxgwFgb9680focAGCTJk3Sen++cePGsT59+ig9hp49eyqV+f3331lAQACTyWTybdnZ2czFxYUdPnyYMcbY+fPnWUBAAHvy5Inec+YbM2YMq1q1Knv37p3WMnfv3mXh4eHs0qVL7MyZM2zYsGFMIBCwy5cvM8YYy8rKYq6uruzs2bNK+w0fPpwNHDhQ63E7duzIRo4cqbTt1q1bDAC7ffs2Y4yxs2fPsi1btrCrV6+yyMhI1r17d+bu7s4eP35s8GMkhJCixNrXb0WUQwPAmc8HoHmU07Vr13D8+HGUKFFC7b7Y2FjUrFkT9+/fx+zZs3H+/HkkJyfLW2YSEhJQr149efkmTZqoHaNu3brg550fAHx8fHDjxg2d9W3QoIH8bzc3N7i7u+PFixcAcnNHmjZtqlS+WbNmOo+nq35r167Fxo0bkZCQgHfv3kEsFiMoKEjnca5du4YHDx6gZMmSStuzsrLkXXHNmjXD3bt3DaoXAPzwww/YsWMHIiMjdSbaBgQEICAgQH67RYsWiI2NxYoVK/D777/jwYMHyMzMRMeOHZX2E4vFaNiwIYDc1+TRo0cAgNatW+PgwYMG1TEkJAQhISFK565duzZ+/vlnzJ8/3+DHSgghxHgmBTRr167FkiVLkJiYiMDAQKxevVrnRXPlypVYt24dEhISULZsWfTt2xcLFy60mxEgBXmb6hFNeno6evTogUWLFqnd5+PjAwDo0aMHKleujA0bNsDX1xcymQz16tWTd6/kc3NzUzuGauItx3FqXVWW2McQqvXbsWMHpk6dimXLliEkJAQlS5bEkiVLcP78eZ3HSU9PR+PGjbF161a1+0xJcl66dCl++OEHHD16VCmYM1SzZs1w+vRped0AYP/+/WqJxUKhEABw4MABeR6Ti4sLAMDb2xtJSUlK5fNve3t7azyvk5MTGjZsiAcPHhhdZ0IIIcYxOqDZuXMnpkyZgvDwcAQHB2PlypXyXAJNI0m2bduGr7/+Ghs3bkSLFi1w7949fPLJJ+A4Ti2hsrDkxzOaWmgaNWqEv//+G/7+/hAI1J+uV69eISYmRj7EGID84lkYAgICcODAAaVtFy9eNOlYZ86cQYsWLTB27Fj5NsVkZwBwdnaGVCpV2taoUSPs3LkT5cuXVxppZIrFixdjwYIFOHz4sMYWJENER0fLg886depAKBQiISEBbdq00Vi+cuXKattCQkIwY8YMpdFfR44cQUBAADw9PTUeRyqV4saNG+jatatJ9SaEEGI4o5OCly9fjhEjRmDYsGGoU6cOwsPD4erqio0bN2osf/bsWbRs2RIfffQR/P390alTJwwcOFDvfCK2JsvOQPKjGERHR8v/PX78GOPGjcPr168xcOBAXLx4EbGxsTh8+DCGDRsGqVQKT09PlClTBuvXr8eDBw9w7NgxTJkypdAex6hRo3D37l1MmzYN9+7dw59//ilPMjZ2CHGNGjVw6dIlHD58GPfu3cOsWbPUgiN/f39cv34dMTExSE5ORk5ODgYNGoSyZcuiZ8+eOHXqFOLi4hAZGYnPP/8cT548AQBcuHABtWrVwtOnT7Wef9GiRZg1axY2btwIf39/JCYmIjExUd7KAgDTp0/HkCFD5LdXrlyJf/75Bw8ePMDNmzcxadIkHDt2DOPGjQMAlCxZElOnTsXkyZOxZcsWxMbG4sqVK1i9ejW2bNmitS4fffQRnJ2dMXz4cNy6dQs7d+7Ejz/+qPRaf/vtt/jvv//w8OFDXLlyBR9//DEePXqEzz77zKjnnRBCiPGMCmjEYjEuX76M0NDQggPweAgNDUVUVJTGfVq0aIHLly/LA5iHDx/iwIEDOn+1ZmdnIzU1VemfVXFAdsIN7Js7GA0bNpT/mzdvHnx9fXHmzBlIpVJ06tQJ9evXx6RJk1CqVCnweDzweDzs2LEDly9fRr169TB58mQsWbLEuvXVoUqVKvjrr7/wv//9Dw0aNMC6devko5zyu1QMNWrUKHzwwQcYMGAAgoOD8erVK6XWGgAYMWIEAgIC0KRJE5QrVw5nzpyBq6srTp48iUqVKuGDDz5A7dq1MXz4cGRlZclbbDIzMxETE6M0RF3VunXrIBaL0bdvX/j4+Mj/LV26VF7m+fPnSEhIkN8Wi8X44osvUL9+fbRp0wbXrl3D0aNH0aFDB3mZ+fPnY9asWVi4cCFq166Nzp07Y//+/ahSpYrWunh4eOC///5DXFwcGjdujC+++AKzZ89WmoPmzZs3GDFiBGrXro2uXbsiNTUVZ8+eRZ06dQx/0gkhhJiEY8zw6XGfPXuGChUq4OzZs0rJj1999RVOnDihNbdi1apVmDp1KhhjkEgkGD16NNatW6f1PHPnzsW8efPUtqekpJjdhaHJ/648wZQ/r6F1jbL4fXiwxY9f2BYsWIDw8HA8fvy4sKtCCCGkGElNTYWHh4fVrt+KrD4PTWRkJL7//nv89NNPuHLlCv73v/9h//79Okd9TJ8+HSkpKfJ/1r4Q5/fE2OHKByb56aefcPHiRTx8+BC///47lixZgqFDhxZ2tQghhBCrMSopuGzZsuDz+RpHe2gb6TFr1iwMHjxYnkdQv359ZGRkYOTIkZgxY4bSDK75hEKh0d0j5uDlRTSsiKy3ff/+fXz33Xd4/fo1KlWqhC+++ALTp08v7GoRQgghVmNUC42zszMaN26sNPV8/lT0il1QijIzM9WClvx5V4zo7bIJC4x8tgsrVqzAs2fPkJWVJU/m1TRCixBCCCkqjL7KTZkyBUOHDkWTJk3QrFkzrFy5EhkZGRg2bBgAYMiQIahQoQIWLlwIIHeOluXLl6Nhw4YIDg7GgwcPMGvWLPTo0UNpQrnCVNRaaAghhJDixuiAZsCAAXj58iVmz56NxMREBAUF4dChQ/JF+BISEpRaZGbOnAmO4zBz5kw8ffoU5cqVQ48ePbBgwQLLPQoz5Qc0muahIYQQQoj9M2qUU2Gxdpb0gRvPMXbrFTT198Su0S0sfnxCCCGkOCpSo5wcAa+IjXIihBBCihsKaFAwg66MIhpCCCHEIVFAA91rORFCCCHE/lFAA8VRToQQQghxRBTQQHGmYAppCCGEEEdEAQ0UWmgoniGEEEIcEgU0KGihoaRgQgghxDFRQAPFUU6FXBFCCCGEmIQCGijOQ0MRDSGEEOKIKKAB5dAQQgghjo4CGijOQ0MRDSGEEOKIKKBBQQ4NhTOEEEKIY6KABgWjnHKkssKtCCGEEEJMQgENCnJoHr3KRFaOtJBrQwghhBBjUUCDglFOAHDl0ZvCqwghhBBCTEIBDQq6nABASonBhBBCiMOhgAZAwTgnmlyPEEIIcUQU0ABQHN9EQ7cJIYQQx0MBDQDFwU00WzAhhBDieCigASBV6GcydeR227ZtMWnSJPltf39/rFy5Uuc+HMdhz549pp3QCschhBBCHFWxD2h69OiBScP6yW8rdjmdOnUKHMfh+vXrRh/34sWLGDlypEXqmG/u3LkICgpS2/78+XN06dLFoudyNIwxzJ49Gz4+PnBxcUFoaCju37+vcx+pVIpZs2ahSpUqcHFxQbVq1TB//nylVrq5c+eiVq1acHNzg6enJ0JDQ3H+/Hm1Y+3fvx/BwcFwcXGBp6cnevXqZemHSAghRIdiH9AMHz4cl86cgCQ1GYByl9OmTZvQpEkTNGjQwOjjlitXDq6urharpy7e3t4QCoU2OZe9Wrx4MVatWoXw8HCcP38ebm5uCAsLQ1ZWltZ9Fi1ahHXr1mHNmjW4c+cOFi1ahMWLF2P16tXyMjVr1sSaNWtw48YNnD59Gv7+/ujUqRNevnwpL/P3339j8ODBGDZsGK5du4YzZ87go48+surjJYQQooI5gJSUFAaApaSkWPzYOTk5zLNsOebR+mNWedq/7N9rzxhjjKWlpbESJUqwdevWseTkZPbhhx8yX19f5uLiwurVq8e2bdumdJw2bdqwiRMnym9XrlyZrVixQn773r17rHXr1kwoFLLatWuz//77jwFgu3fvlpf56quvWI0aNZiLiwurUqUKmzlzJhOLxYwxxjZt2sSQm70s/7dp0ybGGFM7zvXr11m7du2YSCRipUuXZiNGjGBpaWny+4cOHcp69uzJlixZwry9vVnp0qXZ2LFj5efSZM6cOSwwMJD9+uuvzM/Pj7m5ubExY8YwiUTCFi1axLy8vFi5cuXYd999p7TfsmXLWL169ZirqyurWLEiGzNmjFJdGGPs1KlTrFWrVkwkErGKFSuyCRMmsPT0dK11USWTyZi3tzdbsmSJfNvbt2+ZUChk27dv17pft27d2Keffqq07YMPPmCDBg3Suk/+e/Ho0aOMsdz3T4UKFdgvv/xicH0JIaS4sOb1W1Wxb6ERCATo+H4/ZNyIAGMMLG/E065duyCVSjFw4EBkZWWhcePG2L9/P27evImRI0di8ODBuHDhgkHnkMlk+OCDD+Ds7Izz588jPDwc06ZNUytXsmRJbN68Gbdv38aPP/6IDRs2YMWKFQCAAQMG4IsvvkDdunXx/PlzPH/+HAMGDFA7RkZGBsLCwuDp6YmLFy9i165dOHr0KMaPH69U7vjx44iNjcXx48exZcsWbN68GZs3b9b5OGJjY3Hw4EEcOnQI27dvx6+//opu3brhyZMnOHHiBBYtWoSZM2cqdcnweDysWrUKt27dwpYtW3Ds2DF89dVXSsfs3Lkz+vTpg+vXr2Pnzp04ffq0Un3nzp0Lf39/rfWKi4tDYmIiQkND5ds8PDwQHByMqKgorfu1aNECERERuHfvHgDg2rVrOH36tNbuO7FYjPXr18PDwwOBgYEAgCtXruDp06fg8Xho2LAhfHx80KVLF9y8eVPnc0kIIcTCrB4yWYC1I7xf951iAJjXwO/Z3uinjDHGWrduzT7++GOt+3Tr1o198cUX8tu6WmgOHz7MBAIBe/r0qfz+gwcPqrWsqFqyZAlr3Lix/HZ+K4kqxeOsX7+eeXp6KrVw7N+/n/F4PJaYmMgYy22hqVy5MpNIJPIy/fr1YwMGDNBalzlz5jBXV1eWmpoq3xYWFsb8/f2ZVCqVbwsICGALFy7Uepxdu3axMmXKyG8PHz6cjRw5UqnMqVOnGI/HY+/evWOMMbZ69WrWvn17rcc8c+YMA8CePXumtL1fv36sf//+WveTSqVs2rRpjOM4JhAIGMdx7Pvvv1crt2/fPubm5sY4jmO+vr7swoUL8vu2b9/OALBKlSqxv/76i126dIkNHDiQlSlThr169UrruQkhpDigFhob86taA8IKtZF+/QgYgAcPHuDUqVMYPnw4gNzk0fnz56N+/fooXbo0SpQogcOHDyMhIcGg49+5cwd+fn7w9fWVbwsJCVErt3PnTrRs2RLe3t4oUaIEZs6cafA5FM8VGBgINzc3+baWLVtCJpMhJiZGvq1u3brg8/ny2z4+Pnjx4oXOY/v7+6NkyZLy215eXqhTpw54PJ7SNsXjHD16FB06dECFChVQsmRJDB48GK9evUJmZiaA3FaRzZs3o0SJEvJ/YWFhkMlkiIuLAwCMHz8eERERRj0Phvjzzz+xdetWbNu2DVeuXMGWLVuwdOlSbNmyRalcu3btEB0djbNnz6Jz587o37+//DHKZLnD4mbMmIE+ffqgcePG2LRpEziOw65duyxeZ0IIIZpRQAOgdY2yKNGgIzLvnUVmeho2bdqEatWqoU2bNgCAJUuW4Mcff8S0adNw/PhxREdHIywsDGKx2GJ1iIqKwqBBg9C1a1f8+++/uHr1KmbMmGHRcyhycnJSus1xnPzibMw+uo4THx+P7t27o0GDBvj7779x+fJlrF27FgDkjys9PR2jRo1CdHS0/N+1a9dw//59VKtWzaDH4u3tDQBISkpS2p6UlCS/T5Mvv/wSX3/9NT788EPUr18fgwcPxuTJk7Fw4UKlcm5ubqhevTqaN2+OX3/9FQKBAL/++iuA3EAQAOrUqSMvLxQKUbVqVaODUUIIIaajgAaAyImP9l17AhwPJw/uwW+//YZPP/0UXN4iT2fOnEHPnj3x8ccfIzAwEFWrVpXnXRiidu3aePz4MZ4/fy7fdu7cOaUyZ8+eReXKlTFjxgw0adIENWrUwKNHj5TKODs7QyrVvRp47dq1ce3aNWRkZMi3nTlzBjweDwEBAQbX2RIuX74MmUyGZcuWoXnz5qhZsyaePXumVKZRo0a4ffs2qlevrvbP2dnZoPNUqVIF3t7eSq04qampOH/+vMaWsHyZmZlKrUsAwOfz9QZ2MpkM2dnZAIDGjRtDKBQqtX7l5OQgPj4elStXNqj+hBBCzEcBTR5nkRvcarXG76sX4vnz5/jkk0/k99WoUQNHjhzB2bNncefOHYwaNUqtNUCX0NBQ1KxZE0OHDsW1a9dw6tQpzJgxQ6lMjRo1kJCQgB07diA2NharVq3C7t27lcr4+/sjLi4O0dHRSE5Oll9UFQ0aNAgikQhDhw7FzZs3cfz4cUyYMAGDBw+Gl5eXcU+KmapXr46cnBysXr0aDx8+xO+//47w8HClMtOmTcPZs2cxfvx4REdH4/79+/jnn3+UkoLXrFmDDh06aD0Px3GYNGkSvvvuO+zduxc3btzAkCFD4OvrqzQfTIcOHbBmzRr57R49emDBggXYv38/4uPjsXv3bixfvhy9e/cGkJtg/c033+DcuXN49OgRLl++jE8//RRPnz5Fv365cxe5u7tj9OjRmDNnDv777z/ExMRgzJgxACAvQwghxPoooFFQokFHpKemICwsTCnfZebMmWjUqBHCwsLQtm1beHt7GzVxGo/Hw+7du/Hu3Ts0a9YMn332GRYsWKBU5v3338fkyZMxfvx4BAUF4ezZs5g1a5ZSmT59+qBz585o164dypUrh+3bt6udy9XVFYcPH8br16/RtGlT9O3bV+1CbiuBgYFYvnw5Fi1ahHr16mHr1q1q3TkNGjTAiRMncO/ePbRu3RoNGzbE7NmzlZ7/5ORkxMbG6jzXV199hQkTJmDkyJFo2rQp0tPTcejQIYhEInmZ2NhYJCcny2+vXr0affv2xdixY1G7dm1MnToVo0aNwvz58wHkttbcvXsXffr0Qc2aNdGjRw+8evUKp06dQt26deXHWbJkCT788EMMHjwYTZs2xaNHj3Ds2DF4enqa9fwRQggxHMeY/S9elJqaCg8PD6SkpMDd3d0q5xj863mcup+MFQMC0bthRaucgxBCCClObHH9zkctNCrsP7wjhBBCiCoKaPLkJwBTQEMIIYQ4Hgpo8nB5/1M8QwghhDgeCmjycJz+MoQQQgixTxTQqHCAHGlCCCGEqKCAJg91ORFCCCGOiwKaPPlJwRTREEIIIY6HApo8BS00FNEQQgghjoYCmjz5DTT3ktIxdutlxCSmFW6FCCGEEGIwQWFXwH7kRjS/no4DAJyNfYXo2Z0Ks0KEEEIIMRC10ORRHbb9NjOncCpCCCGEEKNRQEMIIYQQh0cBTR6aV48QQghxXBTQ5KGZggkhhBDHRQFNHo7aaAghhBCHRQFNHmqhIYQQQhwXBTR5KKAhhBBCHBcFNIQQQghxeBTQ5KEcGkIIIcRxUUCTj+IZQgghxGFRQJOH4hlCCCHEcVFAk4ejrGBCCCHEYVFAk4fCGUIIIcRxUUBDCCGEEIdHAU0e6nEihBBCHBcFNHkoniGEEEIcFwU0eSgpmBBCCHFcFNDkoXCGEEIIcVwU0OSjiIYQQghxWBTQ5KGlDwghhBDHRQENIYQQQhweBTR5KCeYEEIIcVwmBTRr166Fv78/RCIRgoODceHCBZ3l3759i3HjxsHHxwdCoRA1a9bEgQMHTKqwtVA8QwghhDgugbE77Ny5E1OmTEF4eDiCg4OxcuVKhIWFISYmBuXLl1crLxaL0bFjR5QvXx5//fUXKlSogEePHqFUqVKWqL/FUAsNIYQQ4riMDmiWL1+OESNGYNiwYQCA8PBw7N+/Hxs3bsTXX3+tVn7jxo14/fo1zp49CycnJwCAv7+/ebW2AkoKJoQQQhyXUV1OYrEYly9fRmhoaMEBeDyEhoYiKipK4z579+5FSEgIxo0bBy8vL9SrVw/ff/89pFKp1vNkZ2cjNTVV6Z+1yRiz+jkIIYQQYh1GBTTJycmQSqXw8vJS2u7l5YXExESN+zx8+BB//fUXpFIpDhw4gFmzZmHZsmX47rvvtJ5n4cKF8PDwkP/z8/MzppomkcoooCGEEEIcldVHOclkMpQvXx7r169H48aNMWDAAMyYMQPh4eFa95k+fTpSUlLk/x4/fmztakJKLTSEEEKIwzIqh6Zs2bLg8/lISkpS2p6UlARvb2+N+/j4+MDJyQl8Pl++rXbt2khMTIRYLIazs7PaPkKhEEKh0JiqmY1aaAghhBDHZVQLjbOzMxo3boyIiAj5NplMhoiICISEhGjcp2XLlnjw4AFkMpl827179+Dj46MxmCks1EBDCCGEOC6ju5ymTJmCDRs2YMuWLbhz5w7GjBmDjIwM+ainIUOGYPr06fLyY8aMwevXrzFx4kTcu3cP+/fvx/fff49x48ZZ7lFYALXQEEIIIY7L6GHbAwYMwMuXLzF79mwkJiYiKCgIhw4dkicKJyQkgMcriJP8/Pxw+PBhTJ48GQ0aNECFChUwceJETJs2zXKPwgJsmUMjkzFwHMDR5DeEEEKIRXCM2X9nS2pqKjw8PJCSkgJ3d3ernGP45ouIuPtCaVv8D90sfp6sHCk6LDuB+hU8ED64scWPTwghhNgLW1y/8xndQlNUSWzU5RQZ8xJP377D07fvbHI+QgghpDigxSnz2GpiPeplIoQQQiyPApo8tkoKpniGEEIIsTwKaPLQ0geEEEKI46KAJo/CNDlWRSObCCGEEMujgCaPrYZtUzhDCCGEWB4FNHlsNcqJGmgIIYQQy6OAJo+MZgomhBBCHBYFNHlo2DYhhBDiuCigySPg2SbS4CiLhhBCCLE4Cmjy8G0U0FA8QwghhFgeBTR5BHzrPxUpmTkUzxBCCCFWQAFNHk1dTlcT3ljs+D9FPkDgt/9hx4XHFjsmIYQQQnJRQJNHU5fTqoj7Fjv+4kMxAIBDtxItdkxCCCGE5KKAJo+rM7+wq0AIIYQQE1FAk2dmtzqFXQVCCCGEmIgCmjx+pV1RvXwJm56T0YKYhBBCiEVQQKNANYvmeMxLq84gTPEMIYQQYhkU0CjQNIvvyfsvrXY+W81OTAghhBR1FNAo0DSLb1aOzGrno3CGEEIIsQwKaBTYep0laqAhhBBCLIMCmkLEqI2GEEIIsQgKaBRwGptoKCmYEEIIsXcU0Ciw9TpLFNAQQgghlkEBjQKb59BQlxMhhBBiERTQKKCkYEIIIcQxUUCjQNOwbWuieIYQQgixDApoFNi6hYYm1iOEEEIsgwIaBZQUrOzX03HYdCausKtBCCGE6CUo7ArYFQ1NNFYNOuw4oEnJzMH8f28DAPo38YObUP9bRSZjeJicgWrl3LQMgSeEEEKsg1poFNi8hcaOI5psiVT+t0RqWD0XHryD0OUnsPzIPWtVixBCCNGIAhoFts+hse35TGVo4LXhVG731OpjD6xZHUIIIUQNBTQKbJ9DY8cRDfUYEUIIcSAU0Ciwdd6HHYczhBBCiEOhgEYBjXLSzFHqSQghpPiigEYBLX1ACCGEOCYKaBRominYqqO27SyeseucHgeyLjIWv0XFF3Y1CCGkWKGARlExXsvpZVo2QhYew5LDdwHYfhmIouJ5yjssOnQXs/+5BamjDGMjhJAigAIaBXybJwXrv+BliiX48+JjvErPtmpdwk/EIjE1C2uPx1r1PEVdpliqvxAhhBCLo5mCFZQU2fbpMKSFZvY/t/DX5Seo5V0Shya9Vyh1oXYGQggh9o5aaBR4uDjZ9HyGLE558MZzAMDdxDRrV4cQQghxWBTQKHC3cUBjTzk0xDLoNSWEkMJBAY0CAZ8SYfMpphPR6CfT0PNGCCG2QwGNAp6tk4LpekcIIYRYBAU0CmQ2HmarbZTT8v9isPlMnF3UhZiOnlFCCLEdCmgURD18pbbNmq0omuKnhy/TserYA8zdd1vrfrEv09Fz7RkcvZ1kvcopoAszIYQQe0cBjQJDRh1ZkmqOxcl7Lw2aB2bijqu49vgtPvvtkrWqRiyAuhQJIcR2aB4aBbaeHVf1ejdk4wWD9nubmWPwOV5niLHv2jP0DPJFKVdng/ej9GhCCCGOhAIaBTZfnNIGv+BH/HYJlx+9wdE7Sfh9eLD1T0gIIYQUAupyKkS2GNZ7+dEbAMCp+8lWPxdRRonWhBBiO8U7oNn/BfBLR+BJ4eSi2NPlTrW7jVNorqJcEEIIIfaueAc0SbeAJxeAlCcAbJ83oi9QsOUwctXWBJoUznz0FBJCiO0U74DGxTP3/3dvtBaxZreBvmPP2XvLaucmhBBCihIKaACdAY0u8ckZyBRLTD69vl/wv597ZPKxCSGEkOKkeAc0wpK5/2fnrWStYZiTtqHc15+8Rdulkeiw7ITJp7f1vDfGYEp/2289CSGEEKC4BzT8vHlZpGIAmnNotF3MD91MBAA8T8ky+fSmxjO2Hl5O8QwhhBB7RwENIA9ojGHzoIIYhTGGo7eT8Oztu0KsQ6GdmhBCip3iPbGeQJj7vwkBjSXY8wVPsW52XE2t9t94jvHbrgIA4n/oVsi1IYQQYm3FvIXGKfd/ifEBDc8CTTSWyKH55dRD9Fx7BqlZhi+HUByceaC+0KitUe4RIYTYTjEPaJRbaDTFKNpiDkv0OBlyueP0BE7f7b+Da4/f4pdTcRaoUQHFi7E9tyQR49x8moLRv19GXHJGYVeFEEIsqnh3OeW30Eizjd/XAi00lpy8LlsitdixVFFLgzHsOxDsvvo0AOBeUhqOTW1buJUhhBALKt4tNPIcmtzuGk0hCscBF+Nfo+UPx3D0dlLBdguc3pLXO1uvFE4cW/wraqEhhBQtxTugye9ykmhvoRFLZBj0y3k8ffsOn/1WsOZTwutMs09vj7/g5RSTgu25noQQQghMDGjWrl0Lf39/iEQiBAcH48KFCwbtt2PHDnAch169eplyWsuTdznltdBo6Eaa8uc1iCUypW3Rj99i99WnZp/ekl1ONIzc/lAcSAghtmN0QLNz505MmTIFc+bMwZUrVxAYGIiwsDC8ePFC537x8fGYOnUqWrdubXJlLU7e5WRcDs3Bm88tcnpDLniGBj3WjGfowkwIIcTeGR3QLF++HCNGjMCwYcNQp04dhIeHw9XVFRs3btS6j1QqxaBBgzBv3jxUrVpV7zmys7ORmpqq9M8qVCbWq+Vd0jrn0aIwunISU7IMCpKUlj6gPieT2PPzpm/0HCGEOBqjAhqxWIzLly8jNDS04AA8HkJDQxEVFaV1v2+//Rbly5fH8OHDDTrPwoUL4eHhIf/n5+dnTDUNlx/Q5M1DM7ZddY3FVL/7t59PsMjpDbngabrwaEoANuT6FH4iFs0XRmBVxAOD6ufIZDL7DSYIIYRYnlEBTXJyMqRSKby8vJS2e3l5ITExUeM+p0+fxq+//ooNGzYYfJ7p06cjJSVF/u/x48fGVNNwKi00Lk58jcVUY4XULNNX2FZkyWuuIaOcfjh4FwCw4ug9o45txw0NGh29nYSdl6z0njGCgz1thBDi0Kw6D01aWhoGDx6MDRs2oGzZsgbvJxQKIRQKrVizPAL9i1Nakz3P72JPQQxjDLEv01G5jBuc+PpjcMXRaMWRTMbA4+l+N1OHEyGkqDEqoClbtiz4fD6SkpKUticlJcHb21utfGxsLOLj49GjRw/5Npksd8SQQCBATEwMqlWrZkq9LUPe5aQ7KZjjOOtc4S3ZQlOEr1B7op9i8s5raF2jLH4fHlzY1bFrOy4k4PsDd7D502ZoVMmzsKtDCCE2Y1SXk7OzMxo3boyIiAj5NplMhoiICISEhKiVr1WrFm7cuIHo6Gj5v/fffx/t2rVDdHS09XJjDGXA0geqLsS9ttjp7agRRC1es6elDzaejgcAnLqfbJPzyWQMM/fcwJ8Xzeu2Kozn7ev/3UBqlgQT8hbmJISQ4sLoLqcpU6Zg6NChaNKkCZo1a4aVK1ciIyMDw4YNAwAMGTIEFSpUwMKFCyESiVCvXj2l/UuVKgUAatsLhXwemvwuJ/0RTf+ftSc/G8sSi1PmK8INNDZ39E4S/jiXACAB/ZsWctBtoqLcYkcIIZoYHdAMGDAAL1++xOzZs5GYmIigoCAcOnRIniickJAAHs9BJiAWKLfQaIsKrDX81qKHteIVzJ5zfQzxJkMMTzdng8u/fWf6yuVKr2khPm2F3apGCCG2ZlJS8Pjx4zF+/HiN90VGRurcd/Pmzaac0jryc2hkEkAm01rM1GtDcno2SggFEGkZPVWY1xyxRAZngfbAsyhdEI/eSUK/Joa3tBSHxg1qwSGEFDUO0pRiJXyFX+1SsdYveVMu7k/fvkOT746i/dJIrWUsuvSBkeWN6Tor7ODG1hdfmnSOEEIcT/EOaAQKQ8Ol2Rb9ZR4Zk7sUxLOULK1lrNnjJJMx3E9K01om+vFbpft26kiAZQAuxb/GZ1suIuGV+Yty2pqxz7Ol3geO3lVHiKNIz5ag59oz+Cmy6E8aSrQr3gENz6ngb2mORX+Z8ww41pM373DrWYrFzqlo3r5b6LjipEF1ep7yDu9ypPLbcckZapfivuFROHrnBcZvv2LpqupV2C1ExqDGHUJs7/eoR7j2+C0WH4op7KqQQlTMAxpeQVAj0d6SYtKhDbiwzdpzE91WncbzlHdGdT9pumiqjtDaEvXI4DqlvlOe+fj0A+Xh0Yp1e/LmnYG1dFzmBCWKLyNjwL2kNPx7/Zn5lSKEaJUtkeovRIq84h3QAIDIPff/rFSLdjkZ09rz6FWmUa0QprZYaKuTMRdwQ4u+t/g4Np6OM/zA1mTk82XJVpZOK05i/LarOHX/peUOagGGTFFACCGOhAIal7zZVN+9seiFzJhDuTrzzc62MKTu2lpoVDdn50ghlhSM+jKlbgmvM/Htv7dN2LPoUHze7jy3/Irx2RIpXqXrnuU6K0eKqNhXkEiVR/FRfg8hpKihgEYxoLHgr1ZjWmi0LYqp/dgathmwn2oOTXq2ROPxvtt/B+0URmc5Ug6LJVij9cIax2y3JBKNvzuKp2+1dwOO3XoFAzecw48R9y1+fkIIsScU0CgENJaQmJKFX0/HIVNs+IrcPB5ntcn7lM6jErlM2Jaf4Gv4xbYwkl4VWxPSsyVYePAObjwxPJna2NYIazxGaxwzfwTdyXvau7OO3c0dbbflbLxyfajLiRBSxFBAkx/QZL01+aKjGIz0DT+L+f/exux/bsm39Vx7Ruf+Zx8km90BsOzIPb1lVLucjsfkXgj1P277aaJZejgGP594iB5rThd2VfSyRZBKCCEkFwU0olK5/5vRQiNTuG5pGgV0TWXOF1Wz/rmFuOQMjffldwtZAk9DEs3j15k656BRlZwuxlmFUVAJrzKx8MAdJKVadpSYNncTjc9FsYe4wpqT9Zn0+KiBhhBSxJi09EGRYoGkYBlj4Jt5hXj4Mt2s/Q2hqYatFx/Xu5/qBfOjX84jenZHlHJ1Rr+fzyIpNRsX4/WvQh6fnAFvD5HWpSDshaWCD8Wnze7iBzsI8gghxJKohcYCOTT20AJgCFMv1Joe3pvM3AUck1JzR9lcSXir8xjnHr5C26WR6KWn+00TxWW2zj3UHziZy5zgQ9tbgSbcI4QQ66KAxgKjnCwxBNYWQdHrDLH1T6LF7itPAQB3E9P0lFTZ7+oT3DZzyHNhxZuKr6mt4xm9+TsUYBFCihgKaCzQ5cRYbi6KOescyey4lccSwZbUxINM3nnN/JPrcPNpitpcLpaaKVj5mMYddNv5BHRbdQovDMhNojllCCGEcmhUWmhMI5bKDMpF0cWYi5I9/Lg2tg4yO+yXu/b4LXquPQMnPof7C7rKt1tjSLMhS2Eo+mb3DQDAD4fuYnn/IIvXxx7eQ4QQYknUQiMPaN6afIj0LMuNRDKErUMDi7QAFGI8oy2WOp63InqOVLmAWS00Cg9U6Xkz8aBZOdZZo8b+wkv7c/tZKmbsvoEXabYZwUcIMQ8FNPkBTXYqOGbaxcMSrQ922IAhZ4m62aqF5uZTwyfcy8qRadyuGHo4wlwyM3bf1DlbMDFN11WnsPV8Aqbuul7YVSGEGIACGpGH/E8uy/CLoSJLXPOMOYS9dBcYc7G3RY7Qi9QsdF9t+IR7hqzQa+xrG6OY9Kywr7FdTsaa9pfyRfdZShYO3XyuqSoA7Oc95AhiTJj7iNgWzXxNAMqhAfgCQOgBZKeAe/eq0Kphzy0Bmqr2ze4bBi24OG/fLQxrUcWkFpp7ScaNiIrXkpStrctMWwuN8r6GO/fwFSbuiNZ4n7W/cJM1LFI5+o8rGkoSQkjRRC00AOBWJvf/jGTd5bSw41jEas7GvpLPRaPLpjPxGLjhnEk5G11/PGXCXobL1pKfopjuYkwgdvDGc6XbShPr6YhnklKzILPxMDeaF8dwxfHzTYgjooAGAFzLAgC4TNNaaIp8Do2ZKaRP374z6YItsdBFXttzm6P1+AVXe0u9LtrihyO3kxD8fQQm7oy2zIkMZK/vtxdpWdh37RlypPpbzwghRBEFNADglhvQINO0FhqLBDR2PO7EUZKCtbU6aDuztm4+xeNY6nXRVrc1xx8AAPZde2aR8zi67qtOY8L2q1h/8mFhV4UY4WxsMsZtu0IjwkihooAGAFzzu5xMbaExvwr2+ovZUgrz8T19886gBGBNzKm38kzB9tXHY69dTi/ScnOBjtxOKuSaEGN8tOE89l9/jjn/3CrsqpBijAIawD5aaIp4QFOYMyGHn4hFq0XHkfJOOedHf4eTBV8XKwcQRe39Y89J8kQ7mj6AFCYKaAB5Do2pScGW6XIq2gr7AvUyLRuB8/4zKJdHcZkCc15bxe4qU+MZe2vZsZWi/nkghFgeBTQA4FYu9/+MFybtLrXnhZgswFFyaAyRZsCszkotNBY6r+krnRtWA2vnYF1+9Bp/Xnxs9nEM/azYy/uFEOI4KKABAHff3P9Tnpi0u8wCAzIM+QI3NQ/EXBZZTVzldkpmDo7HvIDEgqNZDAkZRv5+SXul8o+jmBSs4XVJy8rB5UdvlO7T9DgUd7X2xHrWvv73WReFr/6+jqhY0+dq2nvtGQJmHsShm4l6y1I8QwgxFgU0AFDKL/f/lCfgYPwF1iK/Jg04ROP5R20+X4mlqF7PB6yPwrBNF/Hr6Tib1uN83Gv534YEapqe7p5rzqDPurPYmzcy6ejtJNSYeRB/XVYOiA2dh0YXQ7uc7r9Il9fHEFk5MvwU+cDo+sQlZxi9T77Pt1+FRMYw+o/Less66Nvcph68SMPEHVfx4EV6YVeFELtAAQ0AuFcAOB4gFaMsjF/+QGqBgOaJAcl06dkSPH37TuuMuNZijV/Ld/OWCNgTbd5wZbHE8vOVcHr6nB7mXdT/yav7Z79dAmNAhli5Be1lWsHsvbbIhfl8+1Wjyi8+FGPxOvx49D7aL4vEmwyxWccp7JwrR/Dh+nP4J/oZPlx/rrCrQohdoIAGAPhOQEkfAEBFzvjEYEu0mqyKuG9QudaLj5t9LmNZogXqUvwbjdvNuXDdeZ6K2rMPYelh0y7M2k6tGHyY89h7rT1TcEwHzO1ljOHkvZd4kWr43CIrjt7Dw5cZ+NnMeWQontEvOV2c97/6sheFxQHf5qQIoYAmX6lKAIAKJgQ0RT0p+KABOQ/6pGXrT8Y11sKDdyGVMfnkdNYIGor2K6vbwZuJGLLxAlqZEEQbkxuVlSPFsbtJyBQXvEfsaaJJ+6kJIUQXWpwyn4cfgCjTApoi/nMywYpdXOY8dVliKyVJ60kKNuQ+tUM6YBNNZEzuqD9TuvWMeVnn/HMLOy89Rsc6XvJtRfw3AiHECiigyZeXGGxKQFPE4xmrDqE155f4Oy2LSxp8bgNObciFleP0H8vxwhnNDB5GbsTLuvNS7nBwxdmBtQWLZx4kgzGgVY2yhp/ASJvOxEHAp8ZrQhwNBTT5PHIDGj/O+LloinqXkzUfnlktNGYGNIpypDI45V/EFOpkyAWcg/4WCXMbaG4+TUEJoQD+Zd3MO5AR9L02N56kgOOAehU81O4zNwjWtHtWjhSDfjkPALg1LwxuQst/fb3OEGPevtsWPy4hxProZ0g+7wYAgMa8++AZOXTb3rqcLD2025ojTsw5cpYF5+UZozCUWDGI0fXQ8+8ypDvJnFFOSalZ6L76NNoujTT5GIb6dt9tfLg+Sm8OTKZYgh5rTqP76tNmzY80Y/cNjds1Pe2ZCl2MmVbqbjS31Y8UffHJGVhz7D7SsnL0FyY2RS00+XyDAKEH3LNTUItLwG3mb/Cu9jI3DGMMjAEn77+07HEtejRl5vySV5/Q0PCg4drjtzh0qyDZ+egdzS1zOgMaZvhZzZlYL/al7eYZ2Xgmd16gUw+SdbYqpb4rSOB9J5ZCKOAr3W9oELz1fILG7baYKVgskcFZQL/piHHCVp5EtkSGR68ysaRfYGFXhyigT3M+Hh/wzX1z1uPF4ZchTeDp6mTQrvYybHLQL+fR+ceTeJVu3hwgqqzapabh0NsvJOD3qHjrnRNAT4Uh1aqYsV1OBgQr5nQ5FUYDoFTKNJ5XHsRx6tsUmfuW0XRMS+YhxSdnoObMg/gmr4Vo6/lHmLTjqlV/nNDcOkVDdl6S/MX413pKElujFhpFPoFA3EnU5+LA4xk+MmXa35qbzW3tbN609PuumzdZnSprfg2rHjsrR4rp/zPs+bTWyr6K1x2DkoINyqLJnWjv+N0X6BHoCxdnvtr9J+69xNtMMXoGVVDafv2J8ZM9WptSQKPhfnOHXWtqobHk+zD8RCwAYNv5BHzfuz5m7L4JAKjhVdKCZykglTH0WXcW5UsKsX5IE6ucg5DijgIaRT5BAID6vDg4cuwdGWPhLidr5tCoHFti4i9kSyQI33yagurlSyht0zlsO/8Pg1poOAxYH4WHLzMQ/eQtvu9dX63M0I0XAAAN/Tzl247cTsL+G8/1n8BG8gMZxZwgTc+RuW8ZvaPGNDzndxNT8U4sRcNKnup3GkjT4qWWePvfTUxF9OO35h+I2A1LfCtuORuP8BOx2PpZMKqWK6F/ByMdvZ2EciWFCPQrZfFj2yPqclLkk9vlFMSLhSjT/MnkigrrDttWZmq3wtd/Xze4rLaZb7uvPo3hWy4q1cmQh25InTkAD1/mLplwWM9EhckZBV2YYgsu3qmJscGqpuKpmoIAUyskP4/uI2i6u/PKU+j901kkGTGzsa1QbxPRZM7eW3iekoU5e29Z/NgPX6bjs98u6exeL2oooFFUupr8z2px2wqxIvbFEquJa2OpL/o90c+w6OBdg8puu6A5ERUAzjx4pXQxNSigMTIK0zvE27jDmaXJd0dxSksSua56Kj7mdksjseSw8nNvbqueOXvfemZ/XXSWZu5kl68zxNZpeTXyw/A6Q4zEFPMD0MIYaWrJz6lEavn6P3ljnS55e0YBjSIeD4le7wEAvDjNaw8VR7YYcZLPnDNdMDBJz5gh1LpyQfIvCIYcL0NhWn99z6ctZxV+lSHG4F8vGFxePlRdZfva47HK5cx8y+h/jrTfl5xmelK8OaPRbCXiThLeW2L6mm77rz9Ho/lHMP/fOxaslWkazT+C5gsjkGrGEOgpO6MNXguvOOE7wpvZwiigUeHdeljuH8+uUjtxnvNx1ssoUg0YktMKf8SYYo3aLInE7+ceaS37JkNs0Nwlk3dek/+tbyRNYX0NqdbLnHpYI4fG0BYFa/1af5WebZXV3Y21JUr7+9EQ3x/IDWTyh+ib6reoeHz11zWLjAwzp8Xpf1efmn3+osgBV1sxGwU0qqq1BwQuQPI9tEB0YdemyFO89uy79swmk8fp+6CrXg9n7bmptWz4yVit92k9vq6TAfj41/NGH9O4k6r7LSoeI3+/JL996dEb7NZxodB3CTO3VU/fNVLXS2jOqbW9Nx6/zkTj746i44oTph88j6MO336TIcaZB8nyAGb2P7fw56UniLxn/OzqRYG9v4r8YhjRUECjyqUUUOd9AEBDlvtLRggxuvOiUBK6f0WURipWOK3FWP4e+HFJOssWZ9pyVH4wMAfGXPo/5oavV5SdY8Ivdj2H1zTSRtHzlHeY84/2IMsUs/+5pTS5YPiJWJNHnAGW+LJnSMnMQeeVJ/FT5AOjjm+puYMUHb2T+3l+ZGJLgrYY5m2mGDGJaSYd05IMme25y4+nMOiX82rTQuh7v5LCodjlZC+Tv1obBTSa+DUDAAxn/4MXXmOD0zKscV6NyYK/tO5SBinYJ5yB3vwz+MrpT5wSTkYdLt5GFXYsShPXOciv1U83X9T4pSByUp9PRh+lo5jwK2rMH1fM7nYwl76XzfwcGmDDqYe4m5iGxYdijNo3/9zLj9zDxB1XjVsVXUu4a+71QHH2bsXqNF1wFGErT5qdyGzOBWvj6TgEzDyktDioJol5o8eO3S2eLTLWZO68TZooBjTm/DhxJBTQaFKjk/zP86LxeI+fO9Hbp4JDiBaOQCfeRaXiXwu247JoDCpwr5S2HxB+g9JItX59HYziR8uWCbAF59R9v6br37G7L3D1sXKi+OkHyfIJ2oyRni3BATPmlrn+5K3J+5ot78lZe1y91USpmJlf0IwxnUPWVV9C5Va/3L9XRdzHP9HPcCXB/AR/cwPvJYc1B2U5eaNbTt9PNuv4TRYcxY9HTUuM/fbf3MU4J++MNqh8CQstCuooP2YclWJAU9QXUM5HAY0mpSoB7hU138VlYL3zCsQKB8EZOajIvcRowT6lMvNzBsn/HqVyH9GeX2EvXb7aPvrZFkwIHbv1isn78kx8os4+MO+iCQC3n6eh88qT2Hw2Xme57BwZ+oWfxVItF3J9NH3/6uxm0nGnMa+btkDMktdeTYcy5iXVFAi8zhBjxdF7plfKCCVENB8rUHjJ+4ZS/J6wtwWUrYXemdqMjMTppf3QClcBABlMCDeuYAQOn2OYK9iM7vxz8m3HpEGYljMSL1EKnlw6xgv+wSjBfgTxYnFS2gBHZI1xj/nZ/KHYG8WApjCCGFNbhaw5H48xcr+ojPuCSsuW4KNfzE823q5jDh9F+bMbX4x/g6lhAWafV58chRfHnK/u+0maFgJlSpMdGuNeUppF5lmxBUNbTFQXIjX9fBY5TKGx9+orBTRWmOfGHlFAo02JchiL6UjNkoAPKaTgwwVZGC34FxMF/wMAfCQomAviy5yR2CVtK7+9VNIf/fgn4MW9RTDvLoJ5d/El/kSf7Dm4zKz/BW/PFL/IFGMLu2mh0fLZt5dfOfbyPFmbQctO5Omz7qz8b3PySf7TkEeSnC7GzycemnS8TitOqm3LfVyO+yLqqrnifWlZOdh2PgFd6/vAr7SrWln7+DTZB1O+Wo7cTkLEnSTMfb+uxlw+pS4nO/nusjbqctIh/z0gRe6b5R1EWCHpiy7ZC5XKrZH0VApmcnH4QxKqdsyufMMnMSuqrimsaWPMJHe2oq3bwV5GCpja5WRtaUZMjrbv2jM807G4qGowc/nRa51f+jefFuSqqS+nYZ/PlyJHqGM+Q99+c/65hYUH72qdep9yaMwz4rdL2HHxMbZo6f5VfJ0k9tK8bGUU0OigLdfjDquMWTmfAADeMWdskHTTWG6ttBc+F4/DcPEX8m1tedHwcuilL803dFNBUJfwOtNuAgV97CWxzl4nAM0yYgj7hO1X0XZJpMHlT99/pRRo6roW2vt10twcmsJm6PN7Oi9n63WG/pmb152IxeVHtp2d/W5iql2u+2WspFTN3aGKr1MxiWcooNFF1/Xrd2knNMlah1bZPyIFmldJlYGHvbKWiJA1RrvsZZAxDtV4z3FeNB5tedHWqbQDUL3wfbjhHMJWnMTj17ZZe8SUUU6A/TTb2msLjbGMWXgzNStHKRLQuSSFOZWyAU1vowcv0s2a/t8Yln77aFtFXN/roHj//uvP0WfdWaS8s81z8Ph1JjqvPIXg7yMMKp+VI1VrUbLkkjDWeM8qfkaohYbovYAlwwOv4GHQseKYD9ZLu8tvb3ZebFbdipILca8Rk1T4k4vl09YSYw8tNIwxh/o1bympRlzoDOvKKNwn8caTFPzvyhP57R0XH6PlwmM2Obe2p8fQd7fq++/vy080FzShHg9e2OZ74OZTw+f9efQqA7VmHcLEHdFK2x+/focdBibJFzZ7+O6yBQpodLB0H+9ySV+8ZgWtOS5w/OZOR6QvX2GSlvk4LL1IJ2PMpP6Rwpi7xxCWrpbiUyNlKm0yOp62N5liZBmwvpapbj1LwaYzcSZfJBgYeqw5jSl/XlPanpZt2Iy7dtJQKKetOnonXyzEtjRj3qtbzuZOYrn32jO1+77+3w1LVclkhkw1UEziGQpodLH0m0AMJzTK/ll+uwZHi6o5Ekv/yhm66SKuPTFuhljG7DeHxqpUYj9dr8Ta47Foo7Aa9dXHbxCXnAEAkEhlyBSbN1V/t1WnMW/fbfx1+bFZxyks2i7mJgdKWvfTfUDNC5CaWIdClPAqEwN+jsLxGPuaQdkRZ2Q3FwU0Olj6F3kuDudltQAAe4WzqJWmEJjakmDp98PJey/1F9KgqOTQGIPBuF/0iomSiw/FoN3SSABAjzVnUGf2YaO6sLS5/cy0WcB1vY0KdRZoAiA3X+aNlkTmcw9fqW2buusazse9xrBNFzXsYTkZWlrwDBkhVzzCGQpodLJWUHtZVlP+95eCP+V/C5A75w2xrhwTZ/w1IofVahjst8vJ0hQfpuovTFM+mxKpDHee5wYhpxVmTTZ14jtrvA6RMfqDXEt21XSywOrh2qi+RtkSKYZvvohfT8dZ7ZyqJFo/tMqv3YvULHn+TuvFx9Fw/hG8SFN/X3y4/pzaNsVJF9cef4DYl5omZzTPiiP3UHfOYRzXsI6W1i4nA0cFFiUU0BSCdZL3kc1y5zT8VHAIUcLx6MePxAPREFwSjkEpmJ8Yx4cUgdwDcMj9QAsgwUj+PgRwjpHEZk08E/ts7GV4eXHoclJ9phnM/1Keu++W/G/F7sPmCw0b6aJq89l4iw/7tfVLe09hZmRTAyWtOTQqt/dcfYqIuy8wP2/tKI1dTkae+8EL7cHD1YQ3qDP7MH45pX9SxGbfRyB0+Uk8e/sOL9NyA5TzD42fXmPJ4Rh0WGb5IPHHiNx1umb9c9PEI9jHd5e1UUBTCNLgioDsLUiQlQMA+HCvscRpPQDAk0vHd06bTDpuWaRgNH8vIpy/QKxoMP4Rzkac6GN0453DaP4+fOO0HXudZ6G4vLm1eSd23FYwxpjddjlZ+legcg6A8rvWlIvvH+cKgnlLDWM1Z00uU+mq+ozdN9B55UmdSdGF9fZJz1auk6bX0Nj30Jg/Lmu97+u/b0AsleG7/XcMPl6LHwpGmuU/T/qeL4s8nQY+bmeB4Zds1c9PcUABTaHhMDZnosZ7uvPPYQL/f3qP8DH/CHY6f4tq3FNwkOEf4Ux87bQD1XjKKzmvdV6FqU67AABCLgfdeedQkTMtf6MoWKNnpWh7Nv1/N5Bu4GgYW7PmqJXcFhrLNaFbKsFbdTK4G09SsOLIPZ0BhTl1P3QzEVEa8jjybT2fgLuJaTiiYQkHfec3tV6Kr4uubkJzaTqeqS1khgR1hs7erKnr0Zhh4YDhnx1nvmmX7GISz1BAo8vmYU1RUmi95a5usqqok7UR8TIvyBiHseLP5fd94fQXXLUkDLsjHcP4B/Gd0yYE8+4iQvgl4kQfowKn/YtO0Rrn1TgtnIgR/H8RxD1Ad14Uis9b3gx20DCy6/ITuw1orPkWsnRCtsRK3Yc91pzGjxH38VNkrFWOP1pHi4Quf11+gqm7runIKbE9Q1/Sfdee4YOfzqDFD8cwdqtpj98UhrZkaSrWffVpHLubhGyJZVuDk1KzEJ83Ys8YxaWFhhan1KFtQHlcm9MJVb85YLVzZEKE9uJlcIIE2XDGdskNDMxb9HK8YA8WSz6Ul10g+BWDBBF4yspoDV5iZBURJi6YtK8c3mK44ACesHJ4yTzws/NK+X0znLbJ/16D1ViU8yHWSd8HAHCQYYnTeuQwPqZLPoNdXM2JXdMWIyzYfxszutUx7+BGDNs26HBW/oK/+1z7CChbzL+iejGeuit3zpsW1cpoH7Zt4Tqo5UGpJnYbeJwJ26/K/35+I9GkY5jC3G+8TzdfQqBfKewZ28JiCeRvMnPQdmkk7nzbWW9Z5c9L8YhoTGqhWbt2Lfz9/SESiRAcHIwLF7QvuLhhwwa0bt0anp6e8PT0RGhoqM7y9sbUBFJjyMBDNpwBAHMlQ3FNVhUAMFawF/85f4nB/P+w13kGBglykxe1BTPnZbXwvvg7pW0vUQo/SD7CH9KOiJLpvqhMc9qBEN4t9OCdxWD+EfTln8RAwXH4FPO1p/JRSKebti/NDafi8ORNpkWPbe/zajAAr9I1r7Gjy6n7yTh2V3t3kaG0dZe8zTR/uLqhXTF6J9bTUMDar+u9pDT8ce6RRc9zX0di8rXHb5Gcrn8tK11yNLSqKS6ToSsxOp+df1wsxugWmp07d2LKlCkIDw9HcHAwVq5cibCwMMTExKB8+fJq5SMjIzFw4EC0aNECIpEIixYtQqdOnXDr1i1UqFDBIg+iKMmGMybmjEOkMHdBy5q8p5jP26y1/GDx12jPu4qfJD3xEqV0HjsVJRCYtR4S8FGVe459wplqZbY7L1DbttP5W3QUL5EHXYRooutL89ErIwMa1SRgBpy8r573lZyeje8PGJ70aUvdVp3WuF3X83Qh/jUubH6N63M7wV3kZPK5tTUIGNJQEH4iFq/Ss7W2qqkGlxkmJtlrehqMve7qejiaHmunFScBAO0Cysm3/ROteYJTeVKwkXVSZW6+VraGaSYU63TqfrLa/YD6sO3ox29RtZybWe8re2d0C83y5csxYsQIDBs2DHXq1EF4eDhcXV2xceNGjeW3bt2KsWPHIigoCLVq1cIvv/wCmUyGiAjtQyWzs7ORmpqq9K84iWc+2CZpp7b9X2lzdM7+AePFE9Ay60fUzNqCU7IGmCcZqjeYyZeCEsiAC26wqlgj6Yn90mZKq4FrUon3EjGiTzBNsF3P0RlqcQngwX766Ynt6PraNnciO8aAGbtvKt0GgDn/3ML/rtjnjNuJWhJWDbm8aZtEzVAmXYTzKvbDwbvYcCoOPdeeQYKxgaji4WzQLGDqGa4rzNCtukZTAcu0yRrS3aN79Xj1OzUFObqO+d/tRPRaewZdVp7Su58jM6qFRiwW4/Lly5g+fbp8G4/HQ2hoKKKiogw6RmZmJnJyclC6dGmtZRYuXIh58+YZU7Ui5xvJZ/hd2gn+XCJa8G7hCSuHn6XdAXC4yypZ5BxLJQPkf/tnbcM14Wfw4DLxs6QbPJCBlZI++Fc4A2W53IByjGAfxgj2AQA2ScIwXzIYffknEMg9xAtWCkG8B2jHv4Y5OUOxRRpmdH2qc0/wn/M0PEMZTM/5DNdlVSEDD2lwVSjFUFidP8VlQjtT6Zqnx9hEZrFUhmMaJhFT9dCEBElbKOxRWLreqtq6jFQvvNcev8WnWy7i6JQ2Bu2vfjw99xdiN4gjfZQ1PU2fbblk1DH+vZ478vXp23cWqJH9MiqgSU5OhlQqhZeXl9J2Ly8v3L1716BjTJs2Db6+vggNDdVaZvr06ZgyZYr8dmpqKvz8/IypahHA4Q6rjDusMg7Kgm1yxsDsX9S2tc9eiqH8//CF019K24cJDmOY4LDG48xz2oJ5TlsAAP9KgzEhZwKYnsbAKtxzHBV+BQCoiGT87vyD/L4bMn98Jp4KNy4Lh52nwYmT4qbMH/3Fs5EJkVGPkRQOYy9e2RKZfP0lQP1i++hVJm49S7XjXBrt9TKkzmuOPcAPfRqYcX7NV2xd1/EcKVMLSjXlZ1x69BqzTZjgTe1hW2AtJ2vGJZYKesx9izINjTExSfonX1U8rb1MCmptNh3l9MMPP2DHjh2IjIyESKT9QiQUCiEUCm1YM6JNKkpgtfQD7JOFoD//BMYK9hq1f3f+eXTnn8c9WQUskHyMVOaKZU7rUJWXO1rhU/FUnJAF4rhQe7dXfV48zovGK22rx4vHbdGnyGJOaJq9DvV4cWjG3UW4tAfl+hQSa8YWqsf++Nfz1juZCR68SENUrGHTJhhix8XHZgU02nNodF+lDWnxOnU/WWvehhId7weJVKZ5Yj0jO5GMKW3sCuz5z5S5gY3ZI/JMncFZ4UMjtdvA37KMCmjKli0LPp+PpCTlLPykpCR4e3vr3Hfp0qX44YcfcPToUTRoYM4vD1IY4pkPFks+xDJJP1TmklCXi8c8p81g4NBL/C068S4hEyJ0551DS/4ttf1r8p5ii/Mite0bnZcq3f5D0gHbpe2x1CkcAFCbp3tFYxGXgxuiz+S3Jzv9jeuyKrgtq4xZkk+RQzMT2Iw1h4bGv7LPrqV8octPGlzWFpcWS7dcGNoSpnheXXv8eekJGlT0MKtOxjp487n+Qgos1cVsyHOnq4QlYhHrLLRsf4z6tnd2dkbjxo0RERGBXr16AYA8wXf8+PFa91u8eDEWLFiAw4cPo0mTJmZVmBQuKfh4yHzxkPniUHYzSMADAw+/SrsBAPZKW6Cm5Al8uVdowIvFKMF+g4+9R9oCsyXDIAMPXcS5wU997iFGCPbjfX5ujtZtWWX0Fs/DCP5++ezHqhrw4tCAF4d45o3wvHl1LIGD8bkgxYnOxEYzL+OKaw45gsK+fmhbHkP/NVpzxS39eB69ysDOS7p/rGjDGDMp2MiRGPcgClpozAtszO5yssB+Flrpw+4ZPcppypQp2LBhA7Zs2YI7d+5gzJgxyMjIwLBhwwAAQ4YMUUoaXrRoEWbNmoWNGzfC398fiYmJSExMRHq6Y31BEXU5EKjlxmTABVdZDeyXNcdCySD4Z22Df9Y2BGatR4ysIgBgpeQD+GdtwzDxl0r7zs0ZCpnK8W6wqvg8Z4L8OF3FC5ENZ6yR9oZ/1jaMEk/GKWk9/ClpgyymPBwxlG/ZdXYyxRI0mKs5b4jo/hVYTLrw5XTNRByTaP7is/pYOunVlJdPfSI9hWHEAFIyNczPYsCJFA9r6MPMkcqMbqWwl8RhS+SJ2W+umWUZ3R4/YMAAvHz5ErNnz0ZiYiKCgoJw6NAheaJwQkICeLyCi9K6desgFovRt29fpePMmTMHc+fONa/2dmppv0D5zJwkVwpKYIj4a7Tg3cI/spYAgOOyhgjOWoO3KGFy3sthWVMcljUFAEyXfIaySEEpLh2HhV+jCe8emnJ3cZHVsshjuP08tdhdmI1BT02BE/e0r5X29+UnVj+/1hwaq5+5gN5RTibsY2r55t9H4PMONYw8uu3oCjhMbqFR2LG4fG+ZlGAwfvx4rV1MkZGRSrfj4+NNOYVDc3HiF3YV7FISSmO3rLXaNkuRgo8klEYSK41YmQ+q8Z5jhtMf6KUye7Kprjx6a5HjFFXF5Eeg2Yx5nm48ScG7HCmaVTHuc2Lo0GpV2heutEQrgfLxTF4M04R9XmWIlUbNGcJSE+sxljtrdKZYCr/Srvp3UGF6/kvBfsUlh4YWp7QCSXHpsLRjyyX9AABBvIfwhmVGnxgyVLJ409XlVDy+UA1haD5RpliCHmtOo//PUXidYdz0+WO2Xta8ECXH6exK0VYz07qcjN9HcfXsPy89RvfV6hPBKa3ureNYqrkvynP76A9TTA0KVW06G4fG3x1F68XHDVoOIzElS3m5A4skBZt/DEdAAY0VSKTF5N1jx/bLgnFbVhkA8JFA+6zUxHJ0LeRM8UwBQ5+LOrML8rVeZxi3LlRWjgxHbquvCWXqJdqU1++dyjBp1aUsNAV2U/68htcZYmw6E4ev/rqOm0/VZ4lnWv5WK6dSaaOHLluof27TmXj53/qS2288SUHzhRHos+6sfJshtb7xJAUjfruE2JcFx1fucioeH0AKaKygeLx17B2Hv6W53VufC/Zgh/N8BHAJFj+LABJ05l1AaRSv5Tk0+ff6s8KuQpHFcRwO3DBu2HGmhjWWXqRmIUfHtPlau5yM/FY791B/q6i2c436/RLm7btt9H7KZRjuqiRfJ6cZv1iopenruvvrcu7IL8WlGQx5vD3WnMaR20n4dPNFjfdTQENMVlxmZbR3W6Ud5H83593BdufcXBo3vMN14We4KBwNPpS/9JvzbmOeYBO88BocZOjFO43yeKNUpj73EBXwEmG8i3ggGoJw55W4IhqNkfx9EMC4Yd1OkKA37xSmCbbjd6fvUQYpOssLIIEfl4T2vCt2t2bW6mMPtN5XlD8Rxn7e35qwrtWtZ6kYu9W4UXuaLmKrjj3AsxTNa0xZ0uVHb9S2KeXQQPuF+mK8+r7G0rTW0X8aWqx0sUYCtb53iqa3kjHBpOIisIbMFHzjSQo6rTiB4wYsM+IIaNYxKygu0bC9y4IQgVnrcU00EgBQmktHvOgjpTKxosH4V9oc3fnncEdWCTW5x+BzDEMFR+RlHsnKo5N4MQK5WPwpnK/1fN84bcc3TtsRkLVZ76gtDjJU455hg9MyVOEVfNGGcyvQTzxXrbwnUvG1YAcGCCKVtnfKXoR7zP6XBfnvVmJhV8Fqmi44alR5TV1B+jx8afw0FyblvVhoHhp9AyPM+YocuvECfEu5oI6vO9KyrDcvFGeprGAF+q4Nive/SM3Cyoj7CK1d3uDj8xTqqpyErbn8sM0XkZyejWGbL2LTsKZoF2D4uewRtdBYAYUz9iMFJfC5eJzOMt355wAAtXkJ4HPqr15l3gvEiD7RGswsyemvdDtG9Akacve1nI1hjmAL4kQf46jwK6VgBgCa8u4hXvQRZgj+AJDbIrPP+RtcFY1WC2YA4D/hNLzPO6u23d4YNFW+g3plZMKuKUxKUC3ELyIXZ+uN9Ix6+Ap/X3mC+f9q75ayBKu00Gh5TbJycluUFBtSJu2MxrbzCfh0s+ELUWqbBFAxULr2+K3875R3Be/dYZs0d1c5EgporIBaaOzLXllL1M7aqLTttLSu1vJHpI10Hu+ktD7eMWfckfmhbtavWCvthSpZf+C8rGC+m93COTgt/BwD+MfhpNAN1Z53VeOinqPEk5X2HyE4gJa8G/iMfwD1efFKZbdIOuLLnJGQsdwvr1XOazBT8Dsqccb/8ieOwZRJ3kyZnVnbAE1Dv9LyL6iuegIaBmbVyd70HdqQ59MaE+tpuzbcfp4K/6/3Kz0nt58bn5entPSEwrEUA6Wea8/Ik4d1TQDpiKjLyQqK2HukSHgHEfyztgFgqMvFI4b5QZLDxzqnlejCv4iR4snw416CA8Mv0q4omfMO/lwi7rGKGCPYi/a8qzgoDcav0i4QwwlCiCEFD5K8jxADD4PF03FPNFR+zopcMhY5bcAkwd/wRBqiZHXQjl8w4eLinP44IQvCA+aLbDjjncQZwc4Fq9ZvdV6o9BhuySqjn3iOfIXxaFl1HMlbofwzwUF8JjgIABgpnowjssbgQwZXZCETInk9SfFhSrxg7o+x+3lTGzjx1X8rKwZYm87Ew1lDGUvRF8wZ8jBP309G6xrlLFSjvPPquV/x+TclntK25IXqCK/bz1JRrVyJIjf6kL7lrEHLu2TDkCYY8ZvhzYfEGjjcYlXkt8bkTAY05GimwRU3WFUAwEpJX6yE8kzXmnJkxHCCf9ZWXBWOgidXkPPgw70GAKVg5lPxVByTKbcEnZQFwj9rK9yRieuiEUr3tcpeiSdMuX/7PquI8eIJWOO8Wmn7eucVanULy/4BZbkUtOVdw3/SJhabPZnYhikXnr3XnuHDZpUsch5DW3tS83JaVC+rj19nYvGhGKVtYl3j/M2k70dlsgHzwfx88iGmd61toRrlYoxBIpVh4IZzqF6+hNr9ianmjcRSjGd0JQXP3HMTJYRF7/JPXU5WINXyaepYx8vGNSG2x+Fj8Tf4Q9IBAVmblbqR8p2X1cJJmbYV5zmkwg3zcwYBAN4yNzTKClcLZvL9KwtBg6wNmJkzTGetDgu/xlbnhRghOIBdwm9xSzgMJZGpcx9iP0zpPjoba/yEkhO2q4+kMmdW33ytFx837wBGsmR3lqUm2AOAtCwJLsS/xsX4N9h+QX1xzpMKS2akmDAajtOSFKza8pbyLgfDtAzxdmQU0Bhg1cCGRpWnLqfi7Rbzx0zJcGTDGbNzPsEmSRhCsxdjZs4w9MmegwHi2Xq7gH6VdkVo9mIEZ6/Fa7jrLJsKN/wh7Qj/rG34IHsuEmT6m8nduGwM4Nv2IkNMZ6vvlPhX6kHu/hvPHWqgw5Sd0WqT+tmLiTuisfWcYfNhmfKaa+tyKi7XJApoDPB+oK/ScDh9bPHeaViplA3OUjgGGtlMbs9iWCXMkwzFA1YRf0g74jILMHBPDg9YRaMX7bzCauI98Y/y1cn9s7ZhsngM0pgLTkvrolbWJnnZ8YI94OxsLhuiWWGulnzMyDlKCntl5/9dfYpmC+x3dvD9Rk6QaAzGgMO3EvEyLdukVj1HRwGNFWj6QHet723Rc1T0NH6RM0dhjdEFxdluWWvUz/4VH+fMQBaEaJgVDgAoxWVgGF99xBWxP3eeF946Yhw4o4KUopRoWtjBmbHe5Ugx6vfL6PLjSZN+WTva41VFAY2BjHmZNY0UmNmtjknnvfNtZ3wUrN5i4ehvPFJ43sAd/0hbAABmO/2OAfzjEMLac6kwpeHrxDhH7xTekHyOM+77z+g1k+yYo3bVJKeLse5ErNH7WTNR2xYooLECS36eXZz5Gru7HPRzZhBjuveIab7JGS7/e5HTBkwXbLPCWRjG8vdgo9NixIsG4b5oCJpxd6xwHqKLuT9+GAM+22L46MyiNA/XP9FPHbbF2JTJLFPfOfaPjqI3bstKOBgeRGj6hWLKR/yzVrnDizUmehWd7ww1lhxVQDTLgAtOSeuhNf8mAOATwX94wCrgCSsLAIiUBcGUmTAm8P+HBryHKM+9RSDvodr9vzn/gI3SLmjEu4/zstpoz7uCHyQDcUZW35yHQ3QwN76Iik02av2nIhTPYMqf1zCmbbXCrobNpLwTo1xJYWFXw2QU0FiBpg+0KQtWhlQrA0D9siJy4hXLhC9iWVNyxmAV1iKEnzuF/HdOBQnDe6Uh+Dxngt5jlEEKOvEv4YysHnY4z4dv3pw72oi4HIwV7AWQu2AoUDCB4DDxlzguM25EoS5+XBLSmQve6BklVpS9SMuCu8jJrGNoWuhRF23TVhD79ybT+KHi9oQCGivQ1MRryq+W9rVy5x5RXZ9jUmhNpfU4ihpHbeJ1NC/hiYE5M+EveY5I4RdK973Pj8IeaUvME2zBaVk9TJd8hvzQmg8pVjmtRjf+BZ3Hf8LKYoukEzZIuwHg8BE/At87/aq1/HTBNhwXmxbQOCMHJZGJqtxz9OdHwomToBc/d42rTtmLwIcM7/PPwhkSrJL0RgrUJzUripotiED9Ch42PWdR6nIqbqqVc+zPBQU0VmDuEvD58gMZTV1ORfk7o5SLeb8oiXHimQ+aZv2E8YLdeM3c0ZR3F634t7DReSkAYCDvOFLghsWSD+GODEwU/E9nMNM2exnimY/a9n+kLdCOF40XrBSOyBpjEP8oMiFCz7zAoybvKT7lH8RGaReD6s2HFDW5J/if8xy4cNqTmv8TTlO6PVxwEN2yFyjNGF2U3XiaYtb+xn7VyFjR+lFShB6KTs38S6O0m3HTRNgbCmhMtP/zVui26rTG+zT9QjGnFVY1STY3n6doRjRd63tjQLNKWHXsQWFXpVh5iVKYI8mdbThAloDD/K+V7h8t+BejBf+q7fc/aSsEcI9Rl/cIi3I+xDrp+1rPkQEXjMgpaAmKlAWBDyn2SFtiouBvBPEeYrbT7/DhXmGBZBB0XUqEEOO6cASEnGlN5PuFM5DD+Ehg5fGx+Bs8RxmTjlMcvDZyNfGbT1OK1A+ufdefFXYVbKMIRG4U0JiopldJrfdpWiPDnGZYjTnBNvzC8PUQGZUUqE1FTxc8efNOZ5mfBjXGyzTz1jMh5olhldA3ezYWOv2KXdL38JVgJwSceh5F/+xZuMDMW+tGCj6Oyxrifk5FnBZOBJC70vgIwQFskHTFT5L3IYYTMuCitN81HcHMvJzBiGPeeYnNgAuy0Yt/Btdl1cCHFHuFswAATpwU1bjnOCz8Cn3Fc3GP+ZnxSBj4kEEK3atMFwejfr+Mue9rX83e0Tx+rfs7q6goAvEMBTSGCq5SBlEPlddG4fM4jQlwHzevjCdv3mHz2Xj5NnOGTqrm0AC2HeR05uv26LD8BB6+zLDJ+YpSc7WjusRqoaN4CQDgBfPETKc/8IJ5wpt7hdJcOhblfGh2MKPoCSuH1tkrcEo4Wb4tP7BRlMpcIIREHszEynwwKmcyHrAK0PaV/A4ibJd2kN+um/UrNjsvQlPePQCAO/cOvzn/gB7Z36Ek9w41uCd4wsphgmAPVkr64C5TngeKDylk4MDAgwuyMF2wHUMER5TKvGTuCJe8j43SzmDFbHaM9GwJpu66pr8gsStF4XuXAhoDrRrYEN/svoEjtwsmuBJoCGjKlRRC5MTHnB51MLxVFfmibOZ0OZn6RhvcvDJ+P/fI9BPLz2/bd7qxZyvj5oxXRjaLE8PtkbXCnuxWVj/PY+aFUeJJ+Nl5pdYy7pzyr+Vu4u+RBeOGmWbABf3EcwEA5fEG+4XT4c29wUXROLWynfkX0S37e9xi/gAAXyTjgHA6SnG6g/tyXCpmOf2BWU5/IFbmgyTmifXS7vJWI0LsTVGYLqN4/XQwQ7mSQnzRqab8NgfAia/96eM4DhU9XdS2z+1RBzW9jMsk71JPPcHSkAYfizb7WqBJyFrdZIv6aFu5unhwFxWd3yWHZc3wfvZ8NMlah6U5/fCnpA3ETL0bZ0HOR/DP2mZ0MKPqBTzxsfgbnWX2C7/BKqfVWOu0EkeEX+oNZlRV4z1HC/5tLHJaDxdkoSF3H/GijxAlHA8nSOAC87tzCTGX4u/WtWvXwt/fHyKRCMHBwbhwQfeIxl27dqFWrVoQiUSoX78+Dhw4oFZmzJgx8PX1haurKzp37oz79+/L73v9+jUmTJiAgIAAuLi4oFKlSvj888+RkmJcQjsFNEZQjWCd+LojWo7j0CPQFyFVy6B63nC4T1pWwX+T2xh13iC/Uhqyz/VHB3wLTrk7r6ft+sSNbREqCk2lqur4GD53ypZPm1mxJrZ3nVVDMjywRtobX0lGoWb27/KFNqtk/YFqWb9jg7S7xc4XwyqhY/Zite0ZrCBYep8fhW78C3DjlPO7spgThoqnKS0Gmv/vQ/FMpbJe3FvcEX2K3cI5AAAf7jXui4bgjuhT9ONHFkpg4889pyUpCICC79GdO3diypQpmDNnDq5cuYLAwECEhYXhxQvNi5SePXsWAwcOxPDhw3H16lX06tULvXr1ws2buZN25qdbxMfH459//sHVq1dRuXJlhIaGIiMj98fBs2fP8OzZMyxduhQ3b97E5s2bcejQIQwfPlzjObWhgMZEHMdhTg/9F/nVAxti+8jm4JkZXPiVVl6M0tqTVw1uXlnpdusa5XDn284G7duvcUX53855rVhtapZTK1fLW3NitbHPVFEMaIROhn80LRm42jsGnlUSb++ziqiVtQn1sn5Bi6xVWJgzEI2yf8ZOSVu1sv9JG8M/ayv8s7ahVvYWnJAFajzmOVkdNM1aizHiiVic01/n+Zc4rccJ4RQbrKmVqznvNuJFHyFS+AXui4bgknA0mvNu2+TcxD7l/2Bfvnw5RowYgWHDhqFOnToIDw+Hq6srNm7cqHG/H3/8EZ07d8aXX36J2rVrY/78+WjUqBHWrFkDAIiNjZUft2nTpggICMC6devw7t07bN++HQBQr149/P333+jRoweqVauG9u3bY8GCBdi3bx8kEsMDbgpozNCrYQUcnvSe0jZrXVpUZxqWGBjQmJx/E1IZAV4lsXpgwURnLs6GXUimhgXI/w6qVAqXZ4Zi0ydNlRKjP2nhj18/aWrROptzLF8PkeVOagEige7netR7VeV/F4W+b3uQBSHS4YpnKIufpT2QDWdMk4yEf9ZWfJA9FyPEU/CPtAWm5oyGoZ/0l/DEQVkwfpV2lW+Lk3mhVtYmnJQqL/dQnnuLGNEn6MC7bMmHpaQRdw8bnRZjh/N3StvLcqnY4fwd4kUfIV70Ef50nocSyIQQYnzIP4YvBTvQjx8Je1hzxQVZ4EGG6twTOMP6M9uWwxt050WhIvfS6ucqTBwHiMViXL58GaGhofLtPB4PoaGhiIqK0rhfVFSUUnkACAsLk5fPzs5t1RQKC1o8eTwehEIhTp/WPPUJAKSkpMDd3R0CgeFd6kWn893G8r/OPN1sMwmcaouMoS00Z6a1R4sfjhl9vppeJXF48nv6C2qgGERwAMqUyH0jW6tRSdcFXVfezrh21bD2eO6vB4GOfKjCoLfVRfE5pnjGyjhcYTUBBhyRNTHpCNlwRufsH+DHvcARWWMAHIbkTAdygIrcC6x1WiVf+2qF0zr0EH+HR8wLlvyJNJAfgYUqMzW/ZiXwiHmjIU953qdmvBjcFH2mdowlTusRK/PBc1Ya3twbTMoZi5usqlo5Q3jjFYJ4sTguC0I2dE/o5owcfCPYira8a/DnaV55PCjrZ7xFQasvDzK4IQtpcEEY7xI68S+hFe8GfsgZiAhZQ7yDCDkQQAgxhvEP4QGrgM8EB+RLcvwrDUZ9Lg6VeQVdLUPE03BSrUWOQYgclEYa+JwUT1h5+T0cZBjEj0AH3hX8I22Jo7JGAIB0uMIXyVjktB5NePfwl/Q9HJY1xQOZL1rxb+I/aROkwg08yCCCGFLwIAHf6tMCJCcnQyqVwsvLS2m7l5cX7t69q3GfxMREjeUTExMBADVr5uaezps3Dxs3boSbmxtWrFiBJ0+e4Pnz51rrMX/+fIwcOdKo+lNAYwRNFw5PV9vMrKg6j42hLTS+pdQTkwHg+9718c3uG2bXSxONi2lCfdFO1aHsvRtWAGBCi4OJ3/mKrSD2NlGhviBF8TnW9nwT+3KXVVIbAg4AT1h59BTPRwD3GIeFX8Ody8QJ4RT5/aPFk3CfVcAMwVa050djvaQbFkoGogvvAkL5V/CzpDsSWHm05t3AeucV+ET8ldJoqta861ji9DO8uTfybT/kfIg/pKFIR25Xdg/eWSxzWgdnTqr3cVTjPUc15F6I/hXORNOstXgJT6Oei1JIw0HhdHhy6QCABFk5fJQzE2P5e/CRIHdk6HlZLSzIGYS/nOcaVK9o0SgAQMOscJTm0hAh/FJjuRXO6wyqY3f+ebVtvzkvwk2ZP1ZK+qA0l4oJ/D3w46m33PTOnodvnLbKpwYAgHZ87UPZBwuOYjCOFmxw+lmtzF2ZH7qJv7daUHPqfjLQxZy5mDRzcsr90R8bG4vSpUuDz+cjNDQUXbp00TidSWpqKrp164Y6depg7ty5Rp2LAhoT5V9DnPg8RM/uiKBvj+jewUyqAY0pOTQNKnrg+pPcrPGBzfxsEtAoXmtV37yq72V5Iixdn/UGKYqBKs++GpeISTjEsEoYkD0LO4Xzle4JVxnGPlKwHyMF++W3P+ArN9tvcFqGBtkbUIZLxWqnNWqtL62yVyq1IgDAPlkL/JfdBNlwAsChJ+80fnT+CUDukhUTc8Zjq9MCtOTfUqv5z84r8JF4hlEjzjY6L5EHMwBQifdSPrFivmDeXfkkiJqclNbHe3z177CrotEG10Ofl8wdf0vfwz/SljgonA4AqMeLxy/Oy3Tul5/4bUm1eI8xiH8Uv0nDLH7sfGXLlgWfz0dSknIrWFJSEry9vTXu4+3tbVD506dPgzEGsViMcuXKITg4GE2aKLd4pqWloXPnzihZsiR2794tD4YMRQGNEcqW0PyBLWWDVhpTu5wUVSnrJg9oAMDHQ4TnFpgBWBVPqcup4Ib1upyUWWpm48Li6szX20LTLqAcTn3VDs4CHt5aYIVcZwEPYiNXVba0bvV9sP+G5ibo4uI8q4022ctRHm+xwvknVOSSjT6GEyfFHdGnatsfyrzxec54tWAmn2K3zz+yVvg3KwTNeHdxWZbbZfBVzkiMZXvxj7QFmvHuIgcCTHfajka8B7gryl02o37WL0jLa/UJ4BIA5I4ia8bdwU/OPyIbThBACi/uLQDghswflbkXcOcy9T6uXtnf4g1KQMycCpaqyHvrt+DdxDbn77Xue1JaH1/kjIYv9wrfOW1EfV68/L4oaR0ckwWhJe8WfpeGIkLWGEBudxEA+cSIH2TPxTbnBRBpmKH6qLQhXjN39BecULvvc/F47JWFYI7gN/Tmn0YM84M7MrFT2hbbpB0gAR8MwG9OP6A1/yZkjMNuWSv04Z/CKWk9/CLthnmCzfDnJeFbpy34SrATrbJ/hDMkeGFky5g+zs7OaNy4MSIiItCrVy8AgEwmQ0REBMaPH69xn5CQEERERGDSpEnybUeOHEFISIhaWQ+P3IVS79+/j0uXLmH+/ILgPTU1FWFhYRAKhdi7dy9EIuPzGimgMUJpN2fsGh0CkYBvscnmZnarjR6Bvpix+waO3nmB8iWFeKFh6n/VYMCUgIav1HLCWW1VXG3PjaHnM/aptcRroVi1siWckZxu+dEmHwVXwrbzCVrv93BxQk2vEpjToy6WH7mnscwHjSpgcmhNVPQsGPWW+s78gGbe+3Ux/X/WabEz1OSONXUGNPUquOPm01Qb1qhwPGLeeARvtMpeBR5kaMzdQy1eAv6UtkU2nDFHsAXDBIcBAO2yl2GS4G/05J/FXZkfdkjbYa7Tb0rH25OXyCwx8uteCj6iZAUjOZ+iHGZIcofRXpDWBsDQjX8ODXhx8jI3NOTd6PKReCbS4IqFgg0YKDiOi7Ka+FA8C1LwURYpGMQ/ioOyZnqXpTgrq4fqWb/Bm3uDZU7rUIFLxjc5w9XyXV4yT/QQaw58VKcCUJ3h+QqriabZ6+CGd/hQcBzlkIJfpF3xlJWFGLktCV9JRqEd7yo2OS/BBVkAPhTPgizvOPMkQzFPMlTrYxic8w3qSuLxhJVFCkrgi5wx8vuG50zFQeev4cxJUYLLQrRoFHIYHx3ES5HAvLQe0xRTpkzB0KFD0aRJEzRr1gwrV65ERkYGhg3LDVqHDBmCChUqYOHChQCAiRMnok2bNli2bBm6deuGHTt24NKlS1i/fr3ScU+dOoXatWvjxo0bmDhxInr16oVOnToByA1mOnXqhMzMTPzxxx9ITU1FamruZ71cuXLg8w3rZqOAxkhN/Utb9HjVy5eAl7sIPw9ugqTULPx49D52XnqsVs4SLTSqiabWajFRaqFR+Ft1pJaq/LK26nFS7g7T/Lcl9W1cUWtAE7ewq1Jg5q1l1FVJoUBtCL8lAjp7GPmtLxG6c13vYhHQKJKBh4usFi5Ka8m3qV4YJ+aMx8Scgl/Pl2Q1MYR/BNlwwnVWFbukba1UOw7vixcggEvAL07LNOaSaPOSeaBF9mrk5F2CpktGYLpkhFKZZHjgR2kfg48pgQBPWDkMEM82eB9jpcEVaXDFSklfrWWOyxoiIGszxBAYvexF/ozUqmJZBdTM/g37nGfIW5ecOCkacfctHtAMGDAAL1++xOzZs5GYmIigoCAcOnRInvibkJAAnkI/d4sWLbBt2zbMnDkT33zzDWrUqIE9e/agXr16SscdNWoUXrx4AR8fHwwZMgSzZhV0J165cgXnz+fmLFWvXl1pv7i4OPj7+xtUdwpoLMzYa4swLzGVz+O0JvAClgloBCoTAWpbXyrIr5TRxx7TthrWReaOGNKeQ6O8T0VPFzSp7IlLj94o3a94gVYciaSN6lNubjxirfRggZYLdmBFD7Wg5KuwAJ2tOYos0VhoD0O/7SGoKgpusqr4SjLKZueLYZXwnngFvhFsQ3veVbhzmXjEvLBD2g5+3EuUw1vcZX7YKg2FD/caobzL2CVtIw9miiJ9o7ZMw6GH+Hv040diidN6jBJPxmGZ5qkvzDV+/HitXUyRkZFq2/r164d+/frpPObt27fh7q55wtC2bduatd5hvqL7jrJzo9tUQ+zLdARXUW7x6d2oAnZeeowa5ZWXR1Af5WR8voMhLTRL+jZAh9rGR/wNFYIgpYBG4UKpOsqJ4zjsGh2CKtPVp8k21oLe9TBj902zj5NvRtfaWHDgjsWOB2hP9N02ornatlKuzugR6It9157pPa7iUT9p4a+0KKoj0RdU2XpNMWI4Bh4WSD7GAnyss9wTVg6bpYZN0Ek02yVta8VWN8dG4yMKydddamHDkCZqMwg3r1oGkVPbYt8E5cUAVVtkKql0OxhCoDIcRlNOS78mfhqWWTCOtlE3iueTdy9puEgpbjEkaOc4YFBwZf0F1fYrOJPirwPGGEa8Z9rcGrqotpABucm9bkLDf1doer4UA6XpXWup3W8Ia+VTGYPiFUKIOSigsbBq5YxbeFIT/7JuEDkpJ0EpXnB6NayAH/o0wPuBvkYdV62FxkpJNNq6nLSdrmTe4orv5S2PoNRNpaG8ateNpbtLTHlWqpR1k//9acsqGsso1rtPo4oY27YalvbTPG2+MXR16xlKtfWsMOgLaCjgIYToQgGNhewd3xJ9G1fE8v5BVjl+r6DcSedqeZeEl7sIXu4irFJYlsAQqoGAtS5h2rpWFFtBFFcqj5reAZFT2yJAw9pOqkdqX6s87szvjLNft9d6fsaA9YNzh14u7mublbgVV1avoWU1db5C01XVcm74qnMt+SzKmhjap6w4bYCp6zpZeWkwg9AEgYQQc1AOjYU0qFgKS/uVstrxv+wcgCb+ngipWtbkYzipTO9vyR/liodSHuWkeR6aEgrdLCWEAqXbii0uqtc4P08XOPF5SgnUmq6Dnep64/6CLnDi8/DVX9eNqr8pzwtjwL7xrRD3KgN1fDQvusnX0nJlLg8XJ2z7LBhOAp7aa2woSyTkmUtvC40dJC4TQuwXtdA4CKGAj871fODhavzaUR80qoDAih4IrqqcgGxu3oSXu+bWBUPmoSlhYN6IQTk0WrYbc3G3xPW8fkUPvB/oq/T4qyp0RSnmFpnaGqFttxbVy5o1pYC1uh+NoT8p2DrnNWVUHyHE/lBAUwws7x+Ef8a30jDKyfSLWDP/0ihfUv9Mjopn/PHDgi6yehU8tO6ja10lTffo6rYBgG2fBWNmt9o6yyie05TWCsX9FYOV4a0L8mkUk7INuTZbM8ToUKs8QhVGs0kLP57Ru4SDtdpnLJH3RggpfNTlVIQs6dsAuy4/wYW41waVN+tHOWfYL2bFMu8H+qKsmzMSU7PQrIphrQm6zhH+cWMkpWZpzL1R1KJ6WbSoXhbf7Vcehq3t2KY8LYoxkGLcqJi35KQwyqkw44fx7apjalgAsnKk2HI2Hu1rlceJe4ZPimYtToW0KNXMbrXx95UnhXJuQojlUEBThPRr4oddl3V8MatcRc3NmzB2eDWQG1xYSud6mhdLK2zaVsJWbCEztXXMEnkkU8MCAAAiJz5GtakGADgb+8rs45pL07B2RdbqcvI0c5oCkqtdQDkcjyn8wJgUX9TlVMQYE6SYnTahdIXRfDBzr0GWzFXdObI5Znevo/88JiYFa6IYxCgt1GnFnJWvuxg/F00pE3KznPk8bBpmuZlK9eU8VfR0RdR07aPbDHXhmw5mH8PWutX3Kewq6FVYo9S0zcBNih8KaIoYYxJhbTGZmimzu4oEfJQUCeDM56FLPeUvckOqrC0HJ7hqGXzaqiCnxVqjZhQnS1QKaBReGoPiGQ1lDHk6R7ephrvzjZuNtbaP5inJVf09pmAFXY4D2gVoXrnZFLouTFM61kTnut7w8XBRmvPHFOXdjV/Ft7AJnez/q1rkbNgCgpZmqzjK2wHfN8WN/X9KiEHyP9Tze9VDRU8XfN+7vt59VIOD+joSdVXJZMygtXdM+a7h8ThcmhmK63M7oX5FD/w9poX8vrq++i+8qjMia6P4eM1soFGi+Lwot9AUMDWYNHQ3xYkZBwVXkv/trCXgrelVUut9irw9CobLm/OLvFMdL1Qu44qyJfTPoePjIcLnHWrIA0V7GGJua0KBfX5Vj1SYUVskKKSAxkbD+dvVslzwTqzDPj8lxGj5LTPVypXA6Wnt8ZHCRSyfrsvAuekd8L+xLXSUUJaeLTEph8ZQQgFfflFuXNkTBye2xrc966JfEz+9+4r0/Jo9OqUNwj9uhFY1NOfz5F8wF/Wpb3DyctVyCsOzFS70rlp+tdpylHRpN2cs7RcIkRMPvwxtorVcp7r61/DSFqwZ6+fBjXH8i7ZKLXjaWvNUA6ePmxu/zIWja2nB3DNLUpytvFWNMoVTCRu10KRnS2xzIuSuyUaMRwFNEWHIr2tVUzrWBAB83LwSvD1ERnVXpWVJ4KNjdfB8ZUpYJuGyto87hoT4G3QRVV02QlX18iXQ2YCurAFNK+HPUSHqdyj4e0wLDAmpjGkKeSuK118Xp4K8e6X1RA2IADV1nRnTKJI/T1DHOl7o27gibs3rLF9eQvP59FP8NWxO6gLHceDxOINWjZ+c9z7N92nLKiirZ6i+reibDsASwj9ubLc5NDW8SiDAqyRaVS+LHg2MW4rFUsQS4xbqrejpAl8P3d1HrTQEkKG1bddCM7ZtNaXbg4thEG8KCmgc3OTQ3C/7Bb3rGb3vhPbVcWTye/j2feP39fYQYW6PuuhSzxu/fdoM7i7KSaXrBjVC24BymNbZtMUSzaEvoNGMafhLuw8aVsDk0JpoXNkT3/asB3dRweNXvOgrTj6omAfBt8EQ5WNftMWxL9qgQcVSeec0/6es0nw7FjhejlT/xUj1Ys7jcahjQNejLXzWWvMiptrW81I1RSVYK6vhB0Dnet52u9K4E4+HgxNb4/fhzSzy/rKFRpU8wdczok5TS6YtAzaBwo/Lpv6eSjOjE+1o2LaDmxhaA5+08DdoBmHVkSwcx6GGl+45XFTtGdcSP5+IxfQutVGupBDrPs5dM4kxhiEhlVEz73hd6vugSyH9qtTX5aRJtXIlkJxu2Pw9ALB8QJDW+xQv+qVcnXHg89bguNxAa0rHmvj3+jOTm5SNuWS4CQWoasykcRoiuQYVPXDjaYrGBiW+BS6yhrTQaDpNdo7U7HNrU79C7mPWJ0xHF10FT/0XoH8ntEK9Ch5YfuQeAKBZldLoVMdLbb4ke3JuegdciH+Nz7dfBZD72thrsKUNj9M/55GmFm9LBPCGUp7iQfk7Zd2gRhiz9YraPrV93HHneapN6mevqIWmCDB0OYS6vh6Y2qkmlvc3fYXnIL9SWPdxY1Qq46q0neM4fNuzXqHmN3wZFoCSIgHm9Khr8D7/TmiFPo0qYuWHQfJtqkHe3B6ah3prk6Mw7a6zgIc6vu7yUUSfd6iB/ya3MWkJC2vT1MXlxOcp5bAoBjaGXMiGhOh+P0gMmKJYU/KxsxWTZFUDYtXmfyD3PbG4r/bPkVSmv+VJdbbs4Cql1bpo7a2rwdtDhDIK8/aYEsy0NyC51tPCnw/FhXx5ed2dutgiePHR0e2lOAmnatDfpb4PvsybS0rR4j4NdB5TGxeTWrTtEwU0xcz49jXwQaOKhV0NqxjXrjqiZ3eStxIZol4FDyzrHwgfDxcc+Lw1+jauiJ8GNVIq80nLKrgxt5PBeRulFLrfLP1lUdhLLmlbhFSbxpU95X/7lVZvtchRufBruthpumZWNXDodmjt8mbPU+JX2lVt2yctq8DDRftFV9/rtOkT9fl7OI5Djwa+GNDED8v6BSJ6dkd827MgOL8ww7rz5xjasmnupd6Q/f+b3AaL+zQw80y5ujXwQY8GCq3FnH3MXfM2M0frfYotNJpG9Wn6TNT1dUfU9A7YPbYFmlc1bDADYF4unL2hgIYUKeb049fxdcfSfoGooKG/uqTICWKJYd0cbkIBjkx+D8entrV4XoEhOSemmpSXjzVcYa4e1eorfrkaMmxbMe9AU3Cn+l298sMgtKxeBqMUhgNrOkvfxvpHu7k48fHL0KZKa1YZQrFOn7TwR++GFXSW1zQpoeqwfMV5fkoIBWgboJ6czeNycycW9W2APo0ropSrs1ILiK61035UaGE0VT1fw6dtsKbmVUujXEkh+jfV/xrrE/NdZ6z9qJHyaDpwOmelrqNjTqaZ3WrjvZrlcHpaO4PrsPCD+nAXqWd3iFU+y4oBnGKXmFRTQKPyqXAW8OStSg0reWLHSN2DGfI1qeyJxnmL2pbUUEdHQwENIQbKFBuet1HDq6TZE8BpYs2ApqZXSdz7rgtmKcymrGuOD03xTEmVVdQVm+5zDOhechc5YetnzTGuffWCY2g4Uf2Kui++A5v5IeKLNnrPp4liMDI1LEDvr/m/RrdA/yYVceLLtvJtUpXH6qLQ+jG1U02NXTXmzKfi6arcVWXKqCh9760W1fKGZRtZzT5GtgjrGgAor4OBhBrmxuFxupPydc0R9Vnrqvjt02YGDzwIq+uFgc0qYfVHjdTuU+9KKljKRfFzo6n30lK/kxiA5f0DMbpNNewd38oyBy1EFNAQYiCJjft7NH2vGjtE1ViquSkcpzzyRimHRmXfciWFuDank9ZZhzXNydMrKLcFp51Ki4W7yAkHJ7bG0SnvmZTP0LdxRfnIkIoKCbrf9dI8ok9x8sZSCsGBUMCDgM/DnnEttZ6revkSWNw3EJXLFASwqr+qFUetaHs8hjzMJgpdeIpKKPy6Xty3AdZ81FBjOV3EegLONRouyvpc+KaD0hxNgP78FF2tmpaY74rHcWpB6rYRwUadw9B3ZLmSQq3l/VXyEEuKnHBuegdcnhmqtF1TgGWpbyLGGMqWEOLrLrWs8gPM1hy/jYkQGxE58ZCVY92AQh/VZmpr4zhg4ydNMWP3TXzVOUBpeL6mEVQ8nvZ2hkaVPNGqellUK1+w3/cf1EdoHS+00TA/jqHLMWiiOFv0xNAaSM3KQY9AX7SuoXkeHsVcn8aVPVHP1x0NK3vK52YK8itl1Pn9PJUvVoOCK+FCXO4oOm2JtIbk124f2RzJ6dkIWXhMvm3Ue1XRUKF+JYQCtXPwDZjzR1+Xaum8ZGBjWpI0LTOhr3VDoGM+rAZ+Hoh6qL6Qqo+HCM9TsgyqE6chh6ZFtYJ5ZzR18ZgqOU2cd/wyaF2jLE7dT5bf98vQJghdflKpvLeGpF4ZY2pB1uFbiRap35i21fUXciDUQkOIgbZ+FowGKksx2Jq1W2hUCXg81PX1wJ5xLdGiWll4uDhhcmhNlC8pxNJ+xo2Wk8gYpnetjf4Ksz27OgvQvYEvSoosO6pF8Vd+SZETFvcN1BrMaNp3SqcAretUlTZgdW4vdxH+HhOCfye0woHPWyvNqKutAaKip3rysSonPg8+Hso5XtO71tY72siQIfaGBsvGDmxSLS8S8NAzSPucLs468lsmdaipcTLDU18ZntPCcbpXdjdkKgFDHcoLPAR8Hn4fHoyOdQryuaqXL4mBzfTnCWl6v71KFxtdF8XJBGt6lcC56R2U6lMUUEBDiIEaVy6NveNbKf2atyaNXU42aqGZ26MOvNyFmNdTfQj8xNAauDAjVO3XpL7rXIiR+Q/m0DfrdX5Sbk0v9VYmfRf/fk3054TIGEPjyqVRr4IH6vi6KwUcqsffPKwpJrSvrhT0mEPjnEEG9GflSNR3nK+hi87YDsAAlVGHIic+Fn6gfa05XWuxuTjz8VnrqkoJ5t90raWzVUdV+ZIizO6ufWoHQwKaUq7OJiX8O6kEUrpG928a1hQhVctgiYbpAUyZ+kdxmgBXZ4HG1iBHRwENIXZqXLvc5uD+TSrii441UUIowDddrT/VPpA7LPnc9A6oZszEfFpETW+P9YMbKw+dtQLFZR10/QIHgBX9gzC9Sy38PjxY7T59FwtDeiRK6Bgxonr8tgHl8UWnAKvNfVLHx13p4rv/81Ya13qrV0G9i6+0q3rrgOocVPq0r1VeKYAROfE0JuvmU5zF9+Pm6vVUNfI99XmCNAn/uBF6BvliVJuqCPDWPrWDIQENn8fh1rwwveVUl0uY3qU2fDxE+KZr7gzqFXVMwNguoDy2j2yucdoAtXeKAe9JhoKZy7vU89Zd2EFRDg0hdqp+RQ/cmhcGV2c+OI7D2HbVbTq9vLGTpmn7TvXxcFHrJrGkymVcsbx/IJz4PJy89xKA/plgPd2cMaqN5guhvsftX0Z78uSC3vXw6FWmUk5Lvv5NKuJs7Ct0t8AU+gOa+GHnpccY2Kzggs/jcue/aVRZ+dy5s/kW3K7r64Hve9fHtvMJSuUGh/jj8w41ULaEEN/tv43AiqU0Bnc+Hi7YObK52nInqvJHWnEch4HNKmHDqYd4+DID7wdW0JkA3VYhMJ3dvS7+ufoMaUYsDBlW1wtRsa+U1lcDgM71fNTWcNPE0Pl4RE583J3fGbsuPca7HCkqlHLFuG3KM/gOb6W8NIZfaVec/bq9/D024r2qeJUhNrrrR/U9OqG9/lwYxoB9E1rhYtwbnbNcOzIKaAixY24Kw6AdZa0cW/lzVAhWH7uPue/XRbVyJZSmfXcSmP5cldJyod41OgRnH7xCfx1dToOCtc/su7hvIBhjFlkqYH6veujVsIJS9+e1OZ2QmiVRCx45LjcIU13O4aPgSth2PgGTQ2uiqb8nQqqVkdftp0G5S5ocuvlc4/mDq+ruPuzbuCK+763crXTg89Z4mZYtb3FY1Kc+Ut7lQCyRYel/9+TlFId5Owt4GNuuOhYduqt0rMEhlbH+5EON8/kE+pXCukGNTW7xUh0Cr4vIiY/BIf7y25XLtEL31acV7lcPjhRff5ETH3PfN3xmc/kxFP7e8mkztDZwNfbyJUXoZuWW0sJEAQ0hxCze7iIkpmYp/bK2hWZVSit1GdUoXwLtAsrBTSiAt4bRNfp837s+zj18hfe1JKw29S+Npv6Gz8CqiaXWPXIW8NRykkqKnLQmV6/9qBG+238bo9oUtBgs6FUP49pV1ziRZD5jZt1WNLCZn9oUACInvlL3yYCmBa1LaVkS/HzyIb4MU+96+6x1FUikMrRRCF6+DAvAezXKac1nMySYaVzZE5cfvZGvrN0j0Bf7rj3D5x1qAMgNFLacjcexuy/kw6/1qVfBA9tGBOOjDecBwGJDoTXNFpyvevkSGh/vX6NDMHffLdx8mh/oF/I04zbAMV3PlJ1ITU2Fh4cHUlJS4O5uH6vsEkJyPU95h8M3E9G3iR9KCAU4//AVBqw/h/HtqmOqhjVniG34f70fQO5im/smmD5p2vmHr1C2pNCgfKoHL9IRn5yBUCO7UBhjePz6HfxKu5gc9OU/3i/DAuT5Z7q8Ss/G3mvP0CuoAjzdnCGVMbxIy1Jr4br1LAV+pV3hbsRIvCdvMpGVI0P18ubnoAHAmmP35a1Y8T90w7htV7D/em7rWeTUtvDXETh98NMZXEl4i/WDG6NTXdvnztjy+m1SUvDatWvh7+8PkUiE4OBgXLhwQWf5Xbt2oVatWhCJRKhfvz4OHDhgUmUJIfbHx8MFn7SsghJ53WPBVcvg7vzOFMwUsvyJDFsa2B2hTXDVMgYnh1cvX8LoYAbIbbmqVMbVIi1Yhh6iTAkhhrWsAs+8YdF8Hqcx16uur4dRwQyQOwTfUsEMAHSskxuIlM9rKfquZ8HoM30ru28f2RxHp7QplGDG1oxuodm5cyeGDBmC8PBwBAcHY+XKldi1axdiYmJQvrz6vA1nz57Fe++9h4ULF6J79+7Ytm0bFi1ahCtXrqBePc2zdqqiFhpCCDHO49eZiIx5gX5N/Ayeqt+Rzf/3Ng7dTMSBz1vb5Wr25nr8OhNlSwjhkheoSqQyyJh1V563BFtev40OaIKDg9G0aVOsWbMGACCTyeDn54cJEybg66+/Vis/YMAAZGRk4N9//5Vva968OYKCghAeHq7xHNnZ2cjOzpbfTklJQaVKlfD48WMKaAghhGhkqaRrYjmpqanw8/PD27dv4eFh3QVQjUoKFovFuHz5MqZPny7fxuPxEBoaiqioKI37REVFYcqUKUrbwsLCsGfPHq3nWbhwIebNm6e23c/P/NVXCSGEEGJbaWlp9hXQJCcnQyqVwstLuY/Uy8sLd+/e1bhPYmKixvKJidrXopg+fbpSECSTyfD69WuUKVPGotF3fuRILT/2g14T+0OviX2h18P+0GuiHWMMaWlp8PW1zEzYutjlsG2hUAihUHmYXKlSpax2Pnd3d3oT2hl6TewPvSb2hV4P+0OviWbWbpnJZ1Q2UdmyZcHn85GUlKS0PSkpCd7emjOovb29jSpPCCGEEGIsowIaZ2dnNG7cGBEREfJtMpkMERERCAkJ0bhPSEiIUnkAOHLkiNbyhBBCCCHGMrrLacqUKRg6dCiaNGmCZs2aYeXKlcjIyMCwYcMAAEOGDEGFChWwcOFCAMDEiRPRpk0bLFu2DN26dcOOHTtw6dIlrF+/3rKPxARCoRBz5sxR694ihYdeE/tDr4l9odfD/tBrYh9Mmil4zZo1WLJkCRITExEUFIRVq1YhODh3CvK2bdvC398fmzdvlpfftWsXZs6cifj4eNSoUQOLFy9G165dLfYgCCGEEFK8OcTSB4QQQgghutj3FIOEEEIIIQaggIYQQgghDo8CGkIIIYQ4PApoCCGEEOLwinVAs3btWvj7+0MkEiE4OBgXLlwo7CoVSXPnzgXHcUr/atWqJb8/KysL48aNQ5kyZVCiRAn06dNHbTLGhIQEdOvWDa6urihfvjy+/PJLSCQSWz8Uh3Xy5En06NEDvr6+4DhObS01xhhmz54NHx8fuLi4IDQ0FPfv31cq8/r1awwaNAju7u4oVaoUhg8fjvT0dKUy169fR+vWrSESieDn54fFixdb+6E5JH2vxyeffKL2mencubNSGXo9LGvhwoVo2rQpSpYsifLly6NXr16IiYlRKmOp76rIyEg0atQIQqEQ1atXVxoVTExXbAOanTt3YsqUKZgzZw6uXLmCwMBAhIWF4cWLF4VdtSKpbt26eP78ufzf6dOn5fdNnjwZ+/btw65du3DixAk8e/YMH3zwgfx+qVSKbt26QSwW4+zZs9iyZQs2b96M2bNnF8ZDcUgZGRkIDAzE2rVrNd6/ePFirFq1CuHh4Th//jzc3NwQFhaGrKwseZlBgwbh1q1bOHLkCP7991+cPHkSI0eOlN+fmpqKTp06oXLlyrh8+TKWLFmCuXPn2sWcU/ZG3+sBAJ07d1b6zGzfvl3pfno9LOvEiRMYN24czp07hyNHjiAnJwedOnVCRkaGvIwlvqvi4uLQrVs3tGvXDtHR0Zg0aRI+++wzHD582KaPt0hixVSzZs3YuHHj5LelUinz9fVlCxcuLMRaFU1z5sxhgYGBGu97+/Ytc3JyYrt27ZJvu3PnDgPAoqKiGGOMHThwgPF4PJaYmCgvs27dOubu7s6ys7OtWveiCADbvXu3/LZMJmPe3t5syZIl8m1v375lQqGQbd++nTHG2O3btxkAdvHiRXmZgwcPMo7j2NOnTxljjP3000/M09NT6TWZNm0aCwgIsPIjcmyqrwdjjA0dOpT17NlT6z70eljfixcvGAB24sQJxpjlvqu++uorVrduXaVzDRgwgIWFhVn7IRV5xbKFRiwW4/LlywgNDZVv4/F4CA0NRVRUVCHWrOi6f/8+fH19UbVqVQwaNAgJCQkAgMuXLyMnJ0fptahVqxYqVaokfy2ioqJQv359pVXbw8LCkJqailu3btn2gRRBcXFxSExMVHoNPDw8EBwcrPQalCpVCk2aNJGXCQ0NBY/Hw/nz5+Vl3nvvPTg7O8vLhIWFISYmBm/evLHRoyk6IiMjUb58eQQEBGDMmDF49eqV/D56PawvJSUFAFC6dGkAlvuuioqKUjpGfhm69pivWAY0ycnJkEqlSm86APDy8kJiYmIh1aroCg4OxubNm3Ho0CGsW7cOcXFxaN26NdLS0pCYmAhnZ2e11dQVX4vExESNr1X+fcQ8+c+hrs9DYmIiypcvr3S/QCBA6dKl6XWygs6dO+O3335DREQEFi1ahBMnTqBLly6QSqUA6PWwNplMhkmTJqFly5aoV68eAFjsu0pbmdTUVLx7984aD6fYMHotJ0KM1aVLF/nfDRo0QHBwMCpXrow///wTLi4uhVgzQuzThx9+KP+7fv36aNCgAapVq4bIyEh06NChEGtWPIwbNw43b95UyvUj9q9YttCULVsWfD5fLTs9KSkJ3t7ehVSr4qNUqVKoWbMmHjx4AG9vb4jFYrx9+1apjOJr4e3trfG1yr+PmCf/OdT1efD29lZLmJdIJHj9+jW9TjZQtWpVlC1bFg8ePABAr4c1jR8/Hv/++y+OHz+OihUryrdb6rtKWxl3d3f6gWemYhnQODs7o3HjxoiIiJBvk8lkiIiIQEhISCHWrHhIT09HbGwsfHx80LhxYzg5OSm9FjExMUhISJC/FiEhIbhx44bSF/iRI0fg7u6OOnXq2Lz+RU2VKlXg7e2t9Bqkpqbi/PnzSq/B27dvcfnyZXmZY8eOQSaTyRemDQkJwcmTJ5GTkyMvc+TIEQQEBMDT09NGj6ZoevLkCV69egUfHx8A9HpYA2MM48ePx+7du3Hs2DFUqVJF6X5LfVeFhIQoHSO/DF17LKCws5ILy44dO5hQKGSbN29mt2/fZiNHjmSlSpVSyk4nlvHFF1+wyMhIFhcXx86cOcNCQ0NZ2bJl2YsXLxhjjI0ePZpVqlSJHTt2jF26dImFhISwkJAQ+f4SiYTVq1ePderUiUVHR7NDhw6xcuXKsenTpxfWQ3I4aWlp7OrVq+zq1asMAFv+//btHyS1MA7juBfxSIfwDxgiQqHgng5NbkLoJE3iEOLQkKs1uju1RIOTq6ubg2BDUE2SCCJE2uQUCIIKDk/DhQPSpeEi3nvs+4F3el/ec3784OU5h3NubtTtdvX+/i5Jqlar8vl8ajab6vV6ymazikQiWiwW1h7pdFrxeFzPz896eHhQLBZTPp+35qfTqYLBoM7Pz9Xv99VoNGSapmq12tbr/d9914/ZbKarqys9Pj5qNBqp3W4rkUgoFotpuVxae9CPzbq8vJTX69X9/b0mk4k15vO5tWYTZ9Xb25tM09T19bUGg4Hu7u7kdDrVarW2Wu8u+rGBRpJub291eHgowzB0cnKip6enf31LOymXyykUCskwDIXDYeVyOb2+vlrzi8VCpVJJfr9fpmnq7OxMk8lkbY/xeKxMJqO9vT0FAgGVy2WtVqttl2JbnU5HDofjyygUCpJ+/7pdqVQUDAbldruVSqU0HA7X9vj4+FA+n9f+/r48Ho+KxaJms9nampeXFyWTSbndboXDYVWr1W2VaCvf9WM+n+v09FQHBwdyuVw6OjrSxcXFl4ct+rFZf+qHw+FQvV631mzqrOp0Ojo+PpZhGIpGo2vXwN/7JUnbfisEAACwST/yGxoAALBbCDQAAMD2CDQAAMD2CDQAAMD2CDQAAMD2CDQAAMD2CDQAAMD2CDQAAMD2CDQAAMD2CDQAAMD2CDQAAMD2PgFFvO1Y7qCF/wAAAABJRU5ErkJggg==",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"406.818523pt\" height=\"300.989344pt\" viewBox=\"0 0 406.818523 300.989344\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-04-24T20:36:03.278219</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.6.3, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 300.989344 \n",
       "L 406.818523 300.989344 \n",
       "L 406.818523 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 277.111219 \n",
       "L 387.223125 277.111219 \n",
       "L 387.223125 10.999219 \n",
       "L 30.103125 10.999219 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"md7aed13f00\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#md7aed13f00\" x=\"46.335852\" y=\"277.111219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(43.154602 291.709656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md7aed13f00\" x=\"118.868146\" y=\"277.111219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 500 -->\n",
       "      <g transform=\"translate(109.324396 291.709656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md7aed13f00\" x=\"191.400439\" y=\"277.111219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 1000 -->\n",
       "      <g transform=\"translate(178.675439 291.709656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md7aed13f00\" x=\"263.932733\" y=\"277.111219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 1500 -->\n",
       "      <g transform=\"translate(251.207733 291.709656) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md7aed13f00\" x=\"336.465026\" y=\"277.111219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 2000 -->\n",
       "      <g transform=\"translate(323.740026 291.709656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <defs>\n",
       "       <path id=\"mc23ddc5293\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc23ddc5293\" x=\"30.103125\" y=\"277.111219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(7.2 280.910437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc23ddc5293\" x=\"30.103125\" y=\"223.888819\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(7.2 227.688037) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc23ddc5293\" x=\"30.103125\" y=\"170.666419\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 174.465637) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc23ddc5293\" x=\"30.103125\" y=\"117.444019\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 121.243237) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc23ddc5293\" x=\"30.103125\" y=\"64.221619\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(7.2 68.020837) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc23ddc5293\" x=\"30.103125\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(7.2 14.798437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_12\">\n",
       "    <path d=\"M 47.267642 -1 \n",
       "L 47.496369 59.581235 \n",
       "L 47.641434 27.567519 \n",
       "L 47.786498 32.133509 \n",
       "L 47.931563 42.625169 \n",
       "L 48.221692 88.262179 \n",
       "L 48.366756 79.593847 \n",
       "L 48.511821 85.411992 \n",
       "L 48.656886 128.898625 \n",
       "L 48.80195 133.588382 \n",
       "L 49.092079 114.325639 \n",
       "L 49.237144 150.565862 \n",
       "L 49.382209 152.691494 \n",
       "L 49.527273 170.05402 \n",
       "L 49.672338 155.268459 \n",
       "L 49.817402 205.379628 \n",
       "L 49.962467 177.234613 \n",
       "L 50.107532 98.54848 \n",
       "L 50.252596 189.117098 \n",
       "L 50.397661 163.369614 \n",
       "L 50.542725 169.743 \n",
       "L 50.68779 132.125982 \n",
       "L 50.977919 194.125021 \n",
       "L 51.122984 201.312935 \n",
       "L 51.268048 135.933427 \n",
       "L 51.558177 201.265358 \n",
       "L 51.703242 195.943877 \n",
       "L 51.848307 168.818162 \n",
       "L 51.993371 194.5531 \n",
       "L 52.138436 196.882045 \n",
       "L 52.2835 220.037909 \n",
       "L 52.428565 210.137804 \n",
       "L 52.57363 185.493599 \n",
       "L 52.718694 200.932703 \n",
       "L 52.863759 183.334237 \n",
       "L 53.008823 201.480662 \n",
       "L 53.153888 190.628319 \n",
       "L 53.298952 208.083611 \n",
       "L 53.444017 203.672501 \n",
       "L 53.589082 236.489615 \n",
       "L 53.734146 167.51778 \n",
       "L 54.024275 228.76885 \n",
       "L 54.16934 177.956669 \n",
       "L 54.314405 199.284588 \n",
       "L 54.459469 244.926666 \n",
       "L 54.604534 196.805125 \n",
       "L 54.749598 212.050912 \n",
       "L 55.039727 181.192298 \n",
       "L 55.184792 231.270591 \n",
       "L 55.329857 199.08762 \n",
       "L 55.474921 251.278823 \n",
       "L 55.619986 174.291756 \n",
       "L 56.05518 242.688341 \n",
       "L 56.345309 171.244942 \n",
       "L 56.635438 234.114774 \n",
       "L 56.780503 168.743566 \n",
       "L 56.925567 214.417299 \n",
       "L 57.070632 195.973379 \n",
       "L 57.215696 241.522278 \n",
       "L 57.360761 219.854272 \n",
       "L 57.505825 162.266208 \n",
       "L 57.65089 184.134958 \n",
       "L 57.941019 241.011446 \n",
       "L 58.086084 247.491762 \n",
       "L 58.231148 203.256247 \n",
       "L 58.376213 222.889309 \n",
       "L 58.521278 213.626527 \n",
       "L 58.666342 214.491194 \n",
       "L 58.811407 238.305595 \n",
       "L 58.956471 235.551117 \n",
       "L 59.101536 249.692305 \n",
       "L 59.53673 204.849171 \n",
       "L 59.681794 207.48066 \n",
       "L 59.826859 186.705784 \n",
       "L 60.116988 255.805587 \n",
       "L 60.262053 218.160996 \n",
       "L 60.552182 230.588506 \n",
       "L 60.697246 244.359555 \n",
       "L 60.842311 199.731288 \n",
       "L 60.987376 227.417211 \n",
       "L 61.13244 218.735504 \n",
       "L 61.277505 195.227618 \n",
       "L 61.422569 226.829189 \n",
       "L 61.567634 182.233337 \n",
       "L 61.712698 217.433857 \n",
       "L 61.857763 223.4213 \n",
       "L 62.002828 183.262646 \n",
       "L 62.147892 221.807106 \n",
       "L 62.292957 217.434047 \n",
       "L 62.438021 193.947642 \n",
       "L 62.583086 195.545745 \n",
       "L 62.728151 228.848804 \n",
       "L 62.873215 187.594266 \n",
       "L 63.01828 244.641056 \n",
       "L 63.308409 176.705838 \n",
       "L 63.888667 228.697655 \n",
       "L 64.033732 231.360922 \n",
       "L 64.178796 246.621772 \n",
       "L 64.323861 182.682662 \n",
       "L 64.468926 225.381465 \n",
       "L 64.61399 218.251542 \n",
       "L 64.759055 237.973761 \n",
       "L 64.904119 186.482104 \n",
       "L 65.049184 186.806655 \n",
       "L 65.194249 223.146123 \n",
       "L 65.339313 231.238781 \n",
       "L 65.484378 216.777337 \n",
       "L 65.629442 234.767297 \n",
       "L 65.919572 132.102 \n",
       "L 66.064636 220.563726 \n",
       "L 66.209701 222.927872 \n",
       "L 66.49983 173.323879 \n",
       "L 66.644894 190.494948 \n",
       "L 66.789959 190.282626 \n",
       "L 67.225153 245.885342 \n",
       "L 67.370217 166.510677 \n",
       "L 67.515282 208.505813 \n",
       "L 67.660347 122.821763 \n",
       "L 68.240605 244.469718 \n",
       "L 68.385669 213.456353 \n",
       "L 68.530734 253.760007 \n",
       "L 68.675799 239.329198 \n",
       "L 68.820863 202.345535 \n",
       "L 68.965928 231.940407 \n",
       "L 69.110992 181.81031 \n",
       "L 69.256057 178.765535 \n",
       "L 69.401122 235.116052 \n",
       "L 69.546186 195.261062 \n",
       "L 69.836315 251.19705 \n",
       "L 69.98138 183.025857 \n",
       "L 70.126445 235.83156 \n",
       "L 70.416574 197.412296 \n",
       "L 70.561638 206.398437 \n",
       "L 70.706703 233.990677 \n",
       "L 70.851767 237.891503 \n",
       "L 70.996832 249.073497 \n",
       "L 71.141897 202.632946 \n",
       "L 71.286961 228.503626 \n",
       "L 71.432026 207.387965 \n",
       "L 71.57709 251.840776 \n",
       "L 71.86722 216.681208 \n",
       "L 72.012284 205.389557 \n",
       "L 72.157349 156.990123 \n",
       "L 72.447478 224.849621 \n",
       "L 72.737607 177.523 \n",
       "L 72.882672 208.271499 \n",
       "L 73.027736 199.787914 \n",
       "L 73.172801 209.640664 \n",
       "L 73.317865 254.031798 \n",
       "L 73.46293 155.455212 \n",
       "L 73.607995 241.378537 \n",
       "L 73.753059 238.086853 \n",
       "L 73.898124 160.840782 \n",
       "L 74.188253 239.693026 \n",
       "L 74.333318 182.984086 \n",
       "L 74.478382 226.364923 \n",
       "L 74.623447 200.690053 \n",
       "L 74.768511 231.806888 \n",
       "L 74.913576 200.32278 \n",
       "L 75.05864 204.63543 \n",
       "L 75.203705 184.761162 \n",
       "L 75.34877 238.091826 \n",
       "L 75.493834 192.395553 \n",
       "L 75.638899 229.95788 \n",
       "L 75.783963 216.997086 \n",
       "L 75.929028 235.452772 \n",
       "L 76.074093 151.311852 \n",
       "L 76.219157 231.075427 \n",
       "L 76.364222 212.977994 \n",
       "L 76.509286 229.407288 \n",
       "L 76.654351 215.823767 \n",
       "L 76.94448 246.123421 \n",
       "L 77.089545 196.190991 \n",
       "L 77.234609 218.462452 \n",
       "L 77.379674 215.115987 \n",
       "L 77.524738 256.30755 \n",
       "L 77.669803 246.497876 \n",
       "L 77.814868 211.043659 \n",
       "L 77.959932 255.36427 \n",
       "L 78.104997 210.379279 \n",
       "L 78.250061 240.982951 \n",
       "L 78.540191 197.92931 \n",
       "L 78.685255 215.704151 \n",
       "L 78.83032 197.407918 \n",
       "L 78.975384 234.73777 \n",
       "L 79.120449 234.712118 \n",
       "L 79.265513 230.335527 \n",
       "L 79.410578 221.137171 \n",
       "L 79.555643 224.243906 \n",
       "L 79.700707 156.059718 \n",
       "L 79.845772 215.077225 \n",
       "L 80.135901 236.874364 \n",
       "L 80.280966 214.431816 \n",
       "L 80.42603 255.10698 \n",
       "L 80.571095 247.150719 \n",
       "L 80.716159 227.167143 \n",
       "L 80.861224 246.992336 \n",
       "L 81.006289 197.349413 \n",
       "L 81.151353 214.736781 \n",
       "L 81.296418 203.254772 \n",
       "L 81.441482 204.139377 \n",
       "L 81.586547 165.400895 \n",
       "L 81.731611 264.036747 \n",
       "L 81.876676 257.730203 \n",
       "L 82.021741 182.584455 \n",
       "L 82.31187 251.480514 \n",
       "L 82.601999 217.369951 \n",
       "L 82.747064 221.208837 \n",
       "L 83.037193 258.524898 \n",
       "L 83.182257 238.484747 \n",
       "L 83.327322 247.215534 \n",
       "L 83.472387 243.07445 \n",
       "L 83.617451 202.74101 \n",
       "L 84.052645 254.537744 \n",
       "L 84.197709 222.404327 \n",
       "L 84.342774 215.464861 \n",
       "L 84.487839 217.013749 \n",
       "L 84.632903 222.565528 \n",
       "L 84.777968 261.749816 \n",
       "L 84.923032 246.238857 \n",
       "L 85.068097 204.720083 \n",
       "L 85.213162 240.234272 \n",
       "L 85.358226 203.688252 \n",
       "L 85.503291 206.836183 \n",
       "L 85.648355 201.518785 \n",
       "L 85.79342 207.175159 \n",
       "L 85.938484 242.384518 \n",
       "L 86.083549 178.110359 \n",
       "L 86.228614 235.332125 \n",
       "L 86.373678 196.665885 \n",
       "L 86.518743 203.304427 \n",
       "L 86.663807 196.420682 \n",
       "L 86.808872 245.408055 \n",
       "L 86.953937 219.510946 \n",
       "L 87.099001 228.497749 \n",
       "L 87.244066 245.125288 \n",
       "L 87.38913 248.404209 \n",
       "L 87.534195 157.765108 \n",
       "L 87.67926 213.421981 \n",
       "L 87.824324 220.626113 \n",
       "L 87.969389 257.434873 \n",
       "L 88.259518 242.818306 \n",
       "L 88.404582 249.878138 \n",
       "L 88.549647 231.575699 \n",
       "L 88.694712 231.54072 \n",
       "L 88.839776 246.532125 \n",
       "L 89.129905 212.271958 \n",
       "L 89.27497 185.542699 \n",
       "L 89.420035 223.942993 \n",
       "L 89.565099 223.31525 \n",
       "L 89.710164 170.95217 \n",
       "L 89.855228 183.743726 \n",
       "L 90.000293 265.133251 \n",
       "L 90.145358 208.893801 \n",
       "L 90.290422 214.400165 \n",
       "L 90.435487 241.121525 \n",
       "L 90.580551 176.686273 \n",
       "L 90.725616 200.914819 \n",
       "L 90.87068 249.214879 \n",
       "L 91.16081 181.592302 \n",
       "L 91.450939 242.537205 \n",
       "L 91.596003 197.252412 \n",
       "L 91.741068 223.253668 \n",
       "L 92.031197 213.871076 \n",
       "L 92.321326 250.275368 \n",
       "L 92.466391 183.894196 \n",
       "L 92.611455 263.391635 \n",
       "L 92.75652 247.737778 \n",
       "L 92.901585 215.492309 \n",
       "L 93.046649 218.222642 \n",
       "L 93.191714 225.518017 \n",
       "L 93.481843 183.685617 \n",
       "L 93.626908 221.299418 \n",
       "L 93.917037 189.474767 \n",
       "L 94.207166 261.924432 \n",
       "L 94.352231 177.855322 \n",
       "L 94.64236 230.98299 \n",
       "L 94.787424 231.54139 \n",
       "L 94.932489 150.205393 \n",
       "L 95.077553 236.930458 \n",
       "L 95.222618 178.113999 \n",
       "L 95.367683 250.629831 \n",
       "L 95.512747 253.464271 \n",
       "L 95.657812 209.027672 \n",
       "L 95.802876 227.989645 \n",
       "L 95.947941 229.908325 \n",
       "L 96.093006 235.318199 \n",
       "L 96.23807 231.380864 \n",
       "L 96.528199 181.070458 \n",
       "L 96.818329 245.696003 \n",
       "L 97.108458 217.185244 \n",
       "L 97.253522 246.478554 \n",
       "L 97.398587 222.064463 \n",
       "L 97.543651 222.854096 \n",
       "L 97.688716 248.036563 \n",
       "L 97.833781 247.777945 \n",
       "L 97.978845 143.96051 \n",
       "L 98.268974 226.234303 \n",
       "L 98.414039 226.682847 \n",
       "L 98.559104 235.9975 \n",
       "L 98.704168 213.456666 \n",
       "L 99.284426 243.781735 \n",
       "L 99.574556 207.086025 \n",
       "L 99.71962 226.456674 \n",
       "L 100.009749 198.000988 \n",
       "L 100.154814 225.387382 \n",
       "L 100.299879 214.992909 \n",
       "L 100.444943 177.728477 \n",
       "L 100.590008 246.728367 \n",
       "L 100.735072 215.287315 \n",
       "L 100.880137 217.267383 \n",
       "L 101.025202 196.84604 \n",
       "L 101.315331 241.918384 \n",
       "L 101.460395 234.73549 \n",
       "L 101.60546 183.720711 \n",
       "L 101.750524 262.09657 \n",
       "L 101.895589 264.478236 \n",
       "L 102.040654 189.962747 \n",
       "L 102.185718 226.142759 \n",
       "L 102.330783 212.214143 \n",
       "L 102.475847 257.466575 \n",
       "L 102.620912 227.451123 \n",
       "L 102.765977 229.25972 \n",
       "L 102.911041 236.697829 \n",
       "L 103.056106 222.950931 \n",
       "L 103.20117 226.673489 \n",
       "L 103.346235 189.80046 \n",
       "L 103.4913 204.584062 \n",
       "L 103.636364 238.605624 \n",
       "L 103.781429 241.958478 \n",
       "L 103.926493 238.841913 \n",
       "L 104.071558 246.683523 \n",
       "L 104.216622 263.767929 \n",
       "L 104.506752 205.433161 \n",
       "L 104.651816 219.136634 \n",
       "L 104.796881 183.599227 \n",
       "L 104.941945 233.638183 \n",
       "L 105.08701 205.223329 \n",
       "L 105.232075 218.961915 \n",
       "L 105.377139 191.451833 \n",
       "L 105.667268 237.788256 \n",
       "L 105.812333 196.59837 \n",
       "L 105.957397 252.757869 \n",
       "L 106.247527 230.30311 \n",
       "L 106.537656 264.471042 \n",
       "L 106.68272 246.692385 \n",
       "L 106.827785 213.836042 \n",
       "L 106.97285 144.995838 \n",
       "L 107.262979 241.921766 \n",
       "L 107.408043 209.462809 \n",
       "L 107.553108 239.387933 \n",
       "L 107.698173 222.091554 \n",
       "L 107.843237 233.051553 \n",
       "L 107.988302 231.318274 \n",
       "L 108.133366 205.135083 \n",
       "L 108.278431 247.407702 \n",
       "L 108.423495 225.040197 \n",
       "L 108.56856 179.755523 \n",
       "L 108.713625 188.997843 \n",
       "L 109.003754 263.798815 \n",
       "L 109.293883 220.906941 \n",
       "L 109.438948 229.897836 \n",
       "L 109.584012 200.413968 \n",
       "L 109.729077 235.332454 \n",
       "L 109.874141 190.062841 \n",
       "L 110.019206 243.131016 \n",
       "L 110.164271 205.246756 \n",
       "L 110.309335 232.638638 \n",
       "L 110.599464 210.734141 \n",
       "L 110.744529 247.4995 \n",
       "L 110.889593 219.910113 \n",
       "L 111.034658 235.161812 \n",
       "L 111.179723 226.885545 \n",
       "L 111.324787 225.697284 \n",
       "L 111.469852 198.199598 \n",
       "L 111.614916 226.833293 \n",
       "L 111.759981 213.917289 \n",
       "L 111.905046 242.565101 \n",
       "L 112.05011 195.040389 \n",
       "L 112.195175 184.591849 \n",
       "L 112.485304 227.649118 \n",
       "L 112.630368 231.511666 \n",
       "L 112.775433 258.254832 \n",
       "L 112.920498 247.820977 \n",
       "L 113.065562 226.670677 \n",
       "L 113.210627 258.540502 \n",
       "L 113.355691 256.081744 \n",
       "L 113.645821 216.535223 \n",
       "L 113.790885 236.656668 \n",
       "L 113.93595 223.145246 \n",
       "L 114.081014 243.264074 \n",
       "L 114.226079 212.903381 \n",
       "L 114.371144 247.204161 \n",
       "L 114.516208 234.974369 \n",
       "L 114.806337 196.019671 \n",
       "L 114.951402 208.843187 \n",
       "L 115.096466 247.001262 \n",
       "L 115.241531 215.657947 \n",
       "L 115.386596 227.776391 \n",
       "L 115.53166 214.066997 \n",
       "L 115.676725 215.614871 \n",
       "L 115.821789 218.502756 \n",
       "L 115.966854 253.134276 \n",
       "L 116.111919 230.388199 \n",
       "L 116.256983 250.941175 \n",
       "L 116.402048 222.680032 \n",
       "L 116.547112 222.465446 \n",
       "L 116.692177 216.729606 \n",
       "L 116.837242 255.482833 \n",
       "L 116.982306 214.352675 \n",
       "L 117.127371 249.308186 \n",
       "L 117.272435 225.556343 \n",
       "L 117.4175 238.559843 \n",
       "L 117.562564 229.262127 \n",
       "L 117.707629 235.301405 \n",
       "L 117.852694 217.233685 \n",
       "L 117.997758 238.942463 \n",
       "L 118.142823 224.131856 \n",
       "L 118.287887 242.90474 \n",
       "L 118.578017 207.68567 \n",
       "L 118.868146 236.45851 \n",
       "L 119.01321 208.531215 \n",
       "L 119.158275 211.42487 \n",
       "L 119.303339 208.421509 \n",
       "L 119.448404 233.934314 \n",
       "L 119.593469 203.025367 \n",
       "L 119.883598 227.16079 \n",
       "L 120.173727 208.632332 \n",
       "L 120.318792 261.149775 \n",
       "L 120.463856 217.836418 \n",
       "L 120.753985 234.085351 \n",
       "L 120.89905 221.079376 \n",
       "L 121.044115 238.950382 \n",
       "L 121.189179 230.560879 \n",
       "L 121.334244 190.045758 \n",
       "L 121.479308 229.04781 \n",
       "L 121.769437 252.349599 \n",
       "L 121.914502 251.290019 \n",
       "L 122.059567 185.465263 \n",
       "L 122.204631 207.349889 \n",
       "L 122.349696 261.309951 \n",
       "L 122.49476 222.046143 \n",
       "L 122.639825 251.940016 \n",
       "L 122.929954 173.067779 \n",
       "L 123.075019 219.10152 \n",
       "L 123.220083 218.268192 \n",
       "L 123.365148 262.155735 \n",
       "L 123.510212 184.645508 \n",
       "L 123.655277 223.898256 \n",
       "L 123.800342 202.816241 \n",
       "L 123.945406 253.572659 \n",
       "L 124.090471 255.462461 \n",
       "L 124.235535 250.575971 \n",
       "L 124.3806 202.947828 \n",
       "L 124.670729 238.991903 \n",
       "L 124.815794 213.298103 \n",
       "L 124.960858 246.503998 \n",
       "L 125.105923 182.154117 \n",
       "L 125.250988 238.097183 \n",
       "L 125.541117 255.446486 \n",
       "L 125.686181 206.277278 \n",
       "L 125.831246 210.427435 \n",
       "L 125.97631 245.914919 \n",
       "L 126.121375 208.569893 \n",
       "L 126.411504 230.789456 \n",
       "L 126.556569 204.052876 \n",
       "L 126.846698 258.610104 \n",
       "L 126.991763 240.200982 \n",
       "L 127.136827 201.17651 \n",
       "L 127.281892 197.676667 \n",
       "L 127.572021 242.093039 \n",
       "L 127.717086 243.487087 \n",
       "L 127.86215 204.657342 \n",
       "L 128.007215 241.204033 \n",
       "L 128.152279 216.456748 \n",
       "L 128.297344 245.192239 \n",
       "L 128.587473 229.050522 \n",
       "L 128.732538 210.420464 \n",
       "L 129.022667 253.659267 \n",
       "L 129.167731 208.502783 \n",
       "L 129.457861 237.987988 \n",
       "L 129.602925 205.844243 \n",
       "L 129.893054 265.40465 \n",
       "L 130.038119 261.716759 \n",
       "L 130.328248 188.83309 \n",
       "L 130.618377 249.727991 \n",
       "L 130.763442 234.527677 \n",
       "L 130.908506 247.823827 \n",
       "L 131.053571 194.645921 \n",
       "L 131.198636 245.078944 \n",
       "L 131.3437 232.874043 \n",
       "L 131.488765 171.769244 \n",
       "L 131.633829 220.013978 \n",
       "L 131.778894 193.138499 \n",
       "L 131.923959 206.886567 \n",
       "L 132.069023 248.173817 \n",
       "L 132.214088 256.062777 \n",
       "L 132.359152 164.313446 \n",
       "L 132.504217 233.62068 \n",
       "L 132.649281 175.333667 \n",
       "L 132.939411 247.312336 \n",
       "L 133.084475 198.947627 \n",
       "L 133.22954 235.14693 \n",
       "L 133.374604 209.181442 \n",
       "L 133.519669 236.306549 \n",
       "L 133.664734 221.632609 \n",
       "L 133.809798 193.245025 \n",
       "L 134.099927 257.874667 \n",
       "L 134.244992 223.877271 \n",
       "L 134.390057 253.779981 \n",
       "L 134.680186 193.973298 \n",
       "L 134.82525 237.649607 \n",
       "L 135.115379 195.306085 \n",
       "L 135.260444 232.595063 \n",
       "L 135.405509 217.215567 \n",
       "L 135.550573 260.02397 \n",
       "L 135.695638 227.221928 \n",
       "L 135.840702 250.62166 \n",
       "L 135.985767 255.036611 \n",
       "L 136.130832 219.933691 \n",
       "L 136.275896 227.197676 \n",
       "L 136.420961 226.489182 \n",
       "L 136.566025 224.068993 \n",
       "L 136.71109 246.427815 \n",
       "L 136.856154 224.625466 \n",
       "L 137.001219 262.096793 \n",
       "L 137.146284 234.200557 \n",
       "L 137.291348 229.83899 \n",
       "L 137.436413 204.878515 \n",
       "L 137.581477 223.319691 \n",
       "L 137.726542 202.387108 \n",
       "L 137.871607 204.266753 \n",
       "L 138.016671 248.16181 \n",
       "L 138.161736 217.943543 \n",
       "L 138.3068 217.564865 \n",
       "L 138.59693 226.601002 \n",
       "L 138.741994 190.636155 \n",
       "L 138.887059 186.699027 \n",
       "L 139.032123 244.948041 \n",
       "L 139.177188 231.862511 \n",
       "L 139.322252 265.1664 \n",
       "L 139.467317 201.140576 \n",
       "L 139.612382 234.61706 \n",
       "L 139.757446 219.912559 \n",
       "L 140.047575 247.423422 \n",
       "L 140.19264 246.432941 \n",
       "L 140.337705 232.122338 \n",
       "L 140.482769 237.415027 \n",
       "L 140.917963 204.723128 \n",
       "L 141.063028 243.141251 \n",
       "L 141.208092 219.453765 \n",
       "L 141.498221 265.882954 \n",
       "L 141.643286 227.655721 \n",
       "L 141.78835 226.292114 \n",
       "L 141.933415 222.538571 \n",
       "L 142.07848 244.821514 \n",
       "L 142.223544 225.103691 \n",
       "L 142.368609 226.32887 \n",
       "L 142.513673 250.647806 \n",
       "L 142.658738 215.656087 \n",
       "L 142.803803 248.424234 \n",
       "L 142.948867 217.041756 \n",
       "L 143.093932 227.192208 \n",
       "L 143.238996 174.159463 \n",
       "L 143.67419 253.947197 \n",
       "L 143.964319 234.093638 \n",
       "L 144.109384 240.58679 \n",
       "L 144.254448 262.389992 \n",
       "L 144.399513 261.026669 \n",
       "L 144.544578 207.109794 \n",
       "L 144.689642 226.438251 \n",
       "L 144.834707 227.882437 \n",
       "L 144.979771 231.168605 \n",
       "L 145.124836 247.342225 \n",
       "L 145.269901 224.070611 \n",
       "L 145.414965 242.413521 \n",
       "L 145.56003 209.32644 \n",
       "L 145.705094 218.348368 \n",
       "L 145.850159 265.466777 \n",
       "L 146.140288 246.883895 \n",
       "L 146.285353 238.629904 \n",
       "L 146.430417 244.240652 \n",
       "L 146.575482 256.836341 \n",
       "L 146.720546 244.917524 \n",
       "L 146.865611 249.807449 \n",
       "L 147.010676 243.02589 \n",
       "L 147.15574 229.584147 \n",
       "L 147.300805 269.604167 \n",
       "L 147.445869 266.781364 \n",
       "L 147.590934 227.861754 \n",
       "L 147.735999 229.449828 \n",
       "L 147.881063 242.185123 \n",
       "L 148.026128 240.943924 \n",
       "L 148.171192 236.52796 \n",
       "L 148.461321 250.547159 \n",
       "L 148.606386 196.057128 \n",
       "L 148.751451 229.843257 \n",
       "L 148.896515 225.375276 \n",
       "L 149.04158 263.802895 \n",
       "L 149.331709 238.361063 \n",
       "L 149.476774 235.058752 \n",
       "L 149.621838 245.708373 \n",
       "L 149.766903 210.037289 \n",
       "L 150.057032 255.153748 \n",
       "L 150.347161 234.502084 \n",
       "L 150.492226 223.469709 \n",
       "L 150.782355 262.97783 \n",
       "L 151.072484 207.187245 \n",
       "L 151.362613 214.19452 \n",
       "L 151.507678 233.754055 \n",
       "L 151.652742 196.244524 \n",
       "L 151.942872 234.461796 \n",
       "L 152.087936 200.194032 \n",
       "L 152.233001 254.935946 \n",
       "L 152.378065 239.765092 \n",
       "L 152.52313 211.808239 \n",
       "L 152.668194 221.952754 \n",
       "L 152.813259 256.366717 \n",
       "L 152.958324 219.950627 \n",
       "L 153.103388 254.690239 \n",
       "L 153.248453 189.60752 \n",
       "L 153.393517 250.591545 \n",
       "L 153.538582 205.109554 \n",
       "L 153.828711 250.869673 \n",
       "L 153.973776 228.012787 \n",
       "L 154.11884 149.715811 \n",
       "L 154.263905 237.951896 \n",
       "L 154.40897 210.712264 \n",
       "L 154.554034 250.404915 \n",
       "L 154.699099 245.55728 \n",
       "L 154.844163 266.337013 \n",
       "L 154.989228 262.010895 \n",
       "L 155.134292 197.602808 \n",
       "L 155.424422 257.363588 \n",
       "L 155.569486 223.428672 \n",
       "L 155.714551 224.534782 \n",
       "L 155.859615 221.551454 \n",
       "L 156.00468 215.633076 \n",
       "L 156.149745 224.147817 \n",
       "L 156.439874 179.392025 \n",
       "L 156.584938 245.119233 \n",
       "L 156.730003 245.546165 \n",
       "L 157.020132 264.205219 \n",
       "L 157.165197 238.74992 \n",
       "L 157.310261 241.96874 \n",
       "L 157.60039 212.891172 \n",
       "L 157.89052 221.744064 \n",
       "L 158.035584 206.832273 \n",
       "L 158.180649 242.17536 \n",
       "L 158.325713 247.582535 \n",
       "L 158.470778 242.674696 \n",
       "L 158.615843 251.531681 \n",
       "L 158.760907 203.873046 \n",
       "L 159.196101 258.477343 \n",
       "L 159.341165 264.614287 \n",
       "L 159.48623 255.657284 \n",
       "L 159.776359 210.189473 \n",
       "L 159.921424 243.362511 \n",
       "L 160.066488 239.522879 \n",
       "L 160.211553 248.578154 \n",
       "L 160.356618 248.94957 \n",
       "L 160.501682 217.139007 \n",
       "L 160.791811 249.949765 \n",
       "L 160.936876 255.011094 \n",
       "L 161.37207 216.441148 \n",
       "L 161.517134 247.804477 \n",
       "L 161.662199 229.173398 \n",
       "L 161.807263 253.354583 \n",
       "L 161.952328 252.928588 \n",
       "L 162.097393 245.884767 \n",
       "L 162.242457 222.325761 \n",
       "L 162.387522 244.184018 \n",
       "L 162.532586 191.112809 \n",
       "L 162.677651 245.403988 \n",
       "L 162.822716 244.258478 \n",
       "L 162.96778 251.623735 \n",
       "L 163.112845 241.001093 \n",
       "L 163.402974 251.709139 \n",
       "L 163.548038 241.149223 \n",
       "L 163.693103 213.72682 \n",
       "L 163.838168 234.736394 \n",
       "L 164.273361 203.820893 \n",
       "L 164.418426 217.864477 \n",
       "L 164.563491 251.583774 \n",
       "L 164.708555 246.244595 \n",
       "L 164.85362 250.352883 \n",
       "L 164.998684 207.860876 \n",
       "L 165.143749 242.574923 \n",
       "L 165.288814 216.815944 \n",
       "L 165.433878 245.930949 \n",
       "L 165.724007 214.516996 \n",
       "L 165.869072 229.393139 \n",
       "L 166.014136 225.161542 \n",
       "L 166.44933 243.052605 \n",
       "L 166.594395 186.275865 \n",
       "L 166.739459 247.665725 \n",
       "L 166.884524 252.976197 \n",
       "L 167.029589 245.8546 \n",
       "L 167.174653 249.122307 \n",
       "L 167.319718 237.760891 \n",
       "L 167.464782 249.177807 \n",
       "L 167.609847 271.218718 \n",
       "L 167.754911 252.678531 \n",
       "L 167.899976 215.422594 \n",
       "L 168.045041 244.001779 \n",
       "L 168.190105 236.546637 \n",
       "L 168.33517 203.997551 \n",
       "L 168.480234 268.49048 \n",
       "L 168.625299 252.798891 \n",
       "L 168.770364 221.765065 \n",
       "L 168.915428 220.672429 \n",
       "L 169.060493 215.563047 \n",
       "L 169.205557 201.071015 \n",
       "L 169.350622 266.274685 \n",
       "L 169.495687 271.169283 \n",
       "L 169.640751 230.486782 \n",
       "L 169.93088 239.647955 \n",
       "L 170.075945 236.101484 \n",
       "L 170.221009 220.268206 \n",
       "L 170.366074 225.319736 \n",
       "L 170.511139 243.289096 \n",
       "L 170.656203 237.031036 \n",
       "L 170.801268 251.156467 \n",
       "L 170.946332 221.779618 \n",
       "L 171.091397 243.073554 \n",
       "L 171.236462 225.765711 \n",
       "L 171.381526 239.65401 \n",
       "L 171.526591 230.237812 \n",
       "L 171.671655 244.763207 \n",
       "L 171.81672 208.774031 \n",
       "L 172.251914 247.263965 \n",
       "L 172.396978 220.259839 \n",
       "L 172.542043 236.36162 \n",
       "L 172.687107 237.485349 \n",
       "L 172.832172 250.461443 \n",
       "L 172.977237 181.028766 \n",
       "L 173.122301 232.698274 \n",
       "L 173.267366 229.291205 \n",
       "L 173.557495 245.936194 \n",
       "L 173.70256 231.392883 \n",
       "L 173.847624 188.495993 \n",
       "L 173.992689 220.602448 \n",
       "L 174.137753 202.107589 \n",
       "L 174.427882 240.95833 \n",
       "L 174.572947 244.738656 \n",
       "L 174.718012 196.296018 \n",
       "L 175.008141 256.344973 \n",
       "L 175.153205 223.642334 \n",
       "L 175.443335 251.641674 \n",
       "L 175.733464 221.732652 \n",
       "L 175.878528 242.967654 \n",
       "L 176.023593 241.297758 \n",
       "L 176.168658 249.609856 \n",
       "L 176.313722 210.695292 \n",
       "L 176.458787 253.699454 \n",
       "L 176.603851 236.467405 \n",
       "L 176.748916 173.229891 \n",
       "L 177.039045 245.268761 \n",
       "L 177.18411 233.882228 \n",
       "L 177.329174 240.264088 \n",
       "L 177.474239 260.399071 \n",
       "L 177.619303 220.82736 \n",
       "L 177.909433 256.234399 \n",
       "L 178.054497 189.488844 \n",
       "L 178.199562 252.835959 \n",
       "L 178.344626 240.502752 \n",
       "L 178.489691 250.171717 \n",
       "L 178.634756 245.584032 \n",
       "L 178.77982 263.40276 \n",
       "L 178.924885 245.940332 \n",
       "L 179.069949 261.356057 \n",
       "L 179.360078 211.656321 \n",
       "L 179.505143 255.169558 \n",
       "L 179.650208 180.928974 \n",
       "L 179.795272 249.365809 \n",
       "L 179.940337 228.963463 \n",
       "L 180.230466 246.172076 \n",
       "L 180.375531 258.823709 \n",
       "L 180.520595 236.798046 \n",
       "L 180.810724 261.362691 \n",
       "L 180.955789 241.731281 \n",
       "L 181.100853 262.527815 \n",
       "L 181.245918 253.606783 \n",
       "L 181.390983 211.121832 \n",
       "L 181.536047 234.708661 \n",
       "L 181.681112 226.145035 \n",
       "L 181.971241 254.415629 \n",
       "L 182.116306 246.706536 \n",
       "L 182.26137 258.696565 \n",
       "L 182.551499 166.221459 \n",
       "L 182.696564 227.571203 \n",
       "L 182.841629 241.12923 \n",
       "L 182.986693 242.185341 \n",
       "L 183.131758 208.642967 \n",
       "L 183.276822 207.511399 \n",
       "L 183.421887 257.928343 \n",
       "L 183.566951 196.409602 \n",
       "L 183.712016 244.766494 \n",
       "L 183.857081 250.017676 \n",
       "L 184.002145 207.099373 \n",
       "L 184.292274 229.802961 \n",
       "L 184.437339 239.735943 \n",
       "L 184.727468 205.649638 \n",
       "L 184.872533 258.571061 \n",
       "L 185.017597 256.507576 \n",
       "L 185.162662 219.306233 \n",
       "L 185.307727 246.118976 \n",
       "L 185.452791 232.371927 \n",
       "L 185.597856 207.841985 \n",
       "L 185.74292 210.664529 \n",
       "L 185.887985 247.549482 \n",
       "L 186.033049 250.739983 \n",
       "L 186.178114 218.911587 \n",
       "L 186.323179 243.775267 \n",
       "L 186.468243 216.883764 \n",
       "L 186.613308 248.549972 \n",
       "L 186.758372 246.016574 \n",
       "L 186.903437 228.65818 \n",
       "L 187.048502 259.68486 \n",
       "L 187.193566 261.406539 \n",
       "L 187.338631 250.816253 \n",
       "L 187.483695 207.675447 \n",
       "L 187.773824 266.867997 \n",
       "L 187.918889 247.506473 \n",
       "L 188.063954 201.388261 \n",
       "L 188.209018 251.260282 \n",
       "L 188.354083 249.887988 \n",
       "L 188.499147 211.714033 \n",
       "L 188.644212 239.002685 \n",
       "L 188.789277 216.043552 \n",
       "L 189.079406 242.738915 \n",
       "L 189.22447 216.715787 \n",
       "L 189.369535 265.486207 \n",
       "L 189.5146 208.152862 \n",
       "L 189.659664 270.408356 \n",
       "L 189.949793 230.355798 \n",
       "L 190.094858 232.747865 \n",
       "L 190.239922 254.857324 \n",
       "L 190.384987 254.49746 \n",
       "L 190.530052 251.552558 \n",
       "L 190.675116 198.175702 \n",
       "L 190.820181 263.991319 \n",
       "L 190.965245 262.279395 \n",
       "L 191.11031 251.036917 \n",
       "L 191.255375 210.867191 \n",
       "L 191.545504 227.457836 \n",
       "L 191.690568 205.132149 \n",
       "L 191.980698 268.877655 \n",
       "L 192.125762 227.99394 \n",
       "L 192.270827 260.848874 \n",
       "L 192.415891 195.188417 \n",
       "L 192.70602 258.169622 \n",
       "L 192.851085 235.008959 \n",
       "L 193.141214 260.49532 \n",
       "L 193.286279 221.231023 \n",
       "L 193.431343 225.528775 \n",
       "L 193.721473 258.07111 \n",
       "L 193.866537 240.947683 \n",
       "L 194.011602 246.701339 \n",
       "L 194.156666 210.760007 \n",
       "L 194.446795 269.300042 \n",
       "L 194.59186 252.019055 \n",
       "L 194.736925 269.521945 \n",
       "L 195.317183 210.047623 \n",
       "L 195.462248 257.560621 \n",
       "L 195.607312 243.95863 \n",
       "L 195.752377 243.477729 \n",
       "L 195.897441 201.045026 \n",
       "L 196.187571 241.963101 \n",
       "L 196.332635 237.963003 \n",
       "L 196.622764 259.97602 \n",
       "L 196.767829 255.975029 \n",
       "L 196.912893 209.787804 \n",
       "L 197.057958 205.547363 \n",
       "L 197.203023 237.987624 \n",
       "L 197.348087 212.447077 \n",
       "L 197.638216 273.663484 \n",
       "L 197.783281 240.170298 \n",
       "L 197.928346 264.727527 \n",
       "L 198.07341 256.098826 \n",
       "L 198.218475 263.600687 \n",
       "L 198.363539 249.442379 \n",
       "L 198.653669 259.005809 \n",
       "L 198.798733 255.59795 \n",
       "L 198.943798 232.134472 \n",
       "L 199.088862 266.581034 \n",
       "L 199.233927 267.55334 \n",
       "L 199.378991 231.107257 \n",
       "L 199.524056 249.651828 \n",
       "L 199.669121 197.036814 \n",
       "L 199.814185 215.466649 \n",
       "L 199.95925 257.569482 \n",
       "L 200.104314 246.401852 \n",
       "L 200.394444 260.635641 \n",
       "L 200.539508 241.188207 \n",
       "L 200.684573 274.082142 \n",
       "L 200.829637 237.494275 \n",
       "L 200.974702 240.187203 \n",
       "L 201.119766 266.435611 \n",
       "L 201.264831 247.213932 \n",
       "L 201.409896 246.52003 \n",
       "L 201.55496 210.755685 \n",
       "L 201.845089 263.810672 \n",
       "L 201.990154 221.499967 \n",
       "L 202.135219 264.683796 \n",
       "L 202.425348 221.853544 \n",
       "L 202.570412 223.951499 \n",
       "L 202.715477 252.674318 \n",
       "L 202.860542 247.893601 \n",
       "L 203.005606 234.106518 \n",
       "L 203.150671 265.543868 \n",
       "L 203.295735 270.713069 \n",
       "L 203.4408 253.486658 \n",
       "L 203.585864 253.367758 \n",
       "L 203.730929 233.397025 \n",
       "L 203.875994 265.501986 \n",
       "L 204.021058 245.882526 \n",
       "L 204.166123 244.636785 \n",
       "L 204.311187 252.428717 \n",
       "L 204.456252 249.113133 \n",
       "L 204.601317 219.028843 \n",
       "L 204.746381 247.537453 \n",
       "L 204.891446 195.532064 \n",
       "L 205.181575 268.763326 \n",
       "L 205.32664 247.236649 \n",
       "L 205.471704 261.290451 \n",
       "L 205.616769 257.235222 \n",
       "L 205.761833 243.874423 \n",
       "L 205.906898 253.844214 \n",
       "L 206.051962 247.697852 \n",
       "L 206.197027 259.085458 \n",
       "L 206.487156 213.253524 \n",
       "L 206.777285 261.79976 \n",
       "L 206.92235 220.942019 \n",
       "L 207.067415 257.584697 \n",
       "L 207.212479 252.597816 \n",
       "L 207.357544 229.340887 \n",
       "L 207.502608 246.394744 \n",
       "L 207.792737 231.860354 \n",
       "L 207.937802 257.669996 \n",
       "L 208.082867 243.498848 \n",
       "L 208.227931 201.360202 \n",
       "L 208.51806 268.555293 \n",
       "L 208.663125 262.247928 \n",
       "L 208.953254 222.198294 \n",
       "L 209.098319 246.374253 \n",
       "L 209.243383 198.897012 \n",
       "L 209.533513 242.689745 \n",
       "L 209.678577 212.367377 \n",
       "L 209.968706 239.567359 \n",
       "L 210.113771 243.584699 \n",
       "L 210.258835 235.656207 \n",
       "L 210.548965 216.697197 \n",
       "L 210.694029 251.173106 \n",
       "L 210.839094 232.777133 \n",
       "L 211.129223 265.708161 \n",
       "L 211.274288 191.658945 \n",
       "L 211.419352 210.576137 \n",
       "L 211.564417 266.702503 \n",
       "L 211.854546 231.615301 \n",
       "L 212.144675 249.863476 \n",
       "L 212.28974 251.290538 \n",
       "L 212.434804 228.169241 \n",
       "L 212.579869 253.128433 \n",
       "L 212.724933 244.624976 \n",
       "L 212.869998 224.814539 \n",
       "L 213.015063 237.330505 \n",
       "L 213.160127 267.794509 \n",
       "L 213.305192 245.691984 \n",
       "L 213.450256 263.347589 \n",
       "L 213.595321 248.416504 \n",
       "L 213.740386 208.579125 \n",
       "L 213.88545 255.712018 \n",
       "L 214.030515 212.572347 \n",
       "L 214.175579 214.687758 \n",
       "L 214.465708 253.524773 \n",
       "L 214.610773 235.819161 \n",
       "L 214.755838 260.780955 \n",
       "L 215.045967 227.087534 \n",
       "L 215.191031 248.631382 \n",
       "L 215.336096 251.370345 \n",
       "L 215.481161 247.088659 \n",
       "L 215.626225 249.403619 \n",
       "L 215.77129 238.300056 \n",
       "L 215.916354 248.360753 \n",
       "L 216.061419 239.319301 \n",
       "L 216.206484 223.193719 \n",
       "L 216.351548 239.829276 \n",
       "L 216.496613 242.625585 \n",
       "L 216.641677 248.8107 \n",
       "L 216.786742 200.264505 \n",
       "L 216.931806 259.885179 \n",
       "L 217.076871 227.396425 \n",
       "L 217.221936 245.875839 \n",
       "L 217.367 247.56339 \n",
       "L 217.512065 241.060014 \n",
       "L 217.802194 245.677984 \n",
       "L 217.947259 262.715645 \n",
       "L 218.382452 225.494618 \n",
       "L 218.527517 265.471125 \n",
       "L 218.817646 267.031288 \n",
       "L 218.962711 262.630711 \n",
       "L 219.107775 248.203595 \n",
       "L 219.25284 272.437266 \n",
       "L 219.542969 242.3082 \n",
       "L 219.688034 246.400046 \n",
       "L 219.978163 239.990036 \n",
       "L 220.123227 223.130515 \n",
       "L 220.268292 245.64136 \n",
       "L 220.413357 226.093635 \n",
       "L 220.558421 242.029375 \n",
       "L 220.703486 271.358527 \n",
       "L 220.84855 250.355934 \n",
       "L 220.993615 254.821511 \n",
       "L 221.138679 255.549293 \n",
       "L 221.283744 211.979932 \n",
       "L 221.428809 257.023202 \n",
       "L 221.573873 242.938723 \n",
       "L 221.718938 264.451483 \n",
       "L 221.864002 204.647984 \n",
       "L 222.009067 205.981366 \n",
       "L 222.444261 273.193043 \n",
       "L 222.589325 273.188723 \n",
       "L 222.879455 258.216255 \n",
       "L 223.169584 216.313202 \n",
       "L 223.314648 247.735541 \n",
       "L 223.459713 252.645062 \n",
       "L 223.604777 220.782789 \n",
       "L 223.749842 267.141505 \n",
       "L 223.894907 258.227971 \n",
       "L 224.039971 263.486711 \n",
       "L 224.185036 236.951074 \n",
       "L 224.3301 257.008383 \n",
       "L 224.62023 250.320886 \n",
       "L 224.765294 209.369662 \n",
       "L 224.910359 257.046379 \n",
       "L 225.200488 265.944234 \n",
       "L 225.345552 252.014164 \n",
       "L 225.490617 250.799958 \n",
       "L 225.635682 233.000713 \n",
       "L 225.780746 262.642871 \n",
       "L 225.925811 260.948093 \n",
       "L 226.070875 216.897425 \n",
       "L 226.361005 257.147705 \n",
       "L 226.506069 218.393915 \n",
       "L 226.651134 268.769165 \n",
       "L 226.796198 235.115806 \n",
       "L 226.941263 249.078234 \n",
       "L 227.086328 234.528557 \n",
       "L 227.231392 267.246027 \n",
       "L 227.376457 268.187177 \n",
       "L 227.521521 221.293098 \n",
       "L 227.666586 248.700591 \n",
       "L 227.81165 249.489872 \n",
       "L 227.956715 248.833394 \n",
       "L 228.10178 255.940602 \n",
       "L 228.391909 217.074661 \n",
       "L 228.536973 223.3315 \n",
       "L 228.827103 259.752218 \n",
       "L 228.972167 234.45032 \n",
       "L 229.117232 245.099784 \n",
       "L 229.262296 241.818872 \n",
       "L 229.407361 228.718601 \n",
       "L 229.552426 251.590454 \n",
       "L 229.69749 235.741003 \n",
       "L 229.842555 254.439455 \n",
       "L 229.987619 253.173563 \n",
       "L 230.132684 270.802143 \n",
       "L 230.277748 202.71399 \n",
       "L 230.422813 259.667845 \n",
       "L 230.567878 235.708451 \n",
       "L 230.712942 258.677307 \n",
       "L 230.858007 235.591128 \n",
       "L 231.003071 239.964368 \n",
       "L 231.148136 253.944346 \n",
       "L 231.293201 218.445492 \n",
       "L 231.58333 236.884206 \n",
       "L 231.728394 227.294883 \n",
       "L 231.873459 226.253734 \n",
       "L 232.163588 240.258461 \n",
       "L 232.308653 234.898523 \n",
       "L 232.453717 257.142274 \n",
       "L 232.743846 202.926003 \n",
       "L 232.888911 268.047846 \n",
       "L 233.033976 219.36799 \n",
       "L 233.17904 214.330834 \n",
       "L 233.469169 273.136607 \n",
       "L 233.904363 237.661812 \n",
       "L 234.049428 258.633046 \n",
       "L 234.194492 246.392658 \n",
       "L 234.339557 260.95783 \n",
       "L 234.484621 211.511018 \n",
       "L 234.629686 226.622561 \n",
       "L 234.774751 200.131498 \n",
       "L 235.06488 264.137218 \n",
       "L 235.209944 219.945309 \n",
       "L 235.355009 268.712802 \n",
       "L 235.500074 268.520431 \n",
       "L 235.645138 257.736716 \n",
       "L 235.790203 232.426855 \n",
       "L 235.935267 241.425245 \n",
       "L 236.080332 216.114826 \n",
       "L 236.370461 266.546326 \n",
       "L 236.515526 187.879575 \n",
       "L 236.66059 251.575903 \n",
       "L 236.805655 220.635309 \n",
       "L 237.095784 264.406192 \n",
       "L 237.240849 236.308583 \n",
       "L 237.530978 264.639134 \n",
       "L 237.676042 236.889412 \n",
       "L 237.821107 261.887413 \n",
       "L 237.966172 212.013178 \n",
       "L 238.401365 267.840803 \n",
       "L 238.54643 259.876029 \n",
       "L 238.836559 223.99538 \n",
       "L 238.981624 207.672378 \n",
       "L 239.126688 261.761957 \n",
       "L 239.271753 272.289726 \n",
       "L 239.416817 251.610219 \n",
       "L 239.561882 269.676628 \n",
       "L 239.706947 264.841451 \n",
       "L 239.852011 263.73442 \n",
       "L 239.997076 255.100541 \n",
       "L 240.14214 231.691833 \n",
       "L 240.287205 258.938094 \n",
       "L 240.43227 259.078873 \n",
       "L 240.722399 216.059949 \n",
       "L 240.867463 265.020923 \n",
       "L 241.012528 259.661104 \n",
       "L 241.157592 261.761795 \n",
       "L 241.302657 229.601432 \n",
       "L 241.447722 243.334809 \n",
       "L 241.592786 218.877675 \n",
       "L 241.882915 253.953964 \n",
       "L 242.02798 252.677243 \n",
       "L 242.173045 256.01707 \n",
       "L 242.318109 252.063505 \n",
       "L 242.463174 252.261973 \n",
       "L 242.608238 245.042138 \n",
       "L 242.753303 259.027766 \n",
       "L 242.898368 232.990792 \n",
       "L 243.043432 263.312279 \n",
       "L 243.188497 256.016503 \n",
       "L 243.333561 240.591239 \n",
       "L 243.478626 240.267351 \n",
       "L 243.62369 263.988329 \n",
       "L 243.768755 267.314932 \n",
       "L 243.91382 243.198285 \n",
       "L 244.058884 266.468558 \n",
       "L 244.349013 226.157379 \n",
       "L 244.639143 261.845349 \n",
       "L 244.929272 240.747519 \n",
       "L 245.074336 242.784846 \n",
       "L 245.219401 241.854823 \n",
       "L 245.364465 237.661582 \n",
       "L 245.654595 271.652269 \n",
       "L 245.799659 220.336557 \n",
       "L 245.944724 254.412948 \n",
       "L 246.089788 246.192155 \n",
       "L 246.234853 261.112694 \n",
       "L 246.379918 232.386563 \n",
       "L 246.670047 263.372558 \n",
       "L 246.815111 250.446061 \n",
       "L 246.960176 256.315877 \n",
       "L 247.105241 228.592732 \n",
       "L 247.250305 237.534662 \n",
       "L 247.39537 234.545422 \n",
       "L 247.540434 236.565552 \n",
       "L 247.685499 269.255373 \n",
       "L 247.830563 255.626144 \n",
       "L 247.975628 222.648694 \n",
       "L 248.120693 232.844608 \n",
       "L 248.265757 261.060167 \n",
       "L 248.410822 249.001688 \n",
       "L 248.555886 211.819976 \n",
       "L 248.700951 269.175245 \n",
       "L 248.846016 262.58251 \n",
       "L 248.99108 242.606151 \n",
       "L 249.136145 253.004787 \n",
       "L 249.281209 250.4384 \n",
       "L 249.426274 241.931576 \n",
       "L 249.571339 216.350163 \n",
       "L 249.716403 216.81205 \n",
       "L 249.861468 228.733879 \n",
       "L 250.006532 250.88811 \n",
       "L 250.151597 209.408277 \n",
       "L 250.296661 266.35029 \n",
       "L 250.441726 250.880332 \n",
       "L 250.586791 203.494297 \n",
       "L 250.731855 271.870175 \n",
       "L 251.021984 244.847608 \n",
       "L 251.167049 261.208333 \n",
       "L 251.312114 259.793597 \n",
       "L 251.457178 266.563943 \n",
       "L 251.602243 241.34179 \n",
       "L 251.747307 261.531665 \n",
       "L 251.892372 232.901404 \n",
       "L 252.037436 265.325983 \n",
       "L 252.182501 237.660313 \n",
       "L 252.327566 262.728609 \n",
       "L 252.47263 256.594562 \n",
       "L 252.617695 227.839429 \n",
       "L 252.762759 264.217818 \n",
       "L 252.907824 215.367733 \n",
       "L 253.052889 242.467882 \n",
       "L 253.343018 252.341175 \n",
       "L 253.488082 247.800435 \n",
       "L 253.633147 263.655261 \n",
       "L 253.778212 254.493505 \n",
       "L 253.923276 261.177585 \n",
       "L 254.068341 232.423001 \n",
       "L 254.213405 240.614155 \n",
       "L 254.35847 209.03615 \n",
       "L 254.503534 258.677135 \n",
       "L 254.648599 215.026393 \n",
       "L 254.793664 247.338952 \n",
       "L 254.938728 227.477842 \n",
       "L 255.083793 270.152682 \n",
       "L 255.228857 254.834634 \n",
       "L 255.373922 256.144238 \n",
       "L 255.518987 214.806953 \n",
       "L 255.664051 256.227144 \n",
       "L 255.809116 216.959134 \n",
       "L 255.95418 264.160012 \n",
       "L 256.099245 263.408334 \n",
       "L 256.244309 233.349575 \n",
       "L 256.389374 240.450682 \n",
       "L 256.534439 256.581661 \n",
       "L 256.679503 242.580768 \n",
       "L 256.824568 254.757916 \n",
       "L 257.114697 222.565928 \n",
       "L 257.259762 246.637978 \n",
       "L 257.404826 224.852762 \n",
       "L 257.549891 238.703216 \n",
       "L 257.694955 265.910791 \n",
       "L 257.84002 253.591187 \n",
       "L 257.985085 254.406485 \n",
       "L 258.275214 230.816801 \n",
       "L 258.420278 257.49637 \n",
       "L 258.565343 236.751171 \n",
       "L 258.710407 260.919797 \n",
       "L 258.855472 237.717982 \n",
       "L 259.000537 265.481153 \n",
       "L 259.145601 230.763177 \n",
       "L 259.43573 259.00299 \n",
       "L 259.580795 257.761793 \n",
       "L 259.72586 242.152852 \n",
       "L 259.870924 241.17116 \n",
       "L 260.015989 229.822855 \n",
       "L 260.161053 262.80203 \n",
       "L 260.306118 258.368107 \n",
       "L 260.451183 259.65532 \n",
       "L 260.596247 239.171792 \n",
       "L 260.741312 245.527367 \n",
       "L 260.886376 258.810895 \n",
       "L 261.031441 245.822479 \n",
       "L 261.466635 254.673015 \n",
       "L 261.611699 255.119749 \n",
       "L 261.756764 250.794121 \n",
       "L 261.901828 250.579578 \n",
       "L 262.046893 231.943325 \n",
       "L 262.191958 265.580123 \n",
       "L 262.337022 256.862293 \n",
       "L 262.482087 257.116747 \n",
       "L 262.627151 237.969597 \n",
       "L 262.772216 264.881757 \n",
       "L 262.91728 242.701704 \n",
       "L 263.062345 268.405242 \n",
       "L 263.20741 220.036362 \n",
       "L 263.352474 243.987663 \n",
       "L 263.497539 239.728095 \n",
       "L 263.642603 258.755582 \n",
       "L 263.787668 242.62183 \n",
       "L 263.932733 247.715707 \n",
       "L 264.077797 206.204712 \n",
       "L 264.222862 268.641325 \n",
       "L 264.367926 249.817833 \n",
       "L 264.658056 272.093247 \n",
       "L 264.80312 264.77754 \n",
       "L 264.948185 268.398693 \n",
       "L 265.238314 253.885993 \n",
       "L 265.383378 196.485103 \n",
       "L 265.528443 259.805257 \n",
       "L 265.673508 258.809129 \n",
       "L 265.818572 268.766043 \n",
       "L 265.963637 226.320511 \n",
       "L 266.108701 244.652799 \n",
       "L 266.253766 241.637611 \n",
       "L 266.543895 254.796715 \n",
       "L 266.68896 231.083544 \n",
       "L 266.834024 261.204282 \n",
       "L 266.979089 209.949678 \n",
       "L 267.124154 260.410503 \n",
       "L 267.269218 254.714757 \n",
       "L 267.414283 266.378294 \n",
       "L 267.559347 264.823169 \n",
       "L 267.704412 248.224853 \n",
       "L 267.849476 246.674474 \n",
       "L 267.994541 272.031721 \n",
       "L 268.139606 238.989008 \n",
       "L 268.28467 266.83395 \n",
       "L 268.429735 236.57171 \n",
       "L 268.574799 231.372509 \n",
       "L 268.719864 219.348714 \n",
       "L 269.009993 257.328837 \n",
       "L 269.155058 267.626993 \n",
       "L 269.300122 258.908372 \n",
       "L 269.445187 230.253226 \n",
       "L 269.735316 261.966831 \n",
       "L 269.880381 236.038184 \n",
       "L 270.025445 266.156505 \n",
       "L 270.17051 262.043081 \n",
       "L 270.315574 252.314147 \n",
       "L 270.460639 258.479647 \n",
       "L 270.605704 247.162358 \n",
       "L 270.750768 246.158029 \n",
       "L 270.895833 252.286282 \n",
       "L 271.040897 275.097126 \n",
       "L 271.331027 242.230094 \n",
       "L 271.476091 270.311609 \n",
       "L 271.621156 247.535115 \n",
       "L 271.76622 262.418666 \n",
       "L 271.911285 244.60598 \n",
       "L 272.056349 267.32472 \n",
       "L 272.201414 251.961863 \n",
       "L 272.636608 245.878026 \n",
       "L 272.781672 255.692096 \n",
       "L 272.926737 248.38372 \n",
       "L 273.071802 220.945492 \n",
       "L 273.216866 264.624534 \n",
       "L 273.361931 273.129696 \n",
       "L 273.506995 254.61636 \n",
       "L 273.65206 252.377361 \n",
       "L 273.797125 238.66451 \n",
       "L 273.942189 270.076553 \n",
       "L 274.232318 232.14073 \n",
       "L 274.377383 259.068038 \n",
       "L 274.522447 259.770665 \n",
       "L 274.667512 247.359106 \n",
       "L 274.812577 260.200457 \n",
       "L 274.957641 256.224438 \n",
       "L 275.102706 266.202831 \n",
       "L 275.24777 238.848943 \n",
       "L 275.392835 270.903375 \n",
       "L 275.5379 206.255413 \n",
       "L 275.682964 256.705468 \n",
       "L 276.118158 251.257923 \n",
       "L 276.263222 223.336699 \n",
       "L 276.408287 236.949004 \n",
       "L 276.553352 267.226788 \n",
       "L 276.698416 254.935916 \n",
       "L 276.843481 272.722294 \n",
       "L 276.988545 217.950153 \n",
       "L 277.13361 269.453434 \n",
       "L 277.423739 251.454362 \n",
       "L 277.568804 259.277578 \n",
       "L 277.713868 253.964839 \n",
       "L 277.858933 256.806056 \n",
       "L 278.149062 272.12366 \n",
       "L 278.294127 209.184868 \n",
       "L 278.439191 247.213834 \n",
       "L 278.584256 248.059186 \n",
       "L 278.72932 225.073443 \n",
       "L 278.874385 257.387868 \n",
       "L 279.164514 237.648996 \n",
       "L 279.454643 265.701312 \n",
       "L 279.599708 241.497423 \n",
       "L 279.744773 259.209477 \n",
       "L 279.889837 236.796127 \n",
       "L 280.034902 271.377858 \n",
       "L 280.325031 249.194759 \n",
       "L 280.470096 265.495654 \n",
       "L 280.61516 241.644713 \n",
       "L 280.760225 257.574072 \n",
       "L 280.905289 223.105509 \n",
       "L 281.195418 241.310567 \n",
       "L 281.340483 245.79575 \n",
       "L 281.485548 271.723062 \n",
       "L 281.630612 270.098899 \n",
       "L 281.920741 223.859633 \n",
       "L 282.210871 255.948428 \n",
       "L 282.355935 250.090928 \n",
       "L 282.501 237.059725 \n",
       "L 282.646064 255.907868 \n",
       "L 282.791129 244.114055 \n",
       "L 282.936193 269.822947 \n",
       "L 283.081258 269.794162 \n",
       "L 283.226323 263.543414 \n",
       "L 283.371387 244.400413 \n",
       "L 283.661516 273.578706 \n",
       "L 283.806581 246.224752 \n",
       "L 283.951646 251.327547 \n",
       "L 284.09671 267.908174 \n",
       "L 284.386839 240.306263 \n",
       "L 284.531904 264.752155 \n",
       "L 284.822033 253.021991 \n",
       "L 284.967098 259.56918 \n",
       "L 285.112162 259.862866 \n",
       "L 285.257227 210.795898 \n",
       "L 285.402291 208.270166 \n",
       "L 285.547356 260.660262 \n",
       "L 285.692421 261.31924 \n",
       "L 285.837485 263.844473 \n",
       "L 285.98255 264.092852 \n",
       "L 286.127614 230.293902 \n",
       "L 286.272679 251.658864 \n",
       "L 286.417744 233.512346 \n",
       "L 286.707873 263.500178 \n",
       "L 286.852937 225.323888 \n",
       "L 286.998002 232.09621 \n",
       "L 287.288131 271.430433 \n",
       "L 287.433196 238.798785 \n",
       "L 287.57826 232.99187 \n",
       "L 287.723325 261.832867 \n",
       "L 287.868389 250.125377 \n",
       "L 288.013454 249.590095 \n",
       "L 288.158519 207.253634 \n",
       "L 288.303583 243.16603 \n",
       "L 288.448648 222.915242 \n",
       "L 288.738777 253.817971 \n",
       "L 288.883842 243.560661 \n",
       "L 289.028906 255.603707 \n",
       "L 289.173971 228.548264 \n",
       "L 289.4641 263.239819 \n",
       "L 289.609164 260.442666 \n",
       "L 289.754229 226.512649 \n",
       "L 289.899294 252.188938 \n",
       "L 290.044358 214.135801 \n",
       "L 290.189423 257.432084 \n",
       "L 290.334487 249.735012 \n",
       "L 290.479552 192.145949 \n",
       "L 290.624617 258.6896 \n",
       "L 290.769681 235.53474 \n",
       "L 290.914746 237.95866 \n",
       "L 291.05981 253.45315 \n",
       "L 291.204875 243.798171 \n",
       "L 291.34994 248.079887 \n",
       "L 291.495004 262.832599 \n",
       "L 291.640069 258.613229 \n",
       "L 291.785133 273.608237 \n",
       "L 291.930198 249.714154 \n",
       "L 292.075262 257.364589 \n",
       "L 292.365392 245.119449 \n",
       "L 292.655521 266.61981 \n",
       "L 292.800585 272.064499 \n",
       "L 293.090715 250.655743 \n",
       "L 293.235779 265.407154 \n",
       "L 293.525908 266.871287 \n",
       "L 293.670973 231.299324 \n",
       "L 293.816038 234.463779 \n",
       "L 293.961102 267.681644 \n",
       "L 294.251231 212.456467 \n",
       "L 294.396296 265.049778 \n",
       "L 294.54136 257.365995 \n",
       "L 294.686425 266.654483 \n",
       "L 294.83149 244.391725 \n",
       "L 294.976554 242.590214 \n",
       "L 295.121619 261.315109 \n",
       "L 295.411748 252.601867 \n",
       "L 295.556813 261.416589 \n",
       "L 295.701877 247.360547 \n",
       "L 295.846942 270.7909 \n",
       "L 295.992006 236.454716 \n",
       "L 296.137071 269.201169 \n",
       "L 296.282135 267.264931 \n",
       "L 296.4272 236.180355 \n",
       "L 296.572265 261.951352 \n",
       "L 296.717329 244.475111 \n",
       "L 296.862394 272.026718 \n",
       "L 297.007458 268.386284 \n",
       "L 297.297588 218.007687 \n",
       "L 297.442652 251.285122 \n",
       "L 297.587717 226.083242 \n",
       "L 297.877846 262.884052 \n",
       "L 298.022911 260.136467 \n",
       "L 298.167975 264.660982 \n",
       "L 298.458104 235.450519 \n",
       "L 298.603169 261.156624 \n",
       "L 298.748233 249.78241 \n",
       "L 299.183427 269.876122 \n",
       "L 299.473556 262.922532 \n",
       "L 299.618621 272.328647 \n",
       "L 299.90875 254.286052 \n",
       "L 300.053815 226.620515 \n",
       "L 300.198879 254.357728 \n",
       "L 300.343944 206.185512 \n",
       "L 300.489008 256.096388 \n",
       "L 300.634073 253.004662 \n",
       "L 300.779138 260.996491 \n",
       "L 300.924202 253.827734 \n",
       "L 301.069267 272.419225 \n",
       "L 301.214331 221.900934 \n",
       "L 301.359396 269.940298 \n",
       "L 301.504461 213.922567 \n",
       "L 301.649525 261.694081 \n",
       "L 301.79459 214.124979 \n",
       "L 302.084719 273.451203 \n",
       "L 302.229784 230.537194 \n",
       "L 302.519913 261.898977 \n",
       "L 302.664977 272.160551 \n",
       "L 302.810042 268.185652 \n",
       "L 302.955106 258.184946 \n",
       "L 303.100171 264.584858 \n",
       "L 303.3903 232.89613 \n",
       "L 303.535365 244.368791 \n",
       "L 303.680429 265.661416 \n",
       "L 303.825494 263.673443 \n",
       "L 303.970559 251.110355 \n",
       "L 304.115623 249.67656 \n",
       "L 304.260688 231.1985 \n",
       "L 304.405752 252.127507 \n",
       "L 304.695882 238.809492 \n",
       "L 304.840946 260.939466 \n",
       "L 305.131075 241.104407 \n",
       "L 305.421204 265.88303 \n",
       "L 305.566269 230.204063 \n",
       "L 305.856398 261.609592 \n",
       "L 306.001463 252.375412 \n",
       "L 306.146527 260.149555 \n",
       "L 306.291592 244.2835 \n",
       "L 306.436657 271.373773 \n",
       "L 306.581721 256.044721 \n",
       "L 306.726786 257.828649 \n",
       "L 306.87185 266.35428 \n",
       "L 307.016915 220.871986 \n",
       "L 307.161979 270.592593 \n",
       "L 307.307044 272.995434 \n",
       "L 307.452109 248.953941 \n",
       "L 307.742238 269.389216 \n",
       "L 308.177432 220.777705 \n",
       "L 308.322496 266.818516 \n",
       "L 308.467561 256.633342 \n",
       "L 308.612625 257.79877 \n",
       "L 308.75769 236.640807 \n",
       "L 308.902755 260.46899 \n",
       "L 309.192884 263.356999 \n",
       "L 309.483013 240.132354 \n",
       "L 309.628077 233.061546 \n",
       "L 309.773142 269.56481 \n",
       "L 309.918207 242.985883 \n",
       "L 310.063271 244.750447 \n",
       "L 310.208336 261.129724 \n",
       "L 310.3534 243.999979 \n",
       "L 310.498465 258.449336 \n",
       "L 310.64353 238.802766 \n",
       "L 310.788594 272.828697 \n",
       "L 310.933659 233.998109 \n",
       "L 311.078723 233.257872 \n",
       "L 311.223788 263.806227 \n",
       "L 311.368853 263.895865 \n",
       "L 311.513917 270.491606 \n",
       "L 311.658982 249.273588 \n",
       "L 311.804046 259.611207 \n",
       "L 312.094175 246.414956 \n",
       "L 312.23924 218.733387 \n",
       "L 312.529369 256.996774 \n",
       "L 312.674434 206.331231 \n",
       "L 312.819498 247.828732 \n",
       "L 312.964563 248.875905 \n",
       "L 313.109628 217.919675 \n",
       "L 313.254692 269.037592 \n",
       "L 313.544821 234.561652 \n",
       "L 313.689886 263.915373 \n",
       "L 313.83495 177.635878 \n",
       "L 314.12508 275.45456 \n",
       "L 314.270144 249.234617 \n",
       "L 314.415209 262.749654 \n",
       "L 314.560273 237.296732 \n",
       "L 314.705338 262.03493 \n",
       "L 314.850403 239.379566 \n",
       "L 315.140532 264.255953 \n",
       "L 315.285596 257.055145 \n",
       "L 315.430661 237.944631 \n",
       "L 315.72079 265.544726 \n",
       "L 315.865855 271.872531 \n",
       "L 316.010919 253.257992 \n",
       "L 316.155984 251.022225 \n",
       "L 316.301048 255.859236 \n",
       "L 316.446113 242.867112 \n",
       "L 316.591178 255.259114 \n",
       "L 316.736242 256.756367 \n",
       "L 316.881307 231.530946 \n",
       "L 317.171436 266.157473 \n",
       "L 317.316501 218.571334 \n",
       "L 317.461565 256.369777 \n",
       "L 317.60663 234.937415 \n",
       "L 317.751694 265.71848 \n",
       "L 318.041824 245.120299 \n",
       "L 318.186888 260.502542 \n",
       "L 318.331953 228.622492 \n",
       "L 318.477017 256.773191 \n",
       "L 318.622082 249.797383 \n",
       "L 318.767146 264.35506 \n",
       "L 318.912211 232.075582 \n",
       "L 319.057276 259.899972 \n",
       "L 319.20234 260.686914 \n",
       "L 319.347405 240.935109 \n",
       "L 319.492469 262.730054 \n",
       "L 319.782599 257.51775 \n",
       "L 319.927663 270.956523 \n",
       "L 320.072728 262.153062 \n",
       "L 320.362857 225.830826 \n",
       "L 320.507921 262.778933 \n",
       "L 320.652986 222.560163 \n",
       "L 320.798051 255.919163 \n",
       "L 320.943115 257.630071 \n",
       "L 321.08818 261.86609 \n",
       "L 321.233244 253.735067 \n",
       "L 321.378309 235.951287 \n",
       "L 321.523374 260.776585 \n",
       "L 321.813503 246.459106 \n",
       "L 321.958567 252.10053 \n",
       "L 322.103632 236.279085 \n",
       "L 322.393761 270.449732 \n",
       "L 322.538826 214.056648 \n",
       "L 322.68389 250.947198 \n",
       "L 322.828955 246.778349 \n",
       "L 322.974019 273.66319 \n",
       "L 323.119084 254.005523 \n",
       "L 323.264149 266.211267 \n",
       "L 323.409213 227.666756 \n",
       "L 323.554278 223.326642 \n",
       "L 323.699342 243.786366 \n",
       "L 323.844407 238.025386 \n",
       "L 323.989472 267.921729 \n",
       "L 324.134536 252.904033 \n",
       "L 324.279601 252.790228 \n",
       "L 324.424665 260.331701 \n",
       "L 324.56973 231.142275 \n",
       "L 324.714795 261.396964 \n",
       "L 324.859859 218.387737 \n",
       "L 325.149988 263.509357 \n",
       "L 325.295053 243.903852 \n",
       "L 325.730247 273.436137 \n",
       "L 325.875311 271.825005 \n",
       "L 326.020376 219.463099 \n",
       "L 326.16544 266.152545 \n",
       "L 326.310505 260.872296 \n",
       "L 326.45557 231.547906 \n",
       "L 326.600634 256.386653 \n",
       "L 326.745699 261.966571 \n",
       "L 327.035828 217.755116 \n",
       "L 327.180892 258.753007 \n",
       "L 327.325957 263.037936 \n",
       "L 327.471022 257.661473 \n",
       "L 327.616086 235.504599 \n",
       "L 327.761151 255.472317 \n",
       "L 327.906215 243.488931 \n",
       "L 328.05128 243.087742 \n",
       "L 328.196345 240.360882 \n",
       "L 328.341409 242.539199 \n",
       "L 328.486474 273.005162 \n",
       "L 328.631538 248.345966 \n",
       "L 328.776603 265.232908 \n",
       "L 328.921668 243.961386 \n",
       "L 329.211797 263.451118 \n",
       "L 329.356861 272.093819 \n",
       "L 329.501926 248.368398 \n",
       "L 329.64699 273.508125 \n",
       "L 329.792055 257.041885 \n",
       "L 329.93712 262.895606 \n",
       "L 330.082184 263.463929 \n",
       "L 330.227249 252.575218 \n",
       "L 330.372313 214.937449 \n",
       "L 330.517378 245.274695 \n",
       "L 330.662443 246.897915 \n",
       "L 330.807507 247.017852 \n",
       "L 330.952572 217.295243 \n",
       "L 331.097636 258.025253 \n",
       "L 331.242701 229.207413 \n",
       "L 331.53283 252.154441 \n",
       "L 331.677895 249.231062 \n",
       "L 331.822959 261.363592 \n",
       "L 331.968024 242.340962 \n",
       "L 332.113088 266.706153 \n",
       "L 332.403218 245.440103 \n",
       "L 332.693347 256.137257 \n",
       "L 332.838411 247.304382 \n",
       "L 332.983476 201.640142 \n",
       "L 333.128541 244.982284 \n",
       "L 333.273605 239.039484 \n",
       "L 333.41867 265.988884 \n",
       "L 333.563734 257.35367 \n",
       "L 333.708799 263.795108 \n",
       "L 333.853863 214.98691 \n",
       "L 334.143993 270.495066 \n",
       "L 334.289057 257.779588 \n",
       "L 334.434122 266.87332 \n",
       "L 334.579186 222.274949 \n",
       "L 334.724251 263.990892 \n",
       "L 334.869316 271.234187 \n",
       "L 335.01438 258.075298 \n",
       "L 335.159445 260.212563 \n",
       "L 335.304509 252.931533 \n",
       "L 335.449574 258.53315 \n",
       "L 335.594639 271.591052 \n",
       "L 335.739703 239.942 \n",
       "L 335.884768 246.885505 \n",
       "L 336.029832 216.565562 \n",
       "L 336.465026 271.3292 \n",
       "L 336.755155 260.804804 \n",
       "L 336.90022 259.877177 \n",
       "L 337.045284 232.145143 \n",
       "L 337.190349 237.594024 \n",
       "L 337.335414 264.11405 \n",
       "L 337.480478 218.198766 \n",
       "L 337.625543 272.088549 \n",
       "L 337.915672 229.80722 \n",
       "L 338.060737 245.06438 \n",
       "L 338.205801 236.178404 \n",
       "L 338.350866 235.992967 \n",
       "L 338.49593 272.930242 \n",
       "L 338.640995 220.550707 \n",
       "L 338.786059 243.421452 \n",
       "L 338.931124 231.684089 \n",
       "L 339.076189 242.077693 \n",
       "L 339.221253 273.522279 \n",
       "L 339.366318 269.757718 \n",
       "L 339.511382 271.289672 \n",
       "L 339.801512 221.380415 \n",
       "L 339.946576 221.749857 \n",
       "L 340.091641 266.946171 \n",
       "L 340.236705 249.801527 \n",
       "L 340.38177 263.409174 \n",
       "L 340.526834 250.520016 \n",
       "L 340.671899 259.90753 \n",
       "L 340.816964 230.465369 \n",
       "L 340.962028 246.840752 \n",
       "L 341.107093 234.161169 \n",
       "L 341.397222 260.593233 \n",
       "L 341.542287 242.885853 \n",
       "L 341.687351 266.644164 \n",
       "L 341.832416 233.33277 \n",
       "L 341.97748 265.776338 \n",
       "L 342.122545 229.933858 \n",
       "L 342.26761 244.30956 \n",
       "L 342.412674 247.468745 \n",
       "L 342.557739 237.750506 \n",
       "L 342.702803 268.897462 \n",
       "L 342.992932 258.713069 \n",
       "L 343.137997 237.236767 \n",
       "L 343.283062 253.503217 \n",
       "L 343.428126 240.834491 \n",
       "L 343.573191 258.65206 \n",
       "L 343.718255 248.044462 \n",
       "L 343.86332 247.002157 \n",
       "L 344.008385 271.126006 \n",
       "L 344.153449 246.001174 \n",
       "L 344.443578 256.851927 \n",
       "L 344.588643 249.729559 \n",
       "L 344.733708 259.473672 \n",
       "L 344.878772 235.930207 \n",
       "L 345.168901 256.512279 \n",
       "L 345.313966 264.177258 \n",
       "L 345.45903 263.881364 \n",
       "L 345.604095 246.368456 \n",
       "L 345.74916 262.976402 \n",
       "L 345.894224 263.818374 \n",
       "L 346.039289 268.798931 \n",
       "L 346.329418 265.109958 \n",
       "L 346.474483 248.10177 \n",
       "L 346.619547 204.220865 \n",
       "L 346.909676 271.622929 \n",
       "L 347.199805 256.334854 \n",
       "L 347.34487 264.376301 \n",
       "L 347.489935 234.37928 \n",
       "L 347.634999 257.020995 \n",
       "L 347.780064 234.498349 \n",
       "L 347.925128 244.760707 \n",
       "L 348.070193 244.323762 \n",
       "L 348.215258 243.354517 \n",
       "L 348.360322 259.613781 \n",
       "L 348.505387 236.409467 \n",
       "L 348.650451 237.764385 \n",
       "L 348.795516 266.532509 \n",
       "L 348.940581 243.686177 \n",
       "L 349.085645 264.95843 \n",
       "L 349.23071 267.718251 \n",
       "L 349.375774 259.447891 \n",
       "L 349.520839 243.964873 \n",
       "L 349.665903 241.426641 \n",
       "L 349.810968 230.7014 \n",
       "L 349.956033 259.412144 \n",
       "L 350.246162 253.682486 \n",
       "L 350.391226 238.344107 \n",
       "L 350.536291 237.105121 \n",
       "L 350.681356 262.12052 \n",
       "L 350.82642 239.977648 \n",
       "L 351.116549 262.39956 \n",
       "L 351.261614 249.007668 \n",
       "L 351.406678 248.405587 \n",
       "L 351.696808 270.292154 \n",
       "L 351.841872 233.241578 \n",
       "L 351.986937 259.650221 \n",
       "L 352.132001 247.883327 \n",
       "L 352.422131 263.065626 \n",
       "L 352.857324 246.855301 \n",
       "L 353.147454 261.445931 \n",
       "L 353.292518 258.535109 \n",
       "L 353.437583 252.974918 \n",
       "L 353.582647 221.91793 \n",
       "L 353.727712 222.120743 \n",
       "L 353.872776 217.805326 \n",
       "L 354.162906 274.906932 \n",
       "L 354.453035 227.634224 \n",
       "L 354.598099 259.611592 \n",
       "L 355.033293 221.258381 \n",
       "L 355.178358 248.728928 \n",
       "L 355.323422 246.106905 \n",
       "L 355.468487 224.14196 \n",
       "L 355.613552 249.129393 \n",
       "L 355.758616 232.007187 \n",
       "L 355.903681 264.459143 \n",
       "L 356.19381 245.866746 \n",
       "L 356.483939 257.208212 \n",
       "L 356.774068 245.38804 \n",
       "L 356.919133 274.495658 \n",
       "L 357.064197 269.217762 \n",
       "L 357.209262 274.805132 \n",
       "L 357.354327 212.333842 \n",
       "L 357.499391 264.709068 \n",
       "L 357.78952 222.616546 \n",
       "L 358.224714 272.047494 \n",
       "L 358.514843 253.307978 \n",
       "L 358.659908 266.069469 \n",
       "L 358.950037 233.038689 \n",
       "L 359.240166 264.402487 \n",
       "L 359.67536 231.013785 \n",
       "L 359.820425 252.578241 \n",
       "L 359.965489 252.952488 \n",
       "L 360.110554 250.314056 \n",
       "L 360.255618 263.967223 \n",
       "L 360.545747 242.616639 \n",
       "L 360.690812 265.306316 \n",
       "L 360.835877 245.572245 \n",
       "L 360.980941 264.997463 \n",
       "L 361.27107 238.474969 \n",
       "L 361.416135 256.122474 \n",
       "L 361.5612 247.286167 \n",
       "L 361.851329 265.972341 \n",
       "L 361.996393 240.256656 \n",
       "L 362.141458 264.358016 \n",
       "L 362.431587 239.799 \n",
       "L 362.576652 265.472091 \n",
       "L 362.866781 254.259391 \n",
       "L 363.011845 264.15911 \n",
       "L 363.15691 250.050432 \n",
       "L 363.301975 273.212207 \n",
       "L 363.447039 264.66382 \n",
       "L 363.592104 204.590875 \n",
       "L 363.737168 215.061233 \n",
       "L 363.882233 254.226494 \n",
       "L 364.027298 241.496134 \n",
       "L 364.172362 262.89587 \n",
       "L 364.317427 257.135305 \n",
       "L 364.462491 259.258489 \n",
       "L 364.607556 274.198806 \n",
       "L 364.897685 240.767064 \n",
       "L 365.04275 239.601164 \n",
       "L 365.187814 265.346349 \n",
       "L 365.332879 258.081055 \n",
       "L 365.623008 223.423243 \n",
       "L 365.768073 267.277381 \n",
       "L 365.913137 243.084669 \n",
       "L 366.058202 240.834432 \n",
       "L 366.203266 269.604975 \n",
       "L 366.493396 243.128827 \n",
       "L 366.63846 234.1956 \n",
       "L 366.783525 271.441665 \n",
       "L 366.928589 267.959329 \n",
       "L 367.218718 249.372463 \n",
       "L 367.508848 253.631614 \n",
       "L 367.653912 261.717367 \n",
       "L 367.798977 236.096848 \n",
       "L 368.089106 264.238138 \n",
       "L 368.234171 269.113401 \n",
       "L 368.5243 253.58829 \n",
       "L 368.669364 266.010452 \n",
       "L 368.814429 256.083068 \n",
       "L 368.959494 254.874129 \n",
       "L 369.104558 248.457294 \n",
       "L 369.249623 256.417102 \n",
       "L 369.394687 253.652648 \n",
       "L 369.539752 264.149508 \n",
       "L 369.829881 232.351236 \n",
       "L 369.974946 264.416397 \n",
       "L 370.12001 256.421319 \n",
       "L 370.265075 258.694388 \n",
       "L 370.410139 250.184009 \n",
       "L 370.555204 267.260572 \n",
       "L 370.700269 233.243295 \n",
       "L 370.990398 241.129781 \n",
       "L 370.990398 241.129781 \n",
       "\" clip-path=\"url(#p13a8f3cb3c)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path d=\"M 46.335852 159.761253 \n",
       "L 46.480917 161.811349 \n",
       "L 46.916111 178.771827 \n",
       "L 47.786498 191.114162 \n",
       "L 48.366756 197.115242 \n",
       "L 48.947015 200.90651 \n",
       "L 49.817402 205.2715 \n",
       "L 49.962467 205.04453 \n",
       "L 50.107532 205.525999 \n",
       "L 50.397661 207.211596 \n",
       "L 50.68779 207.613357 \n",
       "L 50.977919 209.097344 \n",
       "L 51.268048 209.658411 \n",
       "L 51.413113 210.22163 \n",
       "L 51.558177 209.655363 \n",
       "L 51.848307 210.118187 \n",
       "L 51.993371 210.473967 \n",
       "L 52.428565 209.900251 \n",
       "L 52.57363 209.87984 \n",
       "L 52.863759 210.697261 \n",
       "L 53.008823 210.529025 \n",
       "L 53.153888 210.599277 \n",
       "L 53.444017 209.364236 \n",
       "L 53.734146 208.945247 \n",
       "L 53.879211 209.714767 \n",
       "L 54.024275 209.809614 \n",
       "L 54.16934 210.059525 \n",
       "L 54.314405 210.67325 \n",
       "L 54.459469 210.70386 \n",
       "L 54.749598 210.424049 \n",
       "L 54.894663 210.091195 \n",
       "L 55.184792 210.586932 \n",
       "L 55.329857 210.551909 \n",
       "L 55.474921 211.073004 \n",
       "L 55.619986 210.390474 \n",
       "L 55.910115 211.188169 \n",
       "L 56.05518 211.035868 \n",
       "L 56.200244 210.672969 \n",
       "L 56.345309 210.913441 \n",
       "L 56.635438 211.956699 \n",
       "L 56.780503 211.641881 \n",
       "L 56.925567 212.239482 \n",
       "L 57.070632 212.169188 \n",
       "L 57.215696 212.727862 \n",
       "L 57.505825 212.55446 \n",
       "L 57.65089 212.985693 \n",
       "L 58.086084 212.157761 \n",
       "L 58.376213 211.371446 \n",
       "L 58.811407 211.038376 \n",
       "L 58.956471 211.195638 \n",
       "L 59.101536 210.394679 \n",
       "L 59.246601 210.311542 \n",
       "L 59.391665 210.371327 \n",
       "L 59.53673 209.858385 \n",
       "L 59.681794 209.986954 \n",
       "L 59.826859 210.309078 \n",
       "L 59.971923 210.271861 \n",
       "L 60.116988 210.411821 \n",
       "L 60.262053 209.860666 \n",
       "L 60.407117 209.997125 \n",
       "L 60.697246 209.50575 \n",
       "L 60.842311 208.909766 \n",
       "L 60.987376 209.293371 \n",
       "L 61.13244 208.943154 \n",
       "L 61.567634 209.359309 \n",
       "L 61.712698 209.050094 \n",
       "L 61.857763 209.18651 \n",
       "L 62.002828 209.082077 \n",
       "L 62.147892 209.543523 \n",
       "L 62.292957 209.48369 \n",
       "L 62.438021 209.652248 \n",
       "L 62.583086 210.174006 \n",
       "L 62.873215 210.076595 \n",
       "L 63.453474 211.300049 \n",
       "L 63.598538 211.954043 \n",
       "L 63.743603 212.071675 \n",
       "L 63.888667 212.395121 \n",
       "L 64.033732 212.253071 \n",
       "L 64.323861 211.609578 \n",
       "L 64.759055 212.015 \n",
       "L 64.904119 211.938617 \n",
       "L 65.194249 212.65954 \n",
       "L 65.484378 211.827061 \n",
       "L 65.919572 212.188922 \n",
       "L 66.064636 213.418971 \n",
       "L 66.789959 214.63587 \n",
       "L 66.935024 214.765591 \n",
       "L 67.080088 214.726018 \n",
       "L 67.225153 214.157196 \n",
       "L 67.370217 214.33871 \n",
       "L 67.515282 215.250905 \n",
       "L 67.660347 214.991692 \n",
       "L 68.09554 217.448664 \n",
       "L 68.240605 217.456501 \n",
       "L 68.385669 217.223893 \n",
       "L 68.530734 217.574054 \n",
       "L 68.820863 217.613258 \n",
       "L 69.110992 218.173298 \n",
       "L 69.546186 218.735022 \n",
       "L 69.691251 219.327789 \n",
       "L 69.836315 219.274148 \n",
       "L 69.98138 218.916826 \n",
       "L 70.126445 219.256705 \n",
       "L 70.271509 219.124045 \n",
       "L 70.561638 220.026787 \n",
       "L 70.851767 220.072439 \n",
       "L 71.286961 219.296892 \n",
       "L 71.432026 219.083607 \n",
       "L 71.57709 219.433573 \n",
       "L 71.722155 218.696268 \n",
       "L 71.86722 218.776039 \n",
       "L 72.157349 218.555034 \n",
       "L 73.027736 220.920184 \n",
       "L 73.172801 220.499956 \n",
       "L 73.317865 220.537769 \n",
       "L 73.46293 220.203712 \n",
       "L 73.607995 221.223509 \n",
       "L 73.898124 221.346972 \n",
       "L 74.043188 222.237345 \n",
       "L 74.188253 222.376042 \n",
       "L 74.333318 222.294519 \n",
       "L 74.478382 222.929999 \n",
       "L 74.768511 223.103886 \n",
       "L 74.913576 222.641244 \n",
       "L 75.203705 223.064245 \n",
       "L 75.34877 222.926155 \n",
       "L 75.493834 222.382674 \n",
       "L 75.638899 223.110051 \n",
       "L 75.929028 222.873441 \n",
       "L 76.074093 222.930128 \n",
       "L 76.219157 223.183872 \n",
       "L 76.364222 222.882266 \n",
       "L 76.509286 223.244635 \n",
       "L 76.94448 222.417089 \n",
       "L 77.234609 222.391842 \n",
       "L 77.524738 222.466534 \n",
       "L 77.814868 221.873728 \n",
       "L 77.959932 222.266045 \n",
       "L 78.104997 221.551345 \n",
       "L 78.250061 222.081468 \n",
       "L 78.975384 222.434823 \n",
       "L 79.265513 221.790175 \n",
       "L 79.555643 221.174485 \n",
       "L 79.700707 221.24004 \n",
       "L 79.845772 222.298687 \n",
       "L 80.135901 221.708728 \n",
       "L 80.280966 221.649814 \n",
       "L 80.42603 221.82091 \n",
       "L 80.571095 220.771894 \n",
       "L 80.716159 220.669691 \n",
       "L 80.861224 220.17916 \n",
       "L 81.006289 220.215535 \n",
       "L 81.151353 220.776683 \n",
       "L 81.296418 220.719592 \n",
       "L 81.586547 221.22463 \n",
       "L 81.731611 221.923804 \n",
       "L 82.166805 221.123405 \n",
       "L 82.31187 221.256429 \n",
       "L 82.747064 221.116783 \n",
       "L 82.892128 221.369481 \n",
       "L 83.182257 220.748693 \n",
       "L 83.472387 220.849835 \n",
       "L 83.617451 219.858695 \n",
       "L 84.052645 219.930538 \n",
       "L 84.342774 219.655659 \n",
       "L 84.777968 219.962443 \n",
       "L 85.068097 219.602108 \n",
       "L 85.213162 219.625768 \n",
       "L 85.358226 219.487992 \n",
       "L 85.503291 219.531984 \n",
       "L 85.648355 219.443632 \n",
       "L 85.938484 219.760495 \n",
       "L 86.083549 219.113935 \n",
       "L 86.228614 219.800115 \n",
       "L 86.373678 219.599667 \n",
       "L 86.518743 219.805682 \n",
       "L 86.663807 219.741098 \n",
       "L 86.808872 220.024748 \n",
       "L 86.953937 219.989852 \n",
       "L 87.099001 220.142097 \n",
       "L 87.244066 219.694327 \n",
       "L 87.969389 220.389844 \n",
       "L 88.114453 220.390161 \n",
       "L 88.549647 219.90735 \n",
       "L 88.839776 219.77243 \n",
       "L 89.129905 218.929236 \n",
       "L 89.27497 219.192573 \n",
       "L 89.565099 219.90572 \n",
       "L 89.710164 220.139403 \n",
       "L 90.000293 221.601215 \n",
       "L 90.145358 221.004214 \n",
       "L 90.290422 221.106642 \n",
       "L 90.580551 220.723799 \n",
       "L 90.87068 221.189641 \n",
       "L 91.015745 220.61201 \n",
       "L 91.16081 220.873789 \n",
       "L 91.305874 221.435748 \n",
       "L 91.450939 221.242878 \n",
       "L 91.596003 221.345085 \n",
       "L 91.741068 221.764269 \n",
       "L 91.886133 221.834763 \n",
       "L 92.031197 222.088142 \n",
       "L 92.321326 222.764528 \n",
       "L 92.611455 222.011151 \n",
       "L 92.75652 221.317187 \n",
       "L 93.046649 221.198732 \n",
       "L 93.191714 221.410385 \n",
       "L 93.336778 221.37612 \n",
       "L 93.626908 222.234146 \n",
       "L 93.771972 222.072502 \n",
       "L 94.062101 222.897944 \n",
       "L 94.352231 221.658239 \n",
       "L 94.787424 222.743779 \n",
       "L 94.932489 222.637434 \n",
       "L 95.077553 223.434359 \n",
       "L 95.222618 223.069194 \n",
       "L 95.367683 223.641378 \n",
       "L 95.512747 223.035708 \n",
       "L 95.802876 222.894567 \n",
       "L 95.947941 222.941057 \n",
       "L 96.093006 222.858727 \n",
       "L 96.23807 222.612886 \n",
       "L 96.528199 222.854572 \n",
       "L 96.673264 223.395485 \n",
       "L 96.818329 223.370808 \n",
       "L 97.108458 222.882263 \n",
       "L 97.253522 222.978743 \n",
       "L 97.398587 222.65313 \n",
       "L 97.543651 222.858137 \n",
       "L 97.688716 222.58 \n",
       "L 97.978845 221.571102 \n",
       "L 98.268974 222.661791 \n",
       "L 98.559104 223.193378 \n",
       "L 98.704168 223.100109 \n",
       "L 98.994297 223.892086 \n",
       "L 99.139362 223.88912 \n",
       "L 99.429491 223.624274 \n",
       "L 99.574556 223.573992 \n",
       "L 99.71962 223.935772 \n",
       "L 99.864685 223.80024 \n",
       "L 100.154814 224.56114 \n",
       "L 100.444943 224.242196 \n",
       "L 100.590008 224.553343 \n",
       "L 101.025202 224.664869 \n",
       "L 101.170266 224.837078 \n",
       "L 101.315331 224.74537 \n",
       "L 101.460395 224.511213 \n",
       "L 101.60546 224.695201 \n",
       "L 101.750524 225.161876 \n",
       "L 101.895589 225.050322 \n",
       "L 102.040654 224.63234 \n",
       "L 102.185718 224.957367 \n",
       "L 102.330783 224.863236 \n",
       "L 102.475847 225.295923 \n",
       "L 102.620912 224.864784 \n",
       "L 102.765977 225.083354 \n",
       "L 103.056106 225.064941 \n",
       "L 103.346235 225.214332 \n",
       "L 103.636364 225.832248 \n",
       "L 104.216622 225.106663 \n",
       "L 104.361687 224.728313 \n",
       "L 104.796881 224.67567 \n",
       "L 104.941945 224.923892 \n",
       "L 105.377139 224.849613 \n",
       "L 105.522204 225.206703 \n",
       "L 105.667268 225.132388 \n",
       "L 105.812333 224.840829 \n",
       "L 105.957397 225.486343 \n",
       "L 106.247527 225.022309 \n",
       "L 106.392591 225.060132 \n",
       "L 106.97285 224.185182 \n",
       "L 107.262979 225.461189 \n",
       "L 107.408043 225.565467 \n",
       "L 107.553108 225.983739 \n",
       "L 107.843237 225.297096 \n",
       "L 107.988302 225.57968 \n",
       "L 108.133366 225.486958 \n",
       "L 108.278431 225.955008 \n",
       "L 108.56856 225.136683 \n",
       "L 109.003754 226.21149 \n",
       "L 109.148818 225.419957 \n",
       "L 109.438948 225.105952 \n",
       "L 109.584012 225.342701 \n",
       "L 109.874141 226.045621 \n",
       "L 110.019206 226.174471 \n",
       "L 110.164271 226.041247 \n",
       "L 110.309335 226.378699 \n",
       "L 110.4544 226.185294 \n",
       "L 110.599464 226.43358 \n",
       "L 110.889593 226.053757 \n",
       "L 111.179723 226.511812 \n",
       "L 111.469852 226.153031 \n",
       "L 111.614916 226.630184 \n",
       "L 111.759981 226.44755 \n",
       "L 111.905046 226.543541 \n",
       "L 112.05011 226.425785 \n",
       "L 112.195175 226.51591 \n",
       "L 112.630368 227.542241 \n",
       "L 112.775433 227.23889 \n",
       "L 113.065562 226.438773 \n",
       "L 113.210627 226.592997 \n",
       "L 113.355691 226.442463 \n",
       "L 113.500756 225.928219 \n",
       "L 113.790885 226.063842 \n",
       "L 114.081014 226.29599 \n",
       "L 114.516208 225.919506 \n",
       "L 114.661273 226.106355 \n",
       "L 114.806337 226.066721 \n",
       "L 115.096466 226.62418 \n",
       "L 115.241531 226.212609 \n",
       "L 115.53166 226.781177 \n",
       "L 115.821789 227.360608 \n",
       "L 116.111919 226.818696 \n",
       "L 116.256983 227.012093 \n",
       "L 116.402048 226.847958 \n",
       "L 116.547112 227.099396 \n",
       "L 116.692177 226.821201 \n",
       "L 116.837242 227.104695 \n",
       "L 117.127371 226.452772 \n",
       "L 117.562564 225.518919 \n",
       "L 117.852694 225.91565 \n",
       "L 117.997758 225.386447 \n",
       "L 118.142823 225.333229 \n",
       "L 118.432952 224.659172 \n",
       "L 118.578017 224.944208 \n",
       "L 118.723081 224.856827 \n",
       "L 118.868146 224.948966 \n",
       "L 119.01321 224.676196 \n",
       "L 119.303339 225.056026 \n",
       "L 119.593469 224.754387 \n",
       "L 119.738533 225.30288 \n",
       "L 119.883598 225.407294 \n",
       "L 120.028662 225.673486 \n",
       "L 120.173727 225.693331 \n",
       "L 121.044115 224.96931 \n",
       "L 121.189179 225.180046 \n",
       "L 121.334244 225.146656 \n",
       "L 121.624373 226.012303 \n",
       "L 122.059567 225.336673 \n",
       "L 122.349696 226.11349 \n",
       "L 122.49476 225.746645 \n",
       "L 122.639825 226.147152 \n",
       "L 122.78489 225.969757 \n",
       "L 122.929954 226.092671 \n",
       "L 123.075019 226.410778 \n",
       "L 123.220083 226.45296 \n",
       "L 123.365148 226.294149 \n",
       "L 123.510212 225.715259 \n",
       "L 123.655277 226.350422 \n",
       "L 123.800342 226.290875 \n",
       "L 123.945406 226.438361 \n",
       "L 124.235535 225.848539 \n",
       "L 124.525665 225.086653 \n",
       "L 124.670729 225.238047 \n",
       "L 124.815794 225.166753 \n",
       "L 124.960858 225.685436 \n",
       "L 125.105923 225.231802 \n",
       "L 125.250988 225.756431 \n",
       "L 125.541117 225.541007 \n",
       "L 125.686181 225.460776 \n",
       "L 125.97631 226.079282 \n",
       "L 126.121375 225.994283 \n",
       "L 126.26644 226.195629 \n",
       "L 126.411504 226.179564 \n",
       "L 126.556569 225.918901 \n",
       "L 126.701633 226.309785 \n",
       "L 126.846698 226.240363 \n",
       "L 126.991763 226.033577 \n",
       "L 127.426956 226.841344 \n",
       "L 127.86215 226.626305 \n",
       "L 128.152279 226.937458 \n",
       "L 128.442408 226.961772 \n",
       "L 129.167731 226.102174 \n",
       "L 129.457861 226.752676 \n",
       "L 129.602925 226.713732 \n",
       "L 129.893054 227.336193 \n",
       "L 130.038119 227.292413 \n",
       "L 130.183183 226.746344 \n",
       "L 130.328248 226.751644 \n",
       "L 130.473313 227.142138 \n",
       "L 130.763442 227.143839 \n",
       "L 131.053571 226.985166 \n",
       "L 131.198636 227.131971 \n",
       "L 131.3437 226.864665 \n",
       "L 131.488765 227.190592 \n",
       "L 131.778894 228.253319 \n",
       "L 132.069023 229.081774 \n",
       "L 132.214088 229.168399 \n",
       "L 132.359152 229.056947 \n",
       "L 132.504217 229.911887 \n",
       "L 132.649281 230.005939 \n",
       "L 132.939411 231.001514 \n",
       "L 133.664734 231.804785 \n",
       "L 133.809798 231.953739 \n",
       "L 134.099927 232.765819 \n",
       "L 134.244992 232.147644 \n",
       "L 134.390057 232.207304 \n",
       "L 134.535121 231.923257 \n",
       "L 134.970315 232.883502 \n",
       "L 135.115379 233.020785 \n",
       "L 135.260444 233.524808 \n",
       "L 135.405509 233.29923 \n",
       "L 135.550573 233.514727 \n",
       "L 135.695638 233.466025 \n",
       "L 135.840702 233.580288 \n",
       "L 136.130832 233.103424 \n",
       "L 136.566025 233.879138 \n",
       "L 136.71109 233.710321 \n",
       "L 137.001219 233.245949 \n",
       "L 137.436413 232.466534 \n",
       "L 137.581477 232.762367 \n",
       "L 137.726542 232.53111 \n",
       "L 138.016671 233.411582 \n",
       "L 138.161736 233.048046 \n",
       "L 138.3068 233.088138 \n",
       "L 138.451865 233.476157 \n",
       "L 138.59693 233.441144 \n",
       "L 138.741994 233.722036 \n",
       "L 138.887059 233.71175 \n",
       "L 139.032123 234.350675 \n",
       "L 139.177188 233.95229 \n",
       "L 139.322252 234.004383 \n",
       "L 139.467317 233.861415 \n",
       "L 139.612382 234.130138 \n",
       "L 139.757446 233.281125 \n",
       "L 139.902511 233.461518 \n",
       "L 140.047575 233.147909 \n",
       "L 140.337705 233.168967 \n",
       "L 140.627834 233.757073 \n",
       "L 140.772898 233.446056 \n",
       "L 140.917963 233.554826 \n",
       "L 141.063028 234.081231 \n",
       "L 141.208092 233.884105 \n",
       "L 141.353157 233.934915 \n",
       "L 141.498221 233.771114 \n",
       "L 141.643286 233.268615 \n",
       "L 141.78835 233.233536 \n",
       "L 142.223544 232.571902 \n",
       "L 142.803803 233.442165 \n",
       "L 142.948867 233.37761 \n",
       "L 143.093932 233.446074 \n",
       "L 143.238996 233.303063 \n",
       "L 143.529125 233.908351 \n",
       "L 143.819255 233.379072 \n",
       "L 144.254448 233.627892 \n",
       "L 144.544578 232.683226 \n",
       "L 145.124836 233.93331 \n",
       "L 145.56003 233.676861 \n",
       "L 145.850159 234.281124 \n",
       "L 145.995223 234.115952 \n",
       "L 146.285353 233.674242 \n",
       "L 146.575482 233.895145 \n",
       "L 147.15574 233.460561 \n",
       "L 147.300805 233.456453 \n",
       "L 147.590934 233.15543 \n",
       "L 147.735999 233.33566 \n",
       "L 148.026128 233.284408 \n",
       "L 148.171192 232.786097 \n",
       "L 148.461321 232.888914 \n",
       "L 148.606386 232.89968 \n",
       "L 148.896515 233.503214 \n",
       "L 149.04158 233.766553 \n",
       "L 149.766903 232.754793 \n",
       "L 149.911967 232.692629 \n",
       "L 150.202096 232.447922 \n",
       "L 150.492226 232.682393 \n",
       "L 150.782355 232.45643 \n",
       "L 150.927419 231.994811 \n",
       "L 151.072484 232.067602 \n",
       "L 151.362613 232.335864 \n",
       "L 151.507678 232.48785 \n",
       "L 151.652742 232.401925 \n",
       "L 151.942872 232.943143 \n",
       "L 152.087936 233.029051 \n",
       "L 152.378065 232.817167 \n",
       "L 152.52313 232.949278 \n",
       "L 152.813259 233.561437 \n",
       "L 152.958324 233.375379 \n",
       "L 153.393517 234.463646 \n",
       "L 153.538582 234.111956 \n",
       "L 153.683647 234.500878 \n",
       "L 153.828711 234.495627 \n",
       "L 153.973776 234.026906 \n",
       "L 154.11884 234.431683 \n",
       "L 154.263905 235.462513 \n",
       "L 154.40897 235.300645 \n",
       "L 154.554034 235.400247 \n",
       "L 154.989228 234.606342 \n",
       "L 155.134292 234.697926 \n",
       "L 155.279357 235.026766 \n",
       "L 155.424422 235.04927 \n",
       "L 155.569486 234.872114 \n",
       "L 155.714551 234.998842 \n",
       "L 156.00468 234.993859 \n",
       "L 156.730003 236.284461 \n",
       "L 157.455326 235.309093 \n",
       "L 157.60039 235.292534 \n",
       "L 157.89052 235.888123 \n",
       "L 158.035584 235.873281 \n",
       "L 158.180649 236.168574 \n",
       "L 158.470778 236.150463 \n",
       "L 158.760907 235.34567 \n",
       "L 159.051036 235.717999 \n",
       "L 159.196101 235.788775 \n",
       "L 159.341165 235.51793 \n",
       "L 159.631295 234.406199 \n",
       "L 159.776359 234.08098 \n",
       "L 159.921424 234.231156 \n",
       "L 160.211553 234.259271 \n",
       "L 160.356618 233.73645 \n",
       "L 160.501682 233.669076 \n",
       "L 160.646747 234.061136 \n",
       "L 161.37207 233.479496 \n",
       "L 161.517134 233.744761 \n",
       "L 161.662199 233.679694 \n",
       "L 161.807263 233.884059 \n",
       "L 161.952328 233.457466 \n",
       "L 162.242457 233.371001 \n",
       "L 162.532586 232.68134 \n",
       "L 162.677651 233.222899 \n",
       "L 162.96778 233.067738 \n",
       "L 163.112845 233.155491 \n",
       "L 163.402974 232.897032 \n",
       "L 163.548038 232.942285 \n",
       "L 163.693103 232.425681 \n",
       "L 163.838168 232.816773 \n",
       "L 163.983232 232.874436 \n",
       "L 164.273361 233.455537 \n",
       "L 164.563491 234.332114 \n",
       "L 164.708555 234.429837 \n",
       "L 164.85362 234.392626 \n",
       "L 164.998684 234.00566 \n",
       "L 165.143749 234.478747 \n",
       "L 165.288814 233.862288 \n",
       "L 165.433878 234.187786 \n",
       "L 165.578943 234.018111 \n",
       "L 165.724007 234.074248 \n",
       "L 166.159201 234.80147 \n",
       "L 166.594395 235.210669 \n",
       "L 166.739459 235.973189 \n",
       "L 166.884524 236.032599 \n",
       "L 167.174653 235.502596 \n",
       "L 167.319718 235.272824 \n",
       "L 167.609847 235.367606 \n",
       "L 167.754911 235.122484 \n",
       "L 167.899976 235.182665 \n",
       "L 168.045041 234.995966 \n",
       "L 168.190105 234.218162 \n",
       "L 168.33517 234.128408 \n",
       "L 168.480234 234.499725 \n",
       "L 168.915428 233.652578 \n",
       "L 169.060493 234.025137 \n",
       "L 169.205557 233.833602 \n",
       "L 169.350622 234.270557 \n",
       "L 169.495687 234.107987 \n",
       "L 169.785816 233.318023 \n",
       "L 170.221009 233.108702 \n",
       "L 170.366074 232.962516 \n",
       "L 170.656203 233.427214 \n",
       "L 170.946332 233.199591 \n",
       "L 171.091397 233.305514 \n",
       "L 171.381526 232.802187 \n",
       "L 171.671655 233.086163 \n",
       "L 171.81672 232.827647 \n",
       "L 171.961785 233.177659 \n",
       "L 172.251914 233.179717 \n",
       "L 172.542043 233.251227 \n",
       "L 172.832172 233.723671 \n",
       "L 172.977237 233.727219 \n",
       "L 173.557495 234.626921 \n",
       "L 173.70256 234.181441 \n",
       "L 173.847624 234.380115 \n",
       "L 173.992689 234.994035 \n",
       "L 174.137753 234.905151 \n",
       "L 174.282818 235.274102 \n",
       "L 174.718012 235.023829 \n",
       "L 175.008141 235.460767 \n",
       "L 175.153205 234.978846 \n",
       "L 175.443335 235.554597 \n",
       "L 175.588399 235.341738 \n",
       "L 175.733464 235.344712 \n",
       "L 176.023593 235.791257 \n",
       "L 176.168658 235.893805 \n",
       "L 176.313722 235.379464 \n",
       "L 176.458787 235.912424 \n",
       "L 176.748916 236.143918 \n",
       "L 176.89398 236.520291 \n",
       "L 177.039045 236.487721 \n",
       "L 177.474239 236.054335 \n",
       "L 177.909433 236.42347 \n",
       "L 178.054497 235.81301 \n",
       "L 178.199562 236.340639 \n",
       "L 178.489691 236.339038 \n",
       "L 178.634756 236.369783 \n",
       "L 178.77982 236.518896 \n",
       "L 179.069949 235.893063 \n",
       "L 179.215014 235.769498 \n",
       "L 180.230466 236.998122 \n",
       "L 180.375531 237.231621 \n",
       "L 180.810724 237.05835 \n",
       "L 180.955789 236.545199 \n",
       "L 181.100853 236.703493 \n",
       "L 181.536047 236.315742 \n",
       "L 181.681112 236.244809 \n",
       "L 181.826176 236.40299 \n",
       "L 182.116306 236.339626 \n",
       "L 182.26137 236.47232 \n",
       "L 182.406435 236.445105 \n",
       "L 182.551499 236.575456 \n",
       "L 182.841629 237.072879 \n",
       "L 182.986693 236.786058 \n",
       "L 183.131758 236.78929 \n",
       "L 183.421887 237.766085 \n",
       "L 183.566951 237.834076 \n",
       "L 183.857081 238.619311 \n",
       "L 184.002145 238.613558 \n",
       "L 184.437339 239.772675 \n",
       "L 184.582404 239.69666 \n",
       "L 184.872533 240.778349 \n",
       "L 185.162662 240.435154 \n",
       "L 185.452791 239.905936 \n",
       "L 185.74292 240.543511 \n",
       "L 186.033049 241.083418 \n",
       "L 186.178114 240.9879 \n",
       "L 186.323179 241.539606 \n",
       "L 186.468243 241.476796 \n",
       "L 186.758372 241.888687 \n",
       "L 186.903437 241.90066 \n",
       "L 187.048502 242.079279 \n",
       "L 187.338631 241.45595 \n",
       "L 187.773824 241.892675 \n",
       "L 188.063954 241.366162 \n",
       "L 188.209018 241.591794 \n",
       "L 188.499147 241.585991 \n",
       "L 188.789277 242.075328 \n",
       "L 189.079406 242.885947 \n",
       "L 189.5146 243.159205 \n",
       "L 189.659664 243.536502 \n",
       "L 189.804729 243.278786 \n",
       "L 189.949793 243.285394 \n",
       "L 190.094858 243.472967 \n",
       "L 190.384987 243.262578 \n",
       "L 190.675116 242.405225 \n",
       "L 190.820181 243.111101 \n",
       "L 191.11031 242.933665 \n",
       "L 191.255375 242.995648 \n",
       "L 191.835633 244.395528 \n",
       "L 191.980698 244.253479 \n",
       "L 192.125762 243.697237 \n",
       "L 192.851085 244.186153 \n",
       "L 193.141214 244.060958 \n",
       "L 193.286279 243.845771 \n",
       "L 193.431343 243.952065 \n",
       "L 193.576408 244.273477 \n",
       "L 193.721473 244.218469 \n",
       "L 193.866537 243.65136 \n",
       "L 194.011602 243.559713 \n",
       "L 194.156666 243.778252 \n",
       "L 194.301731 244.293132 \n",
       "L 194.446795 244.272166 \n",
       "L 194.59186 243.801149 \n",
       "L 194.736925 243.744701 \n",
       "L 195.027054 242.658184 \n",
       "L 195.172118 242.634415 \n",
       "L 195.317183 242.489407 \n",
       "L 195.462248 242.708029 \n",
       "L 195.752377 242.524357 \n",
       "L 195.897441 242.446142 \n",
       "L 196.042506 242.64545 \n",
       "L 196.187571 242.536269 \n",
       "L 196.332635 242.628369 \n",
       "L 196.622764 242.637483 \n",
       "L 196.767829 242.694804 \n",
       "L 196.912893 242.051643 \n",
       "L 197.057958 242.059527 \n",
       "L 197.203023 242.671078 \n",
       "L 197.638216 242.949463 \n",
       "L 197.783281 242.711463 \n",
       "L 197.928346 242.822665 \n",
       "L 198.07341 242.457083 \n",
       "L 198.218475 242.427379 \n",
       "L 198.653669 241.826942 \n",
       "L 198.798733 241.914829 \n",
       "L 198.943798 241.81577 \n",
       "L 199.088862 242.127901 \n",
       "L 199.233927 241.946256 \n",
       "L 199.378991 241.356514 \n",
       "L 199.524056 241.602561 \n",
       "L 199.669121 241.231766 \n",
       "L 200.104314 241.596319 \n",
       "L 200.249379 241.490492 \n",
       "L 200.394444 241.582611 \n",
       "L 200.829637 241.040887 \n",
       "L 201.119766 241.248662 \n",
       "L 201.409896 240.989203 \n",
       "L 201.55496 241.007611 \n",
       "L 201.700025 241.293247 \n",
       "L 201.990154 240.805342 \n",
       "L 202.135219 241.016598 \n",
       "L 202.280283 240.857867 \n",
       "L 202.425348 240.461815 \n",
       "L 202.570412 240.842132 \n",
       "L 202.860542 240.808596 \n",
       "L 203.150671 240.874829 \n",
       "L 203.4408 240.396596 \n",
       "L 203.875994 240.55025 \n",
       "L 204.021058 240.150176 \n",
       "L 204.891446 241.386117 \n",
       "L 205.181575 242.216923 \n",
       "L 205.761833 241.390893 \n",
       "L 205.906898 241.408562 \n",
       "L 206.197027 241.074372 \n",
       "L 206.487156 241.407846 \n",
       "L 206.777285 241.97482 \n",
       "L 206.92235 241.476622 \n",
       "L 207.067415 241.837434 \n",
       "L 207.212479 241.690974 \n",
       "L 207.357544 241.809511 \n",
       "L 207.792737 241.030819 \n",
       "L 208.227931 241.713932 \n",
       "L 208.51806 242.595575 \n",
       "L 208.80819 241.70186 \n",
       "L 208.953254 241.708157 \n",
       "L 209.098319 242.012624 \n",
       "L 209.243383 241.75671 \n",
       "L 209.533513 242.843691 \n",
       "L 210.258835 243.739874 \n",
       "L 210.4039 243.477008 \n",
       "L 210.984158 244.645457 \n",
       "L 211.129223 244.571309 \n",
       "L 211.274288 244.244234 \n",
       "L 211.564417 245.457793 \n",
       "L 211.709481 244.959742 \n",
       "L 211.854546 244.892788 \n",
       "L 211.99961 245.148112 \n",
       "L 212.144675 244.927592 \n",
       "L 212.28974 245.116648 \n",
       "L 212.434804 244.954901 \n",
       "L 212.579869 245.163991 \n",
       "L 212.724933 244.977992 \n",
       "L 212.869998 245.204203 \n",
       "L 213.015063 245.637929 \n",
       "L 213.305192 245.286616 \n",
       "L 213.450256 245.324595 \n",
       "L 213.595321 245.179453 \n",
       "L 213.740386 245.254694 \n",
       "L 213.88545 245.507178 \n",
       "L 214.030515 245.120804 \n",
       "L 214.175579 245.228396 \n",
       "L 214.465708 245.78226 \n",
       "L 214.610773 245.591515 \n",
       "L 214.755838 245.684321 \n",
       "L 215.045967 245.32174 \n",
       "L 215.191031 245.566769 \n",
       "L 215.336096 245.437865 \n",
       "L 215.626225 245.529405 \n",
       "L 215.77129 245.74339 \n",
       "L 215.916354 245.38753 \n",
       "L 216.061419 245.500601 \n",
       "L 216.206484 245.464492 \n",
       "L 216.351548 245.819328 \n",
       "L 216.786742 245.801671 \n",
       "L 216.931806 245.983481 \n",
       "L 217.076871 245.698543 \n",
       "L 217.221936 245.793421 \n",
       "L 217.657129 245.335289 \n",
       "L 217.947259 245.202522 \n",
       "L 218.092323 245.146788 \n",
       "L 218.382452 244.450769 \n",
       "L 218.527517 244.876301 \n",
       "L 218.962711 243.744059 \n",
       "L 219.25284 243.988614 \n",
       "L 219.542969 243.585886 \n",
       "L 219.978163 243.934619 \n",
       "L 220.123227 243.649829 \n",
       "L 220.268292 243.684749 \n",
       "L 220.413357 243.229651 \n",
       "L 220.703486 243.544942 \n",
       "L 220.84855 243.03081 \n",
       "L 221.138679 243.351368 \n",
       "L 221.283744 243.373242 \n",
       "L 221.428809 243.577711 \n",
       "L 221.718938 243.153493 \n",
       "L 221.864002 242.902489 \n",
       "L 222.009067 243.521473 \n",
       "L 222.154132 243.340455 \n",
       "L 222.299196 243.594076 \n",
       "L 222.589325 243.031456 \n",
       "L 222.73439 242.943631 \n",
       "L 223.024519 242.583086 \n",
       "L 223.314648 243.184054 \n",
       "L 223.459713 243.325573 \n",
       "L 223.604777 242.919254 \n",
       "L 223.749842 243.02945 \n",
       "L 223.894907 242.950653 \n",
       "L 224.185036 243.010674 \n",
       "L 224.3301 242.965726 \n",
       "L 224.62023 242.192618 \n",
       "L 224.765294 242.307029 \n",
       "L 224.910359 242.936229 \n",
       "L 225.200488 242.944 \n",
       "L 225.345552 242.932972 \n",
       "L 225.635682 243.09318 \n",
       "L 226.070875 243.024352 \n",
       "L 226.21594 243.163844 \n",
       "L 226.361005 242.904192 \n",
       "L 226.506069 242.982924 \n",
       "L 226.651134 243.395596 \n",
       "L 227.231392 243.056436 \n",
       "L 227.521521 242.579877 \n",
       "L 227.81165 242.966884 \n",
       "L 228.10178 243.026906 \n",
       "L 228.246844 242.917921 \n",
       "L 228.827103 243.802681 \n",
       "L 228.972167 243.611072 \n",
       "L 229.117232 243.669242 \n",
       "L 229.842555 244.46368 \n",
       "L 230.132684 244.087244 \n",
       "L 230.277748 243.997676 \n",
       "L 230.422813 244.502189 \n",
       "L 230.567878 244.312986 \n",
       "L 230.712942 244.38375 \n",
       "L 230.858007 244.215525 \n",
       "L 231.003071 244.23623 \n",
       "L 231.58333 244.848014 \n",
       "L 231.728394 244.941094 \n",
       "L 232.018523 245.3406 \n",
       "L 232.598782 245.904831 \n",
       "L 232.743846 245.987026 \n",
       "L 232.888911 246.333113 \n",
       "L 233.033976 245.998088 \n",
       "L 233.17904 246.170064 \n",
       "L 233.324105 246.719309 \n",
       "L 233.469169 246.755302 \n",
       "L 233.759299 245.957336 \n",
       "L 234.049428 246.125439 \n",
       "L 234.194492 245.657308 \n",
       "L 234.339557 245.885134 \n",
       "L 234.484621 245.901381 \n",
       "L 235.06488 247.04339 \n",
       "L 235.209944 246.565519 \n",
       "L 235.355009 246.534187 \n",
       "L 235.790203 245.47479 \n",
       "L 236.080332 245.908575 \n",
       "L 236.225397 245.78237 \n",
       "L 236.370461 246.10756 \n",
       "L 236.515526 246.031942 \n",
       "L 236.66059 246.601622 \n",
       "L 236.805655 246.697946 \n",
       "L 237.095784 247.242624 \n",
       "L 237.240849 247.01198 \n",
       "L 237.385913 247.26421 \n",
       "L 237.530978 247.103781 \n",
       "L 237.966172 247.126771 \n",
       "L 238.111236 247.572585 \n",
       "L 238.401365 247.582515 \n",
       "L 238.691494 246.883703 \n",
       "L 238.981624 247.305171 \n",
       "L 239.126688 247.706452 \n",
       "L 239.271753 247.725385 \n",
       "L 239.416817 247.547423 \n",
       "L 239.561882 247.643097 \n",
       "L 239.997076 246.481305 \n",
       "L 240.14214 246.517071 \n",
       "L 240.577334 245.918414 \n",
       "L 240.867463 246.699222 \n",
       "L 241.012528 246.610455 \n",
       "L 241.157592 246.161914 \n",
       "L 241.447722 245.980144 \n",
       "L 241.592786 246.188396 \n",
       "L 241.737851 246.633703 \n",
       "L 241.882915 246.628964 \n",
       "L 242.02798 246.493931 \n",
       "L 242.173045 246.532976 \n",
       "L 242.318109 246.398612 \n",
       "L 242.463174 246.425557 \n",
       "L 243.188497 245.553817 \n",
       "L 243.62369 245.92415 \n",
       "L 244.203949 245.20406 \n",
       "L 244.639143 245.73113 \n",
       "L 244.929272 245.328927 \n",
       "L 245.219401 245.661251 \n",
       "L 245.50953 245.699327 \n",
       "L 245.799659 245.32383 \n",
       "L 245.944724 245.704145 \n",
       "L 246.089788 245.756569 \n",
       "L 246.379918 245.530512 \n",
       "L 246.524982 245.794756 \n",
       "L 247.105241 245.545078 \n",
       "L 247.39537 245.942942 \n",
       "L 247.540434 246.103284 \n",
       "L 247.975628 246.032671 \n",
       "L 248.120693 246.377351 \n",
       "L 248.410822 246.466817 \n",
       "L 248.555886 246.403817 \n",
       "L 248.700951 246.96967 \n",
       "L 248.99108 246.292332 \n",
       "L 249.426274 246.242894 \n",
       "L 249.571339 246.300735 \n",
       "L 249.716403 246.199281 \n",
       "L 250.006532 246.928413 \n",
       "L 250.151597 247.037373 \n",
       "L 250.296661 247.664223 \n",
       "L 250.441726 247.648495 \n",
       "L 250.586791 247.823679 \n",
       "L 250.731855 248.419352 \n",
       "L 250.87692 248.239511 \n",
       "L 251.021984 247.614517 \n",
       "L 251.167049 247.764093 \n",
       "L 251.312114 247.740101 \n",
       "L 251.457178 247.829826 \n",
       "L 251.602243 247.427391 \n",
       "L 251.747307 247.460501 \n",
       "L 251.892372 247.261561 \n",
       "L 252.037436 247.39684 \n",
       "L 252.47263 247.210537 \n",
       "L 252.617695 246.744088 \n",
       "L 252.762759 247.069799 \n",
       "L 252.907824 246.974768 \n",
       "L 253.197953 247.708427 \n",
       "L 253.488082 247.671435 \n",
       "L 253.633147 247.913748 \n",
       "L 253.778212 247.667085 \n",
       "L 253.923276 247.79049 \n",
       "L 254.068341 247.544431 \n",
       "L 254.213405 247.533926 \n",
       "L 254.35847 247.321272 \n",
       "L 254.503534 247.676992 \n",
       "L 254.648599 247.663509 \n",
       "L 254.938728 248.305209 \n",
       "L 255.083793 248.332963 \n",
       "L 255.228857 248.106064 \n",
       "L 255.373922 248.177386 \n",
       "L 255.518987 247.976326 \n",
       "L 255.664051 248.489821 \n",
       "L 255.809116 248.547981 \n",
       "L 255.95418 248.901531 \n",
       "L 256.389374 248.810352 \n",
       "L 256.679503 249.113863 \n",
       "L 256.824568 249.3098 \n",
       "L 256.969632 249.184522 \n",
       "L 257.259762 249.810319 \n",
       "L 257.549891 250.165658 \n",
       "L 257.694955 250.451873 \n",
       "L 258.130149 250.186394 \n",
       "L 258.275214 250.206207 \n",
       "L 258.420278 250.45496 \n",
       "L 258.855472 250.242824 \n",
       "L 259.000537 250.596942 \n",
       "L 259.145601 250.488294 \n",
       "L 259.290666 250.704435 \n",
       "L 259.43573 250.650809 \n",
       "L 259.580795 250.761545 \n",
       "L 259.870924 250.621294 \n",
       "L 260.161053 251.09974 \n",
       "L 260.306118 250.945311 \n",
       "L 260.596247 250.929326 \n",
       "L 260.741312 251.199636 \n",
       "L 260.886376 251.132852 \n",
       "L 261.031441 251.253777 \n",
       "L 261.176505 250.858106 \n",
       "L 261.611699 250.969876 \n",
       "L 261.756764 250.931258 \n",
       "L 262.046893 250.520378 \n",
       "L 262.191958 250.873213 \n",
       "L 262.337022 250.766771 \n",
       "L 262.482087 250.925371 \n",
       "L 262.627151 250.533705 \n",
       "L 262.772216 250.848543 \n",
       "L 262.91728 250.790752 \n",
       "L 263.062345 250.878279 \n",
       "L 263.20741 250.787002 \n",
       "L 263.497539 251.254471 \n",
       "L 263.787668 251.649807 \n",
       "L 263.932733 251.315438 \n",
       "L 264.077797 251.310419 \n",
       "L 264.222862 251.728964 \n",
       "L 264.367926 251.293285 \n",
       "L 264.512991 251.368985 \n",
       "L 264.658056 251.217133 \n",
       "L 264.948185 250.759527 \n",
       "L 265.093249 250.732553 \n",
       "L 265.238314 250.516911 \n",
       "L 265.383378 250.570145 \n",
       "L 265.673508 251.088982 \n",
       "L 265.818572 251.089301 \n",
       "L 265.963637 250.893588 \n",
       "L 266.108701 251.28534 \n",
       "L 266.253766 251.255259 \n",
       "L 266.398831 251.414623 \n",
       "L 266.68896 250.987226 \n",
       "L 266.834024 251.089496 \n",
       "L 266.979089 250.935411 \n",
       "L 267.124154 251.553145 \n",
       "L 267.269218 251.650029 \n",
       "L 267.414283 251.562744 \n",
       "L 267.704412 250.859384 \n",
       "L 267.994541 250.970784 \n",
       "L 268.139606 250.621064 \n",
       "L 268.28467 250.790252 \n",
       "L 268.429735 250.563054 \n",
       "L 269.009993 251.719652 \n",
       "L 269.300122 251.838071 \n",
       "L 269.445187 251.711235 \n",
       "L 269.735316 252.126432 \n",
       "L 270.025445 252.099328 \n",
       "L 270.605704 252.047716 \n",
       "L 270.750768 252.174721 \n",
       "L 271.185962 251.236569 \n",
       "L 271.331027 251.228017 \n",
       "L 271.476091 251.444161 \n",
       "L 271.76622 251.209561 \n",
       "L 272.781672 250.577141 \n",
       "L 272.926737 250.734524 \n",
       "L 273.071802 250.638675 \n",
       "L 273.216866 250.759138 \n",
       "L 273.361931 250.731222 \n",
       "L 273.797125 249.999679 \n",
       "L 273.942189 250.044694 \n",
       "L 274.232318 249.377494 \n",
       "L 274.377383 249.594266 \n",
       "L 274.957641 249.126157 \n",
       "L 275.102706 249.196311 \n",
       "L 275.392835 249.015346 \n",
       "L 275.5379 248.828202 \n",
       "L 275.828029 248.914272 \n",
       "L 275.973093 248.861008 \n",
       "L 276.118158 248.257672 \n",
       "L 276.553352 248.464066 \n",
       "L 276.988545 247.968528 \n",
       "L 277.13361 248.417352 \n",
       "L 277.278675 248.30895 \n",
       "L 277.423739 248.454005 \n",
       "L 278.003998 248.281902 \n",
       "L 278.294127 248.145935 \n",
       "L 278.439191 248.774731 \n",
       "L 278.72932 248.899667 \n",
       "L 279.01945 249.39354 \n",
       "L 279.164514 249.596265 \n",
       "L 279.309579 249.532768 \n",
       "L 279.454643 249.342794 \n",
       "L 279.744773 249.355559 \n",
       "L 279.889837 248.888029 \n",
       "L 280.034902 249.170566 \n",
       "L 280.179966 249.030447 \n",
       "L 280.470096 249.060551 \n",
       "L 280.61516 248.831497 \n",
       "L 280.760225 249.028201 \n",
       "L 280.905289 249.006221 \n",
       "L 281.195418 249.561542 \n",
       "L 281.340483 249.622042 \n",
       "L 281.485548 249.871993 \n",
       "L 281.630612 249.51931 \n",
       "L 281.775677 249.510333 \n",
       "L 282.210871 250.095782 \n",
       "L 282.355935 249.981049 \n",
       "L 282.646064 250.513672 \n",
       "L 283.081258 249.920148 \n",
       "L 283.371387 249.297744 \n",
       "L 283.516452 249.48258 \n",
       "L 284.09671 249.260674 \n",
       "L 284.386839 249.141099 \n",
       "L 284.676969 249.358688 \n",
       "L 285.257227 249.76467 \n",
       "L 285.547356 250.735342 \n",
       "L 285.98255 249.74874 \n",
       "L 286.127614 249.668776 \n",
       "L 286.707873 250.456893 \n",
       "L 286.852937 250.0409 \n",
       "L 286.998002 250.487064 \n",
       "L 287.143067 250.305328 \n",
       "L 287.288131 250.399437 \n",
       "L 287.433196 249.826383 \n",
       "L 287.57826 249.87177 \n",
       "L 287.723325 250.276363 \n",
       "L 287.868389 249.963407 \n",
       "L 288.158519 250.132694 \n",
       "L 288.448648 251.03196 \n",
       "L 288.738777 251.688604 \n",
       "L 289.028906 251.551305 \n",
       "L 289.173971 251.438956 \n",
       "L 289.4641 251.928075 \n",
       "L 289.754229 251.699119 \n",
       "L 290.044358 251.745364 \n",
       "L 290.189423 252.064888 \n",
       "L 290.334487 251.878662 \n",
       "L 290.479552 251.990707 \n",
       "L 290.624617 252.585437 \n",
       "L 290.769681 252.409585 \n",
       "L 291.05981 252.92806 \n",
       "L 291.204875 252.695569 \n",
       "L 291.34994 252.70185 \n",
       "L 291.495004 252.837147 \n",
       "L 291.930198 252.454691 \n",
       "L 292.075262 252.671287 \n",
       "L 292.365392 252.715432 \n",
       "L 292.510456 252.92778 \n",
       "L 292.655521 252.558492 \n",
       "L 292.94565 252.607529 \n",
       "L 293.090715 252.52596 \n",
       "L 293.380844 252.648371 \n",
       "L 293.816038 252.197804 \n",
       "L 293.961102 252.521351 \n",
       "L 294.106167 252.410868 \n",
       "L 294.54136 252.776955 \n",
       "L 294.83149 252.790213 \n",
       "L 295.121619 252.769225 \n",
       "L 295.266683 252.48669 \n",
       "L 295.411748 252.628577 \n",
       "L 295.701877 252.365756 \n",
       "L 295.846942 252.503448 \n",
       "L 295.992006 252.235538 \n",
       "L 296.137071 252.455485 \n",
       "L 296.282135 252.1515 \n",
       "L 296.572265 252.185316 \n",
       "L 296.717329 251.898381 \n",
       "L 296.862394 252.091692 \n",
       "L 297.152523 252.031437 \n",
       "L 297.297588 252.112177 \n",
       "L 297.442652 252.528212 \n",
       "L 297.587717 252.563616 \n",
       "L 297.732781 252.766933 \n",
       "L 298.022911 252.352616 \n",
       "L 298.167975 252.321219 \n",
       "L 298.31304 251.737922 \n",
       "L 298.458104 251.697094 \n",
       "L 298.603169 251.831348 \n",
       "L 298.748233 251.398978 \n",
       "L 298.893298 251.59153 \n",
       "L 299.038363 251.485431 \n",
       "L 299.618621 250.134464 \n",
       "L 299.763686 250.165723 \n",
       "L 299.90875 250.039597 \n",
       "L 300.343944 250.307767 \n",
       "L 300.489008 250.639708 \n",
       "L 300.924202 250.735499 \n",
       "L 301.214331 250.387886 \n",
       "L 301.359396 250.824324 \n",
       "L 301.504461 250.843646 \n",
       "L 301.649525 251.237001 \n",
       "L 301.79459 251.130282 \n",
       "L 301.939654 251.547625 \n",
       "L 302.084719 251.542921 \n",
       "L 302.229784 251.361 \n",
       "L 302.374848 251.623191 \n",
       "L 302.664977 251.29556 \n",
       "L 302.810042 251.23553 \n",
       "L 302.955106 250.739386 \n",
       "L 303.100171 250.721235 \n",
       "L 303.245236 250.42476 \n",
       "L 303.680429 250.808281 \n",
       "L 303.825494 250.756692 \n",
       "L 303.970559 250.406183 \n",
       "L 304.260688 250.464019 \n",
       "L 304.405752 250.795585 \n",
       "L 304.550817 250.595066 \n",
       "L 304.840946 250.951957 \n",
       "L 304.986011 250.751913 \n",
       "L 305.856398 251.308437 \n",
       "L 306.001463 250.950649 \n",
       "L 306.146527 251.054685 \n",
       "L 306.291592 250.678791 \n",
       "L 306.436657 250.795147 \n",
       "L 306.581721 250.65771 \n",
       "L 306.87185 250.674988 \n",
       "L 307.016915 250.370958 \n",
       "L 307.161979 250.770004 \n",
       "L 307.887302 250.080646 \n",
       "L 308.032367 250.228611 \n",
       "L 308.177432 249.937933 \n",
       "L 308.322496 250.239628 \n",
       "L 308.467561 250.039226 \n",
       "L 308.612625 250.209525 \n",
       "L 308.75769 250.171592 \n",
       "L 308.902755 250.467297 \n",
       "L 309.337948 249.556942 \n",
       "L 309.483013 249.489688 \n",
       "L 309.773142 249.966006 \n",
       "L 309.918207 249.79826 \n",
       "L 310.063271 249.971719 \n",
       "L 310.64353 249.481014 \n",
       "L 310.788594 249.72808 \n",
       "L 310.933659 249.438832 \n",
       "L 311.513917 250.145151 \n",
       "L 311.658982 249.634866 \n",
       "L 311.949111 249.816267 \n",
       "L 312.094175 249.58349 \n",
       "L 312.23924 249.683207 \n",
       "L 312.384305 250.115539 \n",
       "L 312.529369 250.018423 \n",
       "L 312.674434 249.626006 \n",
       "L 312.964563 250.302316 \n",
       "L 313.254692 250.566021 \n",
       "L 313.544821 250.385674 \n",
       "L 313.689886 250.470935 \n",
       "L 313.83495 250.23539 \n",
       "L 314.12508 251.071956 \n",
       "L 314.270144 250.80087 \n",
       "L 314.415209 250.960853 \n",
       "L 314.560273 250.77297 \n",
       "L 314.995467 251.309726 \n",
       "L 315.140532 251.209755 \n",
       "L 315.72079 251.650882 \n",
       "L 315.865855 251.521187 \n",
       "L 316.010919 250.951836 \n",
       "L 316.446113 250.742346 \n",
       "L 316.591178 250.486628 \n",
       "L 316.736242 250.514289 \n",
       "L 316.881307 250.238799 \n",
       "L 317.171436 250.36993 \n",
       "L 317.316501 250.200666 \n",
       "L 317.461565 250.628589 \n",
       "L 317.60663 250.4883 \n",
       "L 317.751694 250.805988 \n",
       "L 318.041824 250.599425 \n",
       "L 318.477017 250.810485 \n",
       "L 318.622082 250.259155 \n",
       "L 318.767146 250.211004 \n",
       "L 318.912211 249.957848 \n",
       "L 319.057276 250.296981 \n",
       "L 319.347405 250.3026 \n",
       "L 319.637534 249.985129 \n",
       "L 319.927663 250.105218 \n",
       "L 320.072728 250.064386 \n",
       "L 320.217792 249.665605 \n",
       "L 320.798051 250.726619 \n",
       "L 321.08818 250.705774 \n",
       "L 321.233244 250.803023 \n",
       "L 321.378309 250.665093 \n",
       "L 321.523374 250.774435 \n",
       "L 321.813503 250.156319 \n",
       "L 322.103632 250.494569 \n",
       "L 322.248697 250.764158 \n",
       "L 322.538826 250.63732 \n",
       "L 322.68389 250.818205 \n",
       "L 322.828955 250.684674 \n",
       "L 322.974019 250.858031 \n",
       "L 323.119084 250.303386 \n",
       "L 323.264149 250.484217 \n",
       "L 323.554278 250.397078 \n",
       "L 323.699342 250.614455 \n",
       "L 323.989472 250.518051 \n",
       "L 324.134536 250.568136 \n",
       "L 324.56973 249.864439 \n",
       "L 324.859859 250.095046 \n",
       "L 325.149988 250.838322 \n",
       "L 325.440117 250.509998 \n",
       "L 325.585182 250.16062 \n",
       "L 325.730247 250.193669 \n",
       "L 326.020376 249.873164 \n",
       "L 326.16544 250.183734 \n",
       "L 326.310505 250.121283 \n",
       "L 326.45557 249.817214 \n",
       "L 326.600634 249.970143 \n",
       "L 326.890763 249.657036 \n",
       "L 327.325957 250.212975 \n",
       "L 327.471022 249.915923 \n",
       "L 327.616086 249.997072 \n",
       "L 328.196345 249.816163 \n",
       "L 328.486474 250.301204 \n",
       "L 328.921668 249.929895 \n",
       "L 329.356861 249.762661 \n",
       "L 329.501926 249.511745 \n",
       "L 329.64699 249.739321 \n",
       "L 329.93712 249.40807 \n",
       "L 330.372313 249.279274 \n",
       "L 330.662443 249.533307 \n",
       "L 330.952572 249.801045 \n",
       "L 331.097636 250.266906 \n",
       "L 331.242701 250.150338 \n",
       "L 331.53283 250.677814 \n",
       "L 331.968024 251.051802 \n",
       "L 332.113088 251.10941 \n",
       "L 332.258153 250.484557 \n",
       "L 332.403218 250.428993 \n",
       "L 332.693347 250.780534 \n",
       "L 332.838411 250.78251 \n",
       "L 333.41867 251.355597 \n",
       "L 333.853863 250.80861 \n",
       "L 333.998928 251.254879 \n",
       "L 334.579186 250.578013 \n",
       "L 334.724251 251.004848 \n",
       "L 334.869316 251.042121 \n",
       "L 335.304509 250.595295 \n",
       "L 335.449574 250.372994 \n",
       "L 335.594639 250.381783 \n",
       "L 335.739703 250.221911 \n",
       "L 335.884768 250.359316 \n",
       "L 336.029832 250.273902 \n",
       "L 336.319961 250.734955 \n",
       "L 336.755155 250.29851 \n",
       "L 337.045284 250.065822 \n",
       "L 337.335414 250.661182 \n",
       "L 337.480478 250.352458 \n",
       "L 337.625543 250.766972 \n",
       "L 337.770607 250.52492 \n",
       "L 337.915672 250.512504 \n",
       "L 338.205801 250.954193 \n",
       "L 338.49593 251.180079 \n",
       "L 338.640995 251.007279 \n",
       "L 338.931124 251.567368 \n",
       "L 339.076189 251.780276 \n",
       "L 339.221253 251.578679 \n",
       "L 339.656447 250.387576 \n",
       "L 340.091641 250.920078 \n",
       "L 340.38177 250.816369 \n",
       "L 340.816964 250.159535 \n",
       "L 340.962028 250.315951 \n",
       "L 341.107093 250.088963 \n",
       "L 341.252157 250.238645 \n",
       "L 341.397222 250.029903 \n",
       "L 341.687351 250.14005 \n",
       "L 341.832416 249.932276 \n",
       "L 341.97748 250.102385 \n",
       "L 342.122545 250.016703 \n",
       "L 342.847868 250.861777 \n",
       "L 342.992932 250.360048 \n",
       "L 343.283062 250.490451 \n",
       "L 343.428126 250.181584 \n",
       "L 343.718255 250.25902 \n",
       "L 344.008385 250.625364 \n",
       "L 344.153449 250.447184 \n",
       "L 344.298514 250.647867 \n",
       "L 344.443578 250.61308 \n",
       "L 344.588643 250.374947 \n",
       "L 345.168901 250.613724 \n",
       "L 345.45903 250.242749 \n",
       "L 345.604095 250.13346 \n",
       "L 345.894224 250.182825 \n",
       "L 346.039289 250.104884 \n",
       "L 346.184353 249.843061 \n",
       "L 346.329418 249.833734 \n",
       "L 346.474483 249.638357 \n",
       "L 346.619547 249.807314 \n",
       "L 346.764612 250.278133 \n",
       "L 347.34487 249.882717 \n",
       "L 347.780064 250.030821 \n",
       "L 347.925128 250.235323 \n",
       "L 348.070193 250.185706 \n",
       "L 348.360322 250.572051 \n",
       "L 348.505387 250.518507 \n",
       "L 348.795516 250.918864 \n",
       "L 348.940581 250.985661 \n",
       "L 349.085645 251.195437 \n",
       "L 349.375774 250.065192 \n",
       "L 349.665903 249.98829 \n",
       "L 350.246162 250.651735 \n",
       "L 350.536291 250.633989 \n",
       "L 350.82642 250.691208 \n",
       "L 350.971485 250.872242 \n",
       "L 351.116549 250.796456 \n",
       "L 351.261614 250.406693 \n",
       "L 351.406678 250.58939 \n",
       "L 351.551743 250.536181 \n",
       "L 351.841872 250.347824 \n",
       "L 351.986937 250.503327 \n",
       "L 352.277066 250.201236 \n",
       "L 352.567195 250.423436 \n",
       "L 353.582647 250.264932 \n",
       "L 354.017841 251.575884 \n",
       "L 354.453035 251.557904 \n",
       "L 354.598099 251.830303 \n",
       "L 354.743164 251.71876 \n",
       "L 355.033293 251.970144 \n",
       "L 355.178358 252.399056 \n",
       "L 355.468487 252.171474 \n",
       "L 355.613552 252.574218 \n",
       "L 355.758616 252.647137 \n",
       "L 355.903681 252.914009 \n",
       "L 356.048745 252.771258 \n",
       "L 356.19381 252.943517 \n",
       "L 356.629004 252.54407 \n",
       "L 356.629004 252.54407 \n",
       "\" clip-path=\"url(#p13a8f3cb3c)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 277.111219 \n",
       "L 30.103125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 387.223125 277.111219 \n",
       "L 387.223125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 277.111219 \n",
       "L 387.223125 277.111219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 10.999219 \n",
       "L 387.223125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_12\">\n",
       "    <!-- 0.092 -->\n",
       "    <g transform=\"translate(370.990398 252.54407) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-39\" d=\"M 703 97 \n",
       "L 703 672 \n",
       "Q 941 559 1184 500 \n",
       "Q 1428 441 1663 441 \n",
       "Q 2288 441 2617 861 \n",
       "Q 2947 1281 2994 2138 \n",
       "Q 2813 1869 2534 1725 \n",
       "Q 2256 1581 1919 1581 \n",
       "Q 1219 1581 811 2004 \n",
       "Q 403 2428 403 3163 \n",
       "Q 403 3881 828 4315 \n",
       "Q 1253 4750 1959 4750 \n",
       "Q 2769 4750 3195 4129 \n",
       "Q 3622 3509 3622 2328 \n",
       "Q 3622 1225 3098 567 \n",
       "Q 2575 -91 1691 -91 \n",
       "Q 1453 -91 1209 -44 \n",
       "Q 966 3 703 97 \n",
       "z\n",
       "M 1959 2075 \n",
       "Q 2384 2075 2632 2365 \n",
       "Q 2881 2656 2881 3163 \n",
       "Q 2881 3666 2632 3958 \n",
       "Q 2384 4250 1959 4250 \n",
       "Q 1534 4250 1286 3958 \n",
       "Q 1038 3666 1038 3163 \n",
       "Q 1038 2656 1286 2365 \n",
       "Q 1534 2075 1959 2075 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-39\" x=\"159.033203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-32\" x=\"222.65625\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_13\">\n",
       "    <!-- Epoch: 5 Loss: 0.1 -->\n",
       "    <g transform=\"translate(46.350359 37.610419) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-45\" d=\"M 628 4666 \n",
       "L 3578 4666 \n",
       "L 3578 4134 \n",
       "L 1259 4134 \n",
       "L 1259 2753 \n",
       "L 3481 2753 \n",
       "L 3481 2222 \n",
       "L 1259 2222 \n",
       "L 1259 531 \n",
       "L 3634 531 \n",
       "L 3634 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-3a\" d=\"M 750 794 \n",
       "L 1409 794 \n",
       "L 1409 0 \n",
       "L 750 0 \n",
       "L 750 794 \n",
       "z\n",
       "M 750 3309 \n",
       "L 1409 3309 \n",
       "L 1409 2516 \n",
       "L 750 2516 \n",
       "L 750 3309 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \n",
       "L 1259 4666 \n",
       "L 1259 531 \n",
       "L 3531 531 \n",
       "L 3531 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-45\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3a\" x=\"306.201172\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"339.892578\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-35\" x=\"371.679688\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"435.302734\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-4c\" x=\"467.089844\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"521.052734\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"582.234375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"634.333984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3a\" x=\"686.433594\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"720.125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"751.912109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2e\" x=\"815.535156\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-31\" x=\"847.322266\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_14\">\n",
       "    <!-- Learning rate: 2.5e-05 -->\n",
       "    <g transform=\"translate(46.350359 64.221619) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \n",
       "Q 2906 2416 2648 2759 \n",
       "Q 2391 3103 1925 3103 \n",
       "Q 1463 3103 1205 2759 \n",
       "Q 947 2416 947 1791 \n",
       "Q 947 1169 1205 825 \n",
       "Q 1463 481 1925 481 \n",
       "Q 2391 481 2648 825 \n",
       "Q 2906 1169 2906 1791 \n",
       "z\n",
       "M 3481 434 \n",
       "Q 3481 -459 3084 -895 \n",
       "Q 2688 -1331 1869 -1331 \n",
       "Q 1566 -1331 1297 -1286 \n",
       "Q 1028 -1241 775 -1147 \n",
       "L 775 -588 \n",
       "Q 1028 -725 1275 -790 \n",
       "Q 1522 -856 1778 -856 \n",
       "Q 2344 -856 2625 -561 \n",
       "Q 2906 -266 2906 331 \n",
       "L 2906 616 \n",
       "Q 2728 306 2450 153 \n",
       "Q 2172 0 1784 0 \n",
       "Q 1141 0 747 490 \n",
       "Q 353 981 353 1791 \n",
       "Q 353 2603 747 3093 \n",
       "Q 1141 3584 1784 3584 \n",
       "Q 2172 3584 2450 3431 \n",
       "Q 2728 3278 2906 2969 \n",
       "L 2906 3500 \n",
       "L 3481 3500 \n",
       "L 3481 434 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \n",
       "L 1997 2009 \n",
       "L 1997 1497 \n",
       "L 313 1497 \n",
       "L 313 2009 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-4c\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"53.962891\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"115.486328\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"176.765625\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"216.128906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"279.507812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"307.291016\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-67\" x=\"370.669922\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"434.146484\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"465.933594\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"507.046875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"568.326172\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"607.535156\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3a\" x=\"669.058594\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"702.75\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-32\" x=\"734.537109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2e\" x=\"798.160156\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-35\" x=\"829.947266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"893.570312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2d\" x=\"955.09375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"991.177734\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-35\" x=\"1054.800781\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_15\">\n",
       "    <!-- Validation mae: 0.836 -->\n",
       "    <g transform=\"translate(46.350359 90.832819) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-56\" d=\"M 1831 0 \n",
       "L 50 4666 \n",
       "L 709 4666 \n",
       "L 2188 738 \n",
       "L 3669 4666 \n",
       "L 4325 4666 \n",
       "L 2547 0 \n",
       "L 1831 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"149.720703\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"177.503906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"240.980469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"302.259766\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"341.46875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"369.251953\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"430.433594\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"493.8125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\" x=\"525.599609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"623.011719\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"684.291016\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3a\" x=\"745.814453\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"779.505859\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"811.292969\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2e\" x=\"874.916016\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-38\" x=\"906.703125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-33\" x=\"970.326172\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-36\" x=\"1033.949219\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p13a8f3cb3c\">\n",
       "   <rect x=\"30.103125\" y=\"10.999219\" width=\"357.12\" height=\"266.112\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(\n",
    "    diffusion_imputer, \n",
    "    data_loader_model, \n",
    "    data_loader_validation,\n",
    "    epochs = 20, \n",
    "    lr = 0.0001, \n",
    "    loss_func = diffusion_imputer.loss_func,\n",
    "    validation_frequency=1,\n",
    "    validation_prp=10,\n",
    "    strategy = \"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the entire model for further training\n",
    "#torch.save(diffusion_imputer, \"diffusion_imputer.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diffusion_imputer = torch.load(\"diffusion_imputer.pt\")\n",
    "#diffusion_imputer = torch.load(\"diffusion_imputer_forecast.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batch_test = 1\n",
    "#data_loader_test = get_dataloader(len(test_set), \"cuda\")[2]\n",
    "data_loader_test = get_dataloader(num_batch_test, \"cuda\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae =  0.418857890991169\n",
      "mae =  0.19646491824235082\n",
      "mae =  0.22354011554116476\n",
      "mae =  0.36338284707204843\n",
      "mae =  0.37546039605006354\n",
      "mae =  0.2988044928332139\n",
      "mae =  0.2856591228062862\n",
      "mae =  0.23676309920208014\n",
      "mae =  0.26417920232977454\n",
      "mae =  0.2919382735256541\n",
      "mae =  0.4896783119383454\n",
      "mae =  0.34829992848753266\n",
      "mae =  0.3011230637242709\n",
      "mae =  0.14378104108374606\n",
      "mae =  0.17679428875505032\n",
      "mae =  0.21561572731876721\n",
      "mae =  0.24926960283897528\n",
      "mae =  0.22381714290454865\n",
      "mae =  0.34488090301970703\n",
      "mae =  0.22697039708756458\n",
      "mae =  0.2797174785877823\n",
      "mae =  0.23751661870160803\n",
      "mae =  0.18334699035312588\n",
      "mae =  0.17837859763377378\n",
      "mae =  0.20790192762166468\n",
      "mae =  0.18132561078396117\n",
      "mae =  0.1743630258230839\n",
      "mae =  0.2602892528017658\n",
      "mae =  0.1890046495419059\n",
      "mae =  0.21289631260923012\n",
      "mae =  0.2843495711845621\n",
      "mae =  0.43330300339743955\n",
      "mae =  0.2870493653244742\n",
      "mae =  0.3791114658139502\n",
      "mae =  0.1909244813218794\n",
      "mae =  0.17721587432577282\n",
      "mae =  0.20048074951096784\n",
      "mae =  0.2281828561102431\n",
      "mae =  0.2173262011920785\n",
      "mae =  0.21995931873881705\n",
      "mae =  0.2007965695979033\n",
      "mae =  0.1915261403965111\n",
      "mae =  0.20566774110928923\n",
      "mae =  0.2114944726044678\n",
      "mae =  0.2458583602701417\n",
      "mae =  0.30441065396881123\n",
      "mae =  0.15977529800835194\n",
      "mae =  0.1789063915829824\n",
      "mae =  0.26979927058731695\n",
      "mae =  0.24908055586292763\n",
      "mae =  0.2319139338507137\n",
      "mae =  0.1873204977609613\n",
      "mae =  0.2333009465119809\n",
      "mae =  0.26752630246733383\n",
      "mae =  0.31978078212078187\n",
      "mae =  0.18334489933322135\n",
      "mae =  0.24019945155486824\n",
      "mae =  0.16985853232152057\n",
      "mae =  0.2863386266932137\n",
      "mae =  0.21684455913623632\n",
      "mae =  0.24092571434091978\n",
      "mae =  0.248786574663615\n",
      "mae =  0.2070529453125829\n",
      "mae =  0.26469887928600605\n",
      "mae =  0.33232596395221015\n",
      "mae =  0.28398206239263346\n",
      "mae =  0.49284024153733014\n",
      "mae =  0.46660372658240973\n",
      "mae =  0.1846985083662114\n",
      "mae =  0.41685482320462824\n",
      "mae =  0.4174067069036219\n",
      "mae =  0.2173309275172477\n",
      "mae =  0.34348964259786796\n",
      "mae =  0.25183707611659945\n",
      "mae =  0.2074270356306646\n",
      "mae =  0.38688271591328066\n",
      "mae =  0.331164617773313\n",
      "mae =  0.327900735167058\n",
      "mae =  0.5221870539156503\n",
      "mae =  0.7364524706331164\n",
      "mae =  0.42861884160549757\n",
      "mae =  0.18277305796330348\n"
     ]
    }
   ],
   "source": [
    "#let's try to impute the data\n",
    "imputed_samples_from_loop = torch.tensor([]).to(\"cuda\")\n",
    "data_from_loop = torch.tensor([]).to(\"cuda\")\n",
    "#imputation_mask_from_loop = torch.tensor([]).to(\"cuda\")\n",
    "\n",
    "data_shape = test_set[0][\"observed_data\"].shape\n",
    "data_shape = (num_batch_test, data_shape[0], data_shape[1])\n",
    "zeros_for_shape = torch.zeros(data_shape).to(\"cuda\")\n",
    "        \n",
    "imputation_mask = diffusion_imputation.get_mask(diffusion_imputer, zeros_for_shape, \"random\").to(\"cuda\")\n",
    "\n",
    "for i in range(1):\n",
    "    imputed_samples = torch.tensor([]).to(\"cuda\")\n",
    "    data = torch.tensor([]).to(\"cuda\")\n",
    "    #imputation_mask = torch.tensor([]).to(\"cuda\")\n",
    "    \n",
    "    for i, batch in enumerate(data_loader_test):\n",
    "                test_data = batch[\"observed_data\"].to(\"cuda\")\n",
    "                imputed_step, data_step, imputation_mask, mae = diffusion_imputation.eval(diffusion_imputer, test_data, imputation_mask)\n",
    "                imputed_samples = torch.cat((imputed_samples, imputed_step), dim = 0)\n",
    "                data = torch.cat((data, data_step), dim = 0)\n",
    "                #imputation_mask = torch.cat((imputation_mask, imputation_mask_step), dim = 0)\n",
    "\n",
    "    imputed_samples_from_loop = torch.cat((imputed_samples_from_loop, imputed_samples), dim = 0)\n",
    "    data_from_loop = torch.cat((data_from_loop, data), dim = 0)\n",
    "    #imputation_mask_from_loop = torch.cat((imputation_mask_from_loop, imputation_mask), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_mask = imputation_mask.repeat(len(test_set), 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the medians in the imputed samples\n",
    "imputed_samples = imputed_samples_from_loop.reshape(1, -1, 36, 36)\n",
    "data = data_from_loop.reshape(1, -1, 36, 36)\n",
    "\n",
    "#find the medians in the imputed samples\n",
    "imputed_samples = torch.mean(imputed_samples, dim = 0).squeeze(0)\n",
    "data = torch.mean(data, dim = 0).squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae =  tensor(21.8097, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59486/2232482165.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  imputed_samples_unnormalized = torch.tensor(imputed_samples).cpu() * torch.tensor(test_set.train_std).unsqueeze(0) + torch.tensor(test_set.train_mean).unsqueeze(0)\n",
      "/tmp/ipykernel_59486/2232482165.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data_unnormalized = torch.tensor(data).cpu() * torch.tensor(test_set.train_std).unsqueeze(0) + torch.tensor(test_set.train_mean).unsqueeze(0)\n",
      "/tmp/ipykernel_59486/2232482165.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  imputation_mask = torch.tensor(imputation_mask).cpu()\n"
     ]
    }
   ],
   "source": [
    "# go back to non-standardized data to find actual MAEs\n",
    "imputed_samples_unnormalized = torch.tensor(imputed_samples).cpu() * torch.tensor(test_set.train_std).unsqueeze(0) + torch.tensor(test_set.train_mean).unsqueeze(0)\n",
    "data_unnormalized = torch.tensor(data).cpu() * torch.tensor(test_set.train_std).unsqueeze(0) + torch.tensor(test_set.train_mean).unsqueeze(0)\n",
    "imputation_mask = torch.tensor(imputation_mask).cpu()\n",
    "print(\"mae = \", torch.mean(torch.abs(data_unnormalized[imputation_mask !=0] - imputed_samples_unnormalized[imputation_mask !=0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch print options full\n",
    "torch.set_printoptions(profile=\"full\",\n",
    "                       sci_mode=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [551368, 36, 36] at index 0 does not match the shape of the indexed tensor [82, 36, 36] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_unnormalized[imputation_mask \u001b[39m!=\u001b[39;49m\u001b[39m0\u001b[39;49m][\u001b[39m1\u001b[39m:\u001b[39m100\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [551368, 36, 36] at index 0 does not match the shape of the indexed tensor [82, 36, 36] at index 0"
     ]
    }
   ],
   "source": [
    "data_unnormalized[imputation_mask !=0][1:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 34.9963,  23.2568,  47.4475,  47.5244,  54.5048,  95.9417, 116.3080,\n",
       "         91.5447,  44.1892,  91.6655,  83.0030,  53.0332,  35.5806,  87.5924,\n",
       "         82.3044,  51.3048,  64.5171,  66.6078, 109.3856,  39.9366,  71.7345,\n",
       "         57.3993,  47.5157,  43.0024,  69.5056,  74.5933, 104.0991,  57.0694,\n",
       "         60.3715,  84.8199,  31.1233,  74.2255,  75.1179,  99.5438,  58.5142,\n",
       "         96.8189,  46.8217,  34.0245,  61.7523,  56.0005,  37.8638,  44.4748,\n",
       "         46.0841,  33.2558, 117.2678,  68.4680,  64.4076,  79.0463,  47.9326,\n",
       "         72.9578,  49.2219,  40.3973,  83.5628,  47.8288,  52.0246,  60.1921,\n",
       "         61.3846,  61.4409,  68.1914,  50.2513,  33.0585,  48.8325,  59.6896,\n",
       "         99.3909,  73.0521,  92.6394,  26.7090,  71.8967,  66.0155,  45.3300,\n",
       "         80.0853,  59.6657,  56.2613,  80.9261,  69.6189,  90.0310,  51.6439,\n",
       "         52.1246,  34.4143,  46.1008,  48.4730,  89.5857,  60.5456,  43.3636,\n",
       "         88.9335,  40.1827,  49.0529,  48.5600,  38.2294,  52.3874,  67.4620,\n",
       "         79.1086,  79.9010,  27.8511,  68.5786,  91.3036,  59.4609,  41.9386,\n",
       "         29.2744], dtype=torch.float64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_samples_unnormalized[imputation_mask !=0][1:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([154.0037, 205.7432, 120.5525, 172.4756,  28.5048,  70.9417,  48.3080,\n",
       "        182.4553,  26.1892,  63.6655,  45.0030, 159.9668,  10.5806, 188.4076,\n",
       "         68.3044,  38.3048,  49.5171,  52.6078,  67.3856,  94.0634,  31.7345,\n",
       "         45.3993,  74.4843,  29.0024,  64.5056,  56.5933,  84.0991,  37.0694,\n",
       "         38.6285, 127.1801,  10.1233,  42.2255,  65.1179,  57.5438,  97.4858,\n",
       "         27.8189,   3.8217,   7.0245,  82.2477,   8.9995,  43.1362, 102.5252,\n",
       "         25.0841,  18.2558,  22.7322,  23.5320, 101.5924,  58.9537,   4.9326,\n",
       "         18.0422, 154.7781,   3.6027,  68.4372,  58.1712,  19.0246,  49.8079,\n",
       "         34.6154, 114.5591,  34.1914,  11.2513,   7.9415,  24.8325,  32.6896,\n",
       "         64.3909,  30.0521,  63.6394,   4.2910,  50.8967,  38.0155,  18.3300,\n",
       "         68.0853,  43.6657,  29.2613,  61.9261,  51.6189,  62.0310,  34.6439,\n",
       "         40.1246,   8.4143,  29.1008,  40.4730,  59.5857,  29.5456,   8.3636,\n",
       "         57.9335,  20.1827,   9.0529,   2.5600,  20.7706,  30.3874,  12.4620,\n",
       "         23.1086,  28.9010,   8.1489,   9.5786,  44.3036,   0.4609,  38.0614,\n",
       "         30.7256], dtype=torch.float64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(data_unnormalized[imputation_mask !=0] - imputed_samples_unnormalized[imputation_mask !=0])[1:100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electricity data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
