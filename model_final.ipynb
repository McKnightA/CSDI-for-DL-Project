{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 24 12:38:40 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    61W / 500W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#show nvidia card info\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import zipfile\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collecting and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alinezhad.f'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### downloading the data (should only need to do this once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(\"data_project/\", exist_ok=True)\n",
    "# url = \"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/STMVL-Release.zip\"\n",
    "# urlData = requests.get(url).content\n",
    "# filename = \"data_project/STMVL-Release.zip\"\n",
    "# with open(filename, mode=\"wb\") as f:\n",
    "#     f.write(urlData)\n",
    "# with zipfile.ZipFile(filename) as z:\n",
    "#     z.extractall(\"data_project/pm25\")\n",
    "        \n",
    "def create_normalizer_pm25():\n",
    "    df = pd.read_csv(\n",
    "        \"/home/alinezhad.f/data_project/pm25/STMVL-Release/Code/STMVL/SampleData/pm25_ground.txt\",\n",
    "        index_col=\"datetime\",\n",
    "        parse_dates=True,\n",
    "    )\n",
    "    test_month = [3, 6, 9, 12]\n",
    "    for i in test_month:\n",
    "        df = df[df.index.month != i]\n",
    "    mean = df.describe().loc[\"mean\"].values\n",
    "    std = df.describe().loc[\"std\"].values\n",
    "    path = \"./data_project/pm25/pm25_meanstd.pk\"\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump([mean, std], f)\n",
    "create_normalizer_pm25()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PM25_Dataset(Dataset):\n",
    "    def __init__(self, eval_length=36, target_dim=36, mode=\"train\", validindex=0):\n",
    "        self.eval_length = eval_length\n",
    "        self.target_dim = target_dim\n",
    "\n",
    "        path = \"./data_project/pm25/pm25_meanstd.pk\"\n",
    "        with open(path, \"rb\") as f:\n",
    "            self.train_mean, self.train_std = pickle.load(f)\n",
    "        if mode == \"train\":\n",
    "            month_list = [1, 2, 4, 5, 7, 8, 10, 11]\n",
    "            # 1st,4th,7th,10th months are excluded from histmask (since the months are used for creating missing patterns in test dataset)\n",
    "            flag_for_histmask = [0, 1, 0, 1, 0, 1, 0, 1] \n",
    "            month_list.pop(validindex)\n",
    "            flag_for_histmask.pop(validindex)\n",
    "        elif mode == \"valid\":\n",
    "            month_list = [1, 2, 4, 5, 7, 8, 10, 11]\n",
    "            month_list = month_list[validindex : validindex + 1]\n",
    "        elif mode == \"test\":\n",
    "            month_list = [3, 6, 9, 12]\n",
    "        self.month_list = month_list\n",
    "\n",
    "        # create data for batch\n",
    "        self.observed_data = []  # values (separated into each month)\n",
    "        self.observed_mask = []  # masks (separated into each month)\n",
    "        self.gt_mask = []  # ground-truth masks (separated into each month)\n",
    "        self.index_month = []  # indicate month\n",
    "        self.position_in_month = []  # indicate the start position in month (length is the same as index_month)\n",
    "        self.valid_for_histmask = []  # whether the sample is used for histmask\n",
    "        self.use_index = []  # to separate train/valid/test\n",
    "        self.cut_length = []  # excluded from evaluation targets\n",
    "\n",
    "        df = pd.read_csv(\n",
    "            \"./data_project/pm25/STMVL-Release/Code/STMVL/SampleData/pm25_ground.txt\",\n",
    "            index_col=\"datetime\",\n",
    "            parse_dates=True,\n",
    "        )\n",
    "        df_gt = pd.read_csv(\n",
    "            \"./data_project/pm25/STMVL-Release/Code/STMVL/SampleData/pm25_missing.txt\",\n",
    "            index_col=\"datetime\",\n",
    "            parse_dates=True,\n",
    "        )\n",
    "        for i in range(len(month_list)):\n",
    "            current_df = df[df.index.month == month_list[i]]\n",
    "            current_df_gt = df_gt[df_gt.index.month == month_list[i]]\n",
    "            current_length = len(current_df) - eval_length + 1\n",
    "\n",
    "            last_index = len(self.index_month)\n",
    "            self.index_month += np.array([i] * current_length).tolist()\n",
    "            self.position_in_month += np.arange(current_length).tolist()\n",
    "            if mode == \"train\":\n",
    "                self.valid_for_histmask += np.array(\n",
    "                    [flag_for_histmask[i]] * current_length\n",
    "                ).tolist()\n",
    "\n",
    "            # mask values for observed indices are 1\n",
    "            c_mask = 1 - current_df.isnull().values\n",
    "            c_gt_mask = 1 - current_df_gt.isnull().values\n",
    "            c_data = (\n",
    "                (current_df.fillna(0).values - self.train_mean) / self.train_std\n",
    "            ) * c_mask\n",
    "\n",
    "            self.observed_mask.append(c_mask)\n",
    "            self.gt_mask.append(c_gt_mask)\n",
    "            self.observed_data.append(c_data)\n",
    "\n",
    "            if mode == \"test\":\n",
    "                n_sample = len(current_df) // eval_length\n",
    "                # interval size is eval_length (missing values are imputed only once)\n",
    "                c_index = np.arange(\n",
    "                    last_index, last_index + eval_length * n_sample, eval_length\n",
    "                )\n",
    "                self.use_index += c_index.tolist()\n",
    "                self.cut_length += [0] * len(c_index)\n",
    "                if len(current_df) % eval_length != 0:  # avoid double-count for the last time-series\n",
    "                    self.use_index += [len(self.index_month) - 1]\n",
    "                    self.cut_length += [eval_length - len(current_df) % eval_length]\n",
    "\n",
    "        if mode != \"test\":\n",
    "            self.use_index = np.arange(len(self.index_month))\n",
    "            self.cut_length = [0] * len(self.use_index)\n",
    "\n",
    "        # masks for 1st,4th,7th,10th months are used for creating missing patterns in test data,\n",
    "        # so these months are excluded from histmask to avoid leakage\n",
    "        if mode == \"train\":\n",
    "            ind = -1\n",
    "            self.index_month_histmask = []\n",
    "            self.position_in_month_histmask = []\n",
    "\n",
    "            for i in range(len(self.index_month)):\n",
    "                while True:\n",
    "                    ind += 1\n",
    "                    if ind == len(self.index_month):\n",
    "                        ind = 0\n",
    "                    if self.valid_for_histmask[ind] == 1:\n",
    "                        self.index_month_histmask.append(self.index_month[ind])\n",
    "                        self.position_in_month_histmask.append(\n",
    "                            self.position_in_month[ind]\n",
    "                        )\n",
    "                        break\n",
    "        else:  # dummy (histmask is only used for training)\n",
    "            self.index_month_histmask = self.index_month\n",
    "            self.position_in_month_histmask = self.position_in_month\n",
    "\n",
    "    def __getitem__(self, org_index):\n",
    "        index = self.use_index[org_index]\n",
    "        c_month = self.index_month[index]\n",
    "        c_index = self.position_in_month[index]\n",
    "        hist_month = self.index_month_histmask[index]\n",
    "        hist_index = self.position_in_month_histmask[index]\n",
    "        s = {\n",
    "            \"observed_data\": self.observed_data[c_month][\n",
    "                c_index : c_index + self.eval_length\n",
    "            ],\n",
    "            \"observed_mask\": self.observed_mask[c_month][\n",
    "                c_index : c_index + self.eval_length\n",
    "            ],\n",
    "            \"gt_mask\": self.gt_mask[c_month][\n",
    "                c_index : c_index + self.eval_length\n",
    "            ],\n",
    "            \"hist_mask\": self.observed_mask[hist_month][\n",
    "                hist_index : hist_index + self.eval_length\n",
    "            ],\n",
    "            \"timepoints\": np.arange(self.eval_length),\n",
    "            \"cut_length\": self.cut_length[org_index],\n",
    "        }\n",
    "\n",
    "        return s\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.use_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size, device, validindex=0):\n",
    "    dataset = PM25_Dataset(mode=\"train\", validindex=validindex)\n",
    "    train_loader = DataLoader(\n",
    "        dataset, batch_size=batch_size, num_workers=3, shuffle=True\n",
    "    )\n",
    "    dataset_test = PM25_Dataset(mode=\"test\", validindex=validindex)\n",
    "    test_loader = DataLoader(\n",
    "        dataset_test, batch_size=batch_size, num_workers=1, shuffle=False\n",
    "    )\n",
    "    dataset_valid = PM25_Dataset(mode=\"valid\", validindex=validindex)\n",
    "    valid_loader = DataLoader(\n",
    "        dataset_valid, batch_size=batch_size, num_workers=1, shuffle=False\n",
    "    )\n",
    "\n",
    "    scaler = torch.from_numpy(dataset.train_std).to(device).float()\n",
    "    mean_scaler = torch.from_numpy(dataset.train_mean).to(device).float()\n",
    "\n",
    "    return train_loader, valid_loader, test_loader, scaler, mean_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moded Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesSeriesAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A module that computes multi-head attention given query, key, and value tensors for time series data of shape (b, t, f, e)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "        \n",
    "        Inputs:\n",
    "        - input_dim: Dimension of the input query, key, and value. We assume they all have\n",
    "          the same dimensions. This is basically the dimension of the embedding.\n",
    "        - num_heads: Number of attention heads\n",
    "        \"\"\"\n",
    "        super(TimesSeriesAttention, self).__init__()\n",
    "\n",
    "        assert embed_dim % num_heads == 0\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dim_per_head = embed_dim // num_heads\n",
    "\n",
    "\n",
    "        self.linear_query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_value = nn.Linear(embed_dim, (self.num_heads * self.dim_per_head * self.dim_per_head))\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.softmax = nn.Softmax2d()\n",
    "\n",
    "\n",
    "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Compute the attended feature representations.\n",
    "        \n",
    "        Inputs:\n",
    "        - query: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension, \n",
    "        and E is the embedding dimension\n",
    "        - key: Tensor of the shape BxTxFXE\n",
    "        - value: Tensor of the shape BxTxFXE\n",
    "        - mask: Tensor indicating where the attention should *not* be performed\n",
    "        \"\"\"\n",
    "        b = query.shape[0]\n",
    "        t = query.shape[1]\n",
    "        f = query.shape[2]\n",
    "        e = query.shape[3]\n",
    "        d = self.dim_per_head\n",
    "        h = self.num_heads\n",
    "\n",
    "\n",
    "        query_linear = self.linear_query(query)\n",
    "        key_linear = self.linear_key(key)\n",
    "        value_linear = self.linear_value(value)\n",
    "\n",
    "        query_reshaped = query_linear.reshape(b, t, f, self.num_heads, self.dim_per_head)\n",
    "        key_reshaped = key_linear.reshape(b, t, f, self.num_heads, self.dim_per_head)\n",
    "        value_reshaped = value_linear.reshape(b, t, f, self.num_heads, self.dim_per_head, self.dim_per_head)\n",
    "\n",
    "        query_reshaped = query_reshaped.permute(0, 3, 1, 2, 4) # BxHxTxFxD\n",
    "        key_reshaped = key_reshaped.permute(0, 3, 1, 2, 4) # BxHxTxFxD\n",
    "        value_reshaped = value_reshaped.permute(0, 3, 1, 2, 4, 5) # BxHxTxFxDxD\n",
    "\n",
    "\n",
    "        kq = torch.einsum(\"bhtfd,bhxyd->bhtfxy\", key_reshaped, query_reshaped)\n",
    "\n",
    "        dot_prod_scores = kq/math.sqrt(self.dim_per_head)\n",
    "\n",
    "\n",
    "        #softmax across last 2 features (use softmax2d)\n",
    "        dot_prod_scores = dot_prod_scores.reshape(b*h, t*f, t, f)\n",
    "        dot_prod_scores = self.softmax(dot_prod_scores)\n",
    "        dot_prod_scores = dot_prod_scores.reshape(b, h, t, f, t, f)\n",
    "\n",
    "        out = torch.einsum(\"bhtfxy,bhtfdc->bhtfd\",\n",
    "                           dot_prod_scores, value_reshaped)\n",
    "        out = out.permute(0, 2, 3, 1, 4).reshape(b, t, f, e)\n",
    "        out = self.output_linear(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single cell (unit) for the Transformer encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, dropout: float):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(TransformerEncoderCell, self).__init__()\n",
    "\n",
    "        self.time_series_attention = TimesSeriesAttention(embed_dim, num_heads)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.linear2 = nn.Linear(ff_dim, embed_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \"\"\"\n",
    "\n",
    "        attention2 = self.time_series_attention(x, x, x, mask)\n",
    "        attention = x + self.dropout1(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        attention2 = self.linear2(self.dropout(self.activation(self.linear1(attention))))\n",
    "        attention = attention + self.dropout2(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A full encoder consisting of a set of TransformerEncoderCell.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, num_cells: int, dropout: float=0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - num_cells: Number of time series attention cells in the encoder\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        \n",
    "        self.norm = None\n",
    "\n",
    "        self.encoder_modules = nn.ModuleList(TransformerEncoderCell(embed_dim, num_heads, ff_dim, dropout) for _ in range(num_cells))\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor=None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \n",
    "        Return:\n",
    "        - y: Tensor of the shape BxTxFXE\n",
    "        \"\"\"\n",
    "\n",
    "        #run encoder modules and add residual connections\n",
    "        for encoder_module in self.encoder_modules:\n",
    "            x = encoder_module(x, mask)\n",
    "\n",
    "        y = x\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch_trans(num_heads=8, num_cells=1, embed_dim=128, ff_dim=512, dropout=0.1):\n",
    "    encoder_layer = nn.TransformerEncoderLayer(\n",
    "        d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim, activation=\"gelu\", dropout=dropout\n",
    "    )\n",
    "    return nn.TransformerEncoder(encoder_layer, num_layers=num_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionEmbedding(nn.Module):\n",
    "    def __init__(self, num_steps, embedding_dim, projection_dim=None):\n",
    "        super(DiffusionEmbedding, self).__init__()\n",
    "        if projection_dim is None:\n",
    "            projection_dim = embedding_dim\n",
    "        self.register_buffer(\n",
    "            \"embedding\",\n",
    "            self._build_embedding(num_steps, embedding_dim / 2),\n",
    "            persistent=False,\n",
    "        )\n",
    "        self.projection1 = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.projection2 = nn.Linear(projection_dim, embedding_dim)        \n",
    "\n",
    "    def forward(self, diffusion_step, data, device=\"cpu\"):\n",
    "        x = self.embedding[diffusion_step]\n",
    "        x = self.projection1(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.projection2(x)\n",
    "        x = F.silu(x)\n",
    "        x = torch.zeros(data.shape).to(device) + x.unsqueeze(1).unsqueeze(1)\n",
    "        return x\n",
    "\n",
    "    def _build_embedding(self, num_steps, dim=64):\n",
    "        steps = torch.arange(num_steps).unsqueeze(1)  # (T,1)\n",
    "        frequencies = 10.0 ** (torch.arange(dim) / (dim - 1) * 4.0).unsqueeze(0)  # (1,dim)\n",
    "        table = steps * frequencies  # (T,dim)\n",
    "        table = torch.cat([torch.sin(table), torch.cos(table)], dim=1)  # (T,dim*2)\n",
    "        return table\n",
    "    \n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=10000.0):\n",
    "        super(TimeEmbedding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.learnable = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, data, device=\"cpu\"):\n",
    "        b, l, f, e = data.shape\n",
    "        pe = torch.arange(l).unsqueeze(0).unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "        pe = torch.zeros(data.shape).to(device) + pe\n",
    "        \n",
    "        div_term = 1 / torch.pow(\n",
    "            self.max_len, torch.arange(0, f, 2) / f\n",
    "        ).unsqueeze(-1).to(device)\n",
    "\n",
    "        pe[:, :, 0::2] = torch.sin(pe[:, :, 0::2] * div_term)\n",
    "        pe[:, :, 1::2] = torch.cos(pe[:, :, 1::2] * div_term)\n",
    "\n",
    "        return self.learnable(pe) \n",
    "    \n",
    "class FeatureEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=10000.0):\n",
    "        super(FeatureEmbedding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.learnable = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, data, device=\"cpu\"):\n",
    "        b, l, f, e = data.shape\n",
    "        pe = torch.arange(f).unsqueeze(0).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        pe = torch.zeros(data.shape).to(device) + pe\n",
    "\n",
    "        div_term = 1 / torch.pow(\n",
    "            self.max_len, torch.arange(0, e, 2) / e\n",
    "        ).to(device)\n",
    "\n",
    "        pe[:, :, :, 0::2] = torch.sin(pe[:, :, :, 0::2] * div_term)\n",
    "        pe[:, :, :, 1::2] = torch.cos(pe[:, :, :, 1::2] * div_term)\n",
    "\n",
    "        return self.learnable(pe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1d_with_init(in_channels, out_channels, kernel_size):\n",
    "    layer = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "    nn.init.kaiming_normal_(layer.weight)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_heads=8, num_cells=1, embed_dim=128, ff_dim=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_add = nn.Sequential(\n",
    "            nn.Linear(embed_dim*4, embed_dim*4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim*4, embed_dim)\n",
    "        )\n",
    "        \n",
    "        #self.output_projection = nn.Linear(embed_dim, embed_dim*2)\n",
    "\n",
    "        self.time_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "        self.feature_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "        self.linear_time = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_feature = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.feature_and_time_transformer = TransformerEncoder(embed_dim = embed_dim,\n",
    "                                              num_heads = num_heads,\n",
    "                                              ff_dim = ff_dim,\n",
    "                                              num_cells = num_cells,\n",
    "                                              dropout = dropout)\n",
    "        \n",
    "        self.mid_projection = Conv1d_with_init(embed_dim, 2 * embed_dim, 1)#nn.Linear(embed_dim, embed_dim*2)\n",
    "        self.output_projection = Conv1d_with_init(embed_dim, 2 * embed_dim, 1)\n",
    "        \n",
    "        \n",
    "    def forward_time(self, y, base_shape):\n",
    "        b, t, f, e = base_shape\n",
    "\n",
    "        y = y.permute(0, 2, 1, 3).reshape(b * f, t, e)\n",
    "        y = self.time_layer(y)\n",
    "        y = y.reshape(b, f, t, e).permute(0, 2, 1, 3)\n",
    "        return y\n",
    "\n",
    "    def forward_feature(self, y, base_shape):\n",
    "        b, t, f, e = base_shape\n",
    "\n",
    "        y = y.reshape(b * t, f, e)\n",
    "        y = self.feature_layer(y)\n",
    "        y = y.reshape(b, t, f, e)\n",
    "        return y        \n",
    "\n",
    "\n",
    "    def forward(self, noised_data, diffusion_emb, time_emb, feature_emb):\n",
    "        b, t, f, e = noised_data.shape\n",
    "        base_shape = noised_data.shape\n",
    "        \n",
    "        y = torch.stack((noised_data, diffusion_emb, time_emb, feature_emb), dim = -1)\n",
    "        y = y.reshape(b, t, f, -1)\n",
    "        y = self.embedding_add(y)\n",
    "        y_resid = y\n",
    "        y = self.forward_time(y, base_shape)\n",
    "        y = self.linear_time(y)\n",
    "        y = y + y_resid\n",
    "        y = (y + y_resid) / math.sqrt(2.0)\n",
    "        y = self.layer_norm(y)\n",
    "        y = self.forward_feature(y, base_shape) \n",
    "        y = self.linear_feature(y)\n",
    "        y = (y + y_resid) / math.sqrt(2.0)\n",
    "        y_resid = y\n",
    "        y = self.layer_norm(y)\n",
    "        y = self.feature_and_time_transformer(y)\n",
    "        y = self.linear_time_and_feature(y)\n",
    "        y = (y + y_resid) / math.sqrt(2.0)\n",
    "        y = self.layer_norm(y)\n",
    "        y = y.permute(0, 3, 1, 2).reshape(b, e, t*f)\n",
    "        y = self.mid_projection(y)\n",
    "        #y = y.permute(0, 3, 2, 1).reshape(b, 2*e, t*f)\n",
    "\n",
    "        gate, filter = torch.chunk(y, 2, dim=1)\n",
    "        y = torch.sigmoid(gate) * torch.tanh(filter)  # (b,e,f*t)\n",
    "        #y = y.permute(0, 2, 1)\n",
    "        y = self.output_projection(y)\n",
    "        #y = y.permute(0, 2, 1)\n",
    "\n",
    "        residual, skip = torch.chunk(y, 2, dim=1)\n",
    "        residual = residual.permute(0, 2, 1)\n",
    "        skip = skip.permute(0, 2, 1)\n",
    "        residual = residual.reshape(base_shape)\n",
    "        skip = skip.reshape(base_shape)\n",
    "        return (noised_data + residual) / math.sqrt(2.0), skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLoop(nn.Module):\n",
    "    def __init__(self, embed_dim=128, diffusion_steps = 1000, num_heads=8, num_cells=1, num_residual_layers = 4, ff_dim=512, dropout=0.1, device = \"cpu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.emb_dim = embed_dim\n",
    "\n",
    "        # self.data_embedding_linear = nn.Sequential(\n",
    "        #     nn.Linear(1, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        # ) \n",
    "        # self.x_embedding = nn.Sequential(\n",
    "        #     nn.Linear(1, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        # ) \n",
    "\n",
    "        self.data_embedding_linear = Conv1d_with_init(1, self.emb_dim, 1)\n",
    "        self.x_embedding = Conv1d_with_init(2, self.emb_dim, 1)\n",
    "        \n",
    "        self.output = Conv1d_with_init(self.emb_dim, 1, 1)\n",
    "        self.output_final = Conv1d_with_init(self.emb_dim, 1, 1)\n",
    "        \n",
    "        # self.x_add = nn.Sequential(\n",
    "        #     nn.Linear(embed_dim*num_residual_layers, embed_dim*num_residual_layers),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(embed_dim*num_residual_layers, embed_dim)\n",
    "        # )\n",
    "\n",
    "        \n",
    "        self.diffusion_embedding = DiffusionEmbedding(diffusion_steps, embed_dim)\n",
    "        self.time_embedding = TimeEmbedding(embed_dim)\n",
    "        self.feature_embedding = FeatureEmbedding(embed_dim)\n",
    "\n",
    "        self.residual_layers = nn.ModuleList(\n",
    "                ResidualBlock(\n",
    "                    num_heads=num_heads,\n",
    "                    num_cells=num_cells,\n",
    "                    embed_dim=embed_dim,\n",
    "                    ff_dim=ff_dim,\n",
    "                    dropout=dropout\n",
    "                ) for _ in range(num_residual_layers)\n",
    "        )\n",
    "    \n",
    "        # self.output = nn.Sequential(\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, 1)\n",
    "        # )\n",
    "\n",
    "        # self.output_final = nn.Sequential(\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, 1)\n",
    "        # )\n",
    "\n",
    "\n",
    "    def forward(self, noised_data, noise_mask, diffusion_t):\n",
    "\n",
    "        b, t, f, a = noised_data.shape\n",
    "        \n",
    "        noised_data_reshaped = noised_data.permute(0, 3, 1, 2).reshape(b, 1, t*f)\n",
    "        noised_data_embedded = self.data_embedding_linear(noised_data_reshaped).permute(0, 2, 1).reshape(b, t, f, self.emb_dim)\n",
    "        diffusion_embedding = self.diffusion_embedding(diffusion_t, noised_data_embedded, device = self.device)\n",
    "        time_embedding = self.time_embedding(noised_data_embedded, device = self.device)\n",
    "        feature_embedding = self.feature_embedding(noised_data_embedded, device = self.device)\n",
    "\n",
    "        x = noised_data_embedded\n",
    "        skip = []\n",
    "        for layer in self.residual_layers:\n",
    "            x, skip_connection = layer(x, diffusion_embedding, time_embedding, feature_embedding)\n",
    "            skip.append(skip_connection)\n",
    "            x = x.permute(0, 3, 1, 2).reshape(b, self.emb_dim, t*f)\n",
    "            x = self.output(x).permute(0, 2, 1).reshape(b, t, f)\n",
    "            x = torch.stack((x, noised_data.squeeze(-1)), dim = -1)\n",
    "            #x = x * noise_mask + noised_data * (1 - noise_mask)\n",
    "            x = x.permute(0, 3, 1, 2).reshape(b, 2, t*f)\n",
    "            x = self.x_embedding(x).permute(0, 2, 1).reshape(b, t, f, self.emb_dim)\n",
    "\n",
    "        x = torch.sum(torch.stack(skip, dim = -1), dim=-1)/ math.sqrt(len(self.residual_layers))\n",
    "        # x = torch.stack(skip, dim = -1).reshape(b, t, f, -1)\n",
    "        #x = self.x_add(x)\n",
    "        x = x.permute(0, 3, 1, 2).reshape(b, self.emb_dim, t*f)\n",
    "        x = self.output_final(x).permute(0, 2, 1).reshape(b, t, f, 1).squeeze(-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_beta_schedule(schedule_name, num_diffusion_timesteps):\n",
    "    \"\"\"\n",
    "    Get a pre-defined beta schedule for the given name.\n",
    "\n",
    "    The beta schedule library consists of beta schedules which remain similar\n",
    "    in the limit of num_diffusion_timesteps.\n",
    "    Beta schedules may be added, but should not be removed or changed once\n",
    "    they are committed to maintain backwards compatibility.\n",
    "    \"\"\"\n",
    "    if schedule_name == \"linear\":\n",
    "        # Linear schedule from Ho et al, extended to work for any number of\n",
    "        # diffusion steps.\n",
    "        scale = 1000 / num_diffusion_timesteps\n",
    "        beta_start = scale * 0.0001\n",
    "        beta_end = scale * 0.02\n",
    "        return torch.linspace(\n",
    "            beta_start, beta_end, num_diffusion_timesteps\n",
    "        )\n",
    "    elif schedule_name == \"cosine\":\n",
    "        return betas_for_alpha_bar(\n",
    "            num_diffusion_timesteps,\n",
    "            lambda t: math.cos((t + 0.008) / 1.008 * math.pi / 2) ** 2,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f\"unknown beta schedule: {schedule_name}\")\n",
    "\n",
    "\n",
    "def betas_for_alpha_bar(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n",
    "    \"\"\"\n",
    "    Create a beta schedule that discretizes the given alpha_t_bar function,\n",
    "    which defines the cumulative product of (1-beta) over time from t = [0,1].\n",
    "\n",
    "    :param num_diffusion_timesteps: the number of betas to produce.\n",
    "    :param alpha_bar: a lambda that takes an argument t from 0 to 1 and\n",
    "                      produces the cumulative product of (1-beta) up to that\n",
    "                      part of the diffusion process.\n",
    "    :param max_beta: the maximum beta to use; use values lower than 1 to\n",
    "                     prevent singularities.\n",
    "    \"\"\"\n",
    "    betas = []\n",
    "    for i in range(num_diffusion_timesteps):\n",
    "        t1 = i / num_diffusion_timesteps\n",
    "        t2 = (i + 1) / num_diffusion_timesteps\n",
    "        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n",
    "    return torch.tensor(betas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diffusion_imputation(nn.Module):\n",
    "    def __init__(self, emb_dim,\n",
    "                #vocab_size,\n",
    "                #pad_idx= None,\n",
    "                strategy = \"random\",\n",
    "                num_residual_layers = 4,\n",
    "                features_to_impute = None,\n",
    "                missing_prp = 0.1,\n",
    "                diffusion_steps = 1000,\n",
    "                diffusion_beta_schedule = \"cosine\",\n",
    "                num_heads = 8,\n",
    "                ff_dim = 512,\n",
    "                num_cells = 2,\n",
    "                dropout = 0.1,\n",
    "                device = \"cpu\"):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "        self.device = device\n",
    "        self.emb_dim = emb_dim\n",
    "        self.strategy = strategy\n",
    "        self.features_to_impute = features_to_impute\n",
    "        self.missing_prp = missing_prp\n",
    "        self.diffusion_steps = diffusion_steps\n",
    "\n",
    "        #set device to cuda if available\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda\"\n",
    "\n",
    "        \n",
    "        self.model_loop = ModelLoop(embed_dim = self.emb_dim,\n",
    "                                    diffusion_steps = diffusion_steps,\n",
    "                                    num_heads = num_heads,\n",
    "                                    ff_dim = ff_dim,\n",
    "                                    num_cells = num_cells,\n",
    "                                    dropout = dropout,\n",
    "                                    num_residual_layers = num_residual_layers,\n",
    "                                    device = self.device)\n",
    "        \n",
    "        self.beta = get_named_beta_schedule(diffusion_beta_schedule, \n",
    "                                            diffusion_steps)\n",
    "        \n",
    "        #self.beta = torch.linspace(0.0001, 0.5, diffusion_steps)\n",
    "\n",
    "        # self.beta = torch.linspace(\n",
    "        #         0.0001 ** 0.5, 0.5 ** 0.5, diffusion_steps\n",
    "        #     ) ** 2\n",
    "        \n",
    "        self.alpha_hat = 1 - self.beta \n",
    "        self.alpha = torch.cumprod(self.alpha_hat, dim=0)\n",
    "        self.alpha_torch = torch.tensor(self.alpha).float()\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "\n",
    "    def get_mask(self, data, strategy = \"random\"):\n",
    "        \n",
    "        b = data.shape[0]\n",
    "        t = data.shape[1]\n",
    "        f = data.shape[2]\n",
    "\n",
    "        if strategy == \"forecasting\":\n",
    "            forecasted_time = torch.randint(2, t, (b, 1, 1))\n",
    "            mask = torch.zeros_like(data)\n",
    "            for i in range(b):\n",
    "                mask[i, forecasted_time[i]:, :] = 1\n",
    "        \n",
    "        # if strategy == \"random_features\":\n",
    "        #     selected_features = torch.randint(0, f, (b, 1, 1, 1))\n",
    "        #     mask = torch.zeros_like(data)\n",
    "        #     mask[:, :, selected_features, :] = 1\n",
    "        \n",
    "        # if strategy == \"selected_features\":\n",
    "        #     mask = torch.zeros_like(data)\n",
    "        #     mask[:, :, self.features_to_impute, :] = 1\n",
    "        \n",
    "        # if strategy == \"selected_features_after_time\":\n",
    "        #     selected_time = torch.randint(1, t, (b, 1, 1))\n",
    "        #     mask = torch.zeros_like(data)\n",
    "        #     mask[:, selected_time:, self.features_to_impute, :] = 1\n",
    "        \n",
    "        if strategy == \"random\":\n",
    "            mask = torch.rand(size=(b, t, f))\n",
    "            mask = mask < self.missing_prp\n",
    "            mask = mask.float()\n",
    "        return mask\n",
    "    \n",
    "    def loss_func(self, predicted_noise, noise, noise_mask):\n",
    "\n",
    "        residual = noise - predicted_noise\n",
    "        num_obs = torch.sum(noise_mask)\n",
    "        loss = (residual**2).sum() / num_obs\n",
    "        return(loss)\n",
    "    \n",
    "    def forward(self, data):\n",
    "         \n",
    "        b, t, f = data.shape\n",
    "\n",
    "        noise_mask = self.get_mask(data, self.strategy).to(self.device)\n",
    "        noise = torch.randn((b, t, f)).to(self.device)\n",
    "        noise = (noise_mask * noise)\n",
    "\n",
    "        diffusion_t = torch.randint(0, self.diffusion_steps, (b,1)).squeeze(1)\n",
    "        alpha = self.alpha_torch[diffusion_t].unsqueeze(1).unsqueeze(2).to(self.device)\n",
    "\n",
    "        noised_data = data * noise_mask\n",
    "        noised_data = noised_data * (alpha**0.5) + noise * ((1 - alpha)**0.5)\n",
    "        conditional_data = data * (1 - noise_mask)\n",
    "        noised_data = noised_data + conditional_data\n",
    "        noised_data = noised_data.float()\n",
    "\n",
    "        predicted_noise = self.model_loop(noised_data.unsqueeze(3), noise_mask.unsqueeze(3), diffusion_t)\n",
    "        predicted_noise = predicted_noise * noise_mask\n",
    "\n",
    "        return (predicted_noise, noise, noise_mask)\n",
    "    \n",
    "    def eval(self, data, imputation_mask, verbose = True):\n",
    "        \n",
    "        conditional_data = data * (1 - imputation_mask)\n",
    "        random_noise = torch.randn_like(data)* imputation_mask*0.1\n",
    "        data_2 = (conditional_data + random_noise).unsqueeze(3)\n",
    "\n",
    "        b, ti, f, e = data_2.shape\n",
    "        imputed_samples = torch.zeros((b, ti, f)).to(self.device)\n",
    "        x = (conditional_data + random_noise)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for t in range(self.diffusion_steps - 1, -1, -1):\n",
    "\n",
    "                x = x.unsqueeze(3).float()\n",
    "                predicted_noise = self.model_loop(x, imputation_mask.unsqueeze(3), torch.tensor([t]).to(self.device))\n",
    "                predicted_noise = predicted_noise * imputation_mask\n",
    "\n",
    "                \n",
    "                coeff1 = 1 / self.alpha_hat[t] ** 0.5\n",
    "                coeff2 = (1 - self.alpha_hat[t]) / (1 - self.alpha[t]) ** 0.5\n",
    "                \n",
    "                x = x.squeeze(3)\n",
    "                x = coeff1 * (x - coeff2 * predicted_noise)\n",
    "                \n",
    "                if t > 0:\n",
    "                    noise = torch.randn_like(x)\n",
    "                    sigma = (\n",
    "                        (1.0 - self.alpha[t - 1]) / (1.0 - self.alpha[t]) * self.beta[t]\n",
    "                    ) ** 0.5\n",
    "                    x += sigma * noise\n",
    "                \n",
    "                x = data_2.squeeze(3) * (1 - imputation_mask) + x * imputation_mask\n",
    "            \n",
    "\n",
    "            imputed_samples = x.detach()\n",
    "\n",
    "        if verbose == True:\n",
    "            print(\"mae = \", torch.mean(torch.abs(data[imputation_mask !=0] - imputed_samples[imputation_mask !=0])).item())\n",
    "        # data_to_print = data[imputation_mask !=0]\n",
    "        # imputed_samples_to_print = imputed_samples[imputation_mask !=0]\n",
    "        # print(\"data:\", data_to_print)\n",
    "        # print(\"imputed:\", imputed_samples_to_print)\n",
    "        # print(\"absolute difference in the first 100 : \", torch.abs(data_to_print - imputed_samples_to_print)[:100])\n",
    "        # print(\"mae = \", torch.mean(torch.abs(data_to_print - imputed_samples_to_print)).item())\n",
    "\n",
    "        return(imputed_samples, data, imputation_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a train function that also shows a dynamic loss plot. It should also be batched. \n",
    "#the plot should be dynamic and show the loss for each epoch.\n",
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def train(model, data_loader, epochs, lr, loss_func, device = \"cuda\", verbose = True):\n",
    "\n",
    "    model = model.to(device)\n",
    "    #annealing for the learning rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    epoch_loss = 0\n",
    "    epoch_loss_list = []\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            predicted_noise, noise, noise_mask = model(batch[\"observed_data\"].to(device))\n",
    "            loss = loss_func(predicted_noise, noise, noise_mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "            if i % 2 == 0:       \n",
    "                ax.clear()\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.plot(loss_list)\n",
    "                #ax.text(len(loss_list) - 1, loss_list[-1], str(round(loss_list[-1], 3)))\n",
    "                #add a smooth line to the plot every 100 steps\n",
    "                if len(loss_list) > 100:\n",
    "                    ax.plot(np.convolve(loss_list, np.ones((100,))/100, mode='valid'))\n",
    "                    #show the last loss value on the plot\n",
    "                    ax.text(len(loss_list) - 1, np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1],\n",
    "                             str(round(np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1], 3)))\n",
    "                ax.text(0.1, 0.1, \"Epoch: \" + str(epoch) + \" Loss: \" + str(round(epoch_loss, 3)))\n",
    "                display(fig)\n",
    "                clear_output(wait=True)\n",
    "            #print(\"Epoch: \", epoch, \"Loss: \", loss.item())\n",
    "        end = time.time()    \n",
    "        if verbose:\n",
    "            #add the epoch average loss to the plot\n",
    "            #find the number of batches in the epoch\n",
    "            num_batches = len(data_loader)\n",
    "            #find the average loss for the epoch\n",
    "            epoch_loss = sum(loss_list[-num_batches:]) / num_batches\n",
    "            epoch_loss_list.append(epoch_loss)\n",
    "        \n",
    "        #annealing for the learning rate (if the loss has not decreased by at least 0.1% in the last 2 epochs, divide the learning rate by 2)\n",
    "        if epoch > 2:\n",
    "            if epoch_loss >= min(epoch_loss_list[-2:]):\n",
    "                for g in optimizer.param_groups:\n",
    "                    g['lr'] = g['lr'] / 2\n",
    "                    #print the last learning rate on the plot\n",
    "                    ax.text(0.1, 0.2, \"Learning rate: \" + str(round(g['lr'], 5)))\n",
    "            \n",
    "\n",
    "\n",
    "    return(model, loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['observed_data', 'observed_mask', 'gt_mask', 'hist_mask', 'timepoints', 'cut_length'])\n",
      "dict_keys(['observed_data', 'observed_mask', 'gt_mask', 'hist_mask', 'timepoints', 'cut_length'])\n",
      "4842\n",
      "709\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "data_loader_model = get_dataloader(20, \"cuda\")\n",
    "len(data_loader_model[0])\n",
    "for i, thing in enumerate(data_loader_model[0]):\n",
    "    print(thing.keys())\n",
    "    if i > 0:\n",
    "        break\n",
    "\n",
    "train_set = PM25_Dataset(mode=\"train\")\n",
    "valid_set = PM25_Dataset(mode=\"valid\")\n",
    "test_set  = PM25_Dataset(mode=\"test\")\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(valid_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50167/16752756.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.alpha_torch = torch.tensor(self.alpha).float()\n"
     ]
    }
   ],
   "source": [
    "diffusion_imputer = diffusion_imputation(emb_dim = 128,\n",
    "                                         strategy='forecasting',\n",
    "                                         num_residual_layers=4,\n",
    "                                         missing_prp= 0.1,\n",
    "                                         diffusion_steps= 50,\n",
    "                                         diffusion_beta_schedule= \"linear\",\n",
    "                                         num_heads=8,\n",
    "                                         ff_dim=4096,\n",
    "                                         num_cells = 2,\n",
    "                                         dropout=0.0,\n",
    "                                         device=\"cuda\")\n",
    "\n",
    "# data = torch.ones((10,10,10)).to(\"cuda\")\n",
    "# diffusion_imputer(data, strategy='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(diffusion_imputer, data_loader_model[0], epochs = 100, lr = 0.00001, loss_func = diffusion_imputer.loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the entire model for further training\n",
    "torch.save(diffusion_imputer, \"diffusion_imputer.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_imputer = torch.load(\"diffusion_imputer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3284,  0.1762,  0.7471,  0.5838,  0.3580, -0.0073, -0.5613,  0.1909,\n",
      "        -0.6022, -0.3799, -0.3427, -0.0369, -0.6512, -0.6019, -0.5917, -0.2806,\n",
      "        -0.2377, -0.7821, -0.7296, -0.7736, -0.8079, -0.8845, -0.7862, -0.9322,\n",
      "        -0.9700, -0.8410, -0.7658, -0.8167, -0.8506, -0.7670, -0.8891, -0.5611,\n",
      "        -0.7872, -0.7860, -0.7729, -0.8209, -0.9276, -0.9836, -0.9507, -0.9267,\n",
      "        -0.8631, -0.9234, -0.9484, -0.9602, -0.9687, -1.0487, -1.0196, -0.9251,\n",
      "        -0.9671, -1.0290, -1.0018, -1.0560, -0.9936, -0.9478, -0.9973, -0.9484,\n",
      "        -1.0074, -1.0363, -0.9808, -1.0276, -1.0363, -0.9895, -1.0300, -0.9320,\n",
      "        -1.0624, -1.0226, -0.9507, -1.0056, -1.0611, -1.0244, -1.0544, -0.9706,\n",
      "        -0.8846, -1.0596, -1.0017, -0.9009, -1.0511, -1.0296, -0.8955, -1.0349,\n",
      "        -1.0054, -1.1237, -0.9390, -0.9919, -1.0044, -1.0466, -1.0239, -1.0603,\n",
      "        -0.9808, -1.0765, -1.0455, -0.8965, -1.0283, -1.0493, -0.9607, -0.9204,\n",
      "        -0.9873, -0.9776, -0.9084, -0.9779, -1.0925, -0.8947, -1.0139, -1.0418,\n",
      "        -1.0226, -0.9142, -0.9723, -1.0488, -0.9325, -0.9435, -0.9314, -1.0224,\n",
      "        -0.8432, -1.0275, -0.9581, -0.9693, -1.0221, -0.9840, -0.9202, -0.9159,\n",
      "        -0.9565, -0.9724, -1.0221, -0.9198, -0.8795], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "data: tensor([ 0.3284,  0.1762,  0.7471,  0.5838,  0.3580, -0.0073, -0.0000, -0.5613,\n",
      "         0.1909, -0.6022, -0.3799, -0.3427, -0.0369, -0.0000, -0.6512, -0.6019,\n",
      "        -0.5917, -0.2806, -0.2377, -0.7821, -0.7296, -0.7736, -0.8079, -0.8845,\n",
      "        -0.7862, -0.9322, -0.9700, -0.8410, -0.7658, -0.8167, -0.8506, -0.7670,\n",
      "        -0.8891, -0.5611, -0.7872, -0.7860, -0.7729, -0.8209, -0.9276, -0.9836,\n",
      "        -0.9507, -0.9267, -0.8631, -0.9234, -0.9484, -0.9602, -0.9687, -1.0487,\n",
      "        -1.0196, -0.9251, -0.9671, -1.0290, -1.0018, -1.0560, -0.9936, -0.9478,\n",
      "        -0.9973, -0.9484, -1.0074, -1.0363, -0.9808, -1.0276, -1.0363, -0.9895,\n",
      "        -1.0300, -0.9320, -1.0624, -1.0226, -0.9507, -1.0056, -1.0611, -1.0244,\n",
      "        -1.0544, -0.9706, -0.8846, -1.0596, -1.0017, -0.9009, -1.0511, -1.0296,\n",
      "        -0.8955, -1.0349, -1.0054, -1.1237, -0.9390, -0.9919, -1.0044, -1.0466,\n",
      "        -1.0239, -1.0603, -0.9808, -1.0765, -1.0455, -0.8965, -1.0283, -1.0493,\n",
      "        -0.9607, -0.9204, -0.9873, -0.9776, -0.9084, -0.9779, -1.0925, -0.8947,\n",
      "        -1.0139, -1.0418, -1.0226, -0.9142, -0.9723, -1.0488, -0.9325, -0.9435,\n",
      "        -0.9314, -1.0224, -0.0000, -0.8432, -1.0275, -0.9581, -0.9693, -1.0221,\n",
      "        -0.9840, -0.9202, -0.9159, -0.9565, -0.9724, -1.0221, -0.9198, -0.8795],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "imputed: tensor([-0.3103, -0.2179, -0.1120,  0.9142, -0.2682, -0.6959, -0.2453,  0.1329,\n",
      "        -0.3385, -0.5567,  0.1715,  0.4820, -0.1996, -0.4527, -0.6210, -0.6382,\n",
      "        -0.7795, -0.7339, -0.6281, -0.6521, -0.9000, -0.8523, -0.8441, -0.8731,\n",
      "        -0.8660, -0.8148, -0.5174, -0.6071, -0.8783, -0.9285, -0.8191, -0.6303,\n",
      "        -0.8654, -0.8763, -1.0029, -0.8806, -0.9044, -0.7684, -0.9412, -0.9569,\n",
      "        -1.0255, -0.9151, -0.7937, -0.9641, -0.9634, -0.8891, -0.9739, -0.9864,\n",
      "        -0.9192, -0.7924, -1.0237, -0.9227, -0.8247, -1.0258, -0.9367, -0.8256,\n",
      "        -1.0380, -0.8625, -0.8012, -1.0861, -0.9455, -1.0708, -0.9743, -0.9513,\n",
      "        -0.9835, -0.5848, -0.9429, -0.9717, -0.9195, -0.6540, -1.0103, -0.9215,\n",
      "        -0.9931, -0.9766, -0.8332, -1.0542, -0.9056, -0.7911, -0.9282, -0.9742,\n",
      "        -0.9001, -1.0275, -0.9359, -1.0728, -0.8093, -0.2027, -0.8601, -0.8076,\n",
      "        -0.8546, -0.9127, -0.1408, -1.0205, -0.9105, -0.8969, -0.7830, -1.0319,\n",
      "        -0.9809, -0.7618, -0.9184, -0.8643, -0.9792, -0.9600, -1.0065, -0.8393,\n",
      "        -0.9481, -1.0204, -0.9785, -0.9393, -1.0103, -1.0047, -0.9320, -1.0048,\n",
      "        -0.8791, -0.9581, -0.8897, -0.7322, -1.0325, -0.9128, -0.9710, -1.0063,\n",
      "        -0.9912, -0.9227, -0.8839, -0.8717, -1.0367, -0.9099, -0.9071, -0.8304],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "absolute difference in the first 100 :  tensor([6.3867e-01, 3.9414e-01, 8.5908e-01, 3.3041e-01, 6.2617e-01, 6.8859e-01,\n",
      "        2.4533e-01, 6.9418e-01, 5.2942e-01, 4.5526e-02, 5.5138e-01, 8.2465e-01,\n",
      "        1.6273e-01, 4.5265e-01, 3.0160e-02, 3.6288e-02, 1.8780e-01, 4.5328e-01,\n",
      "        3.9039e-01, 1.2997e-01, 1.7042e-01, 7.8667e-02, 3.6178e-02, 1.1423e-02,\n",
      "        7.9759e-02, 1.1747e-01, 4.5266e-01, 2.3389e-01, 1.1245e-01, 1.1175e-01,\n",
      "        3.1483e-02, 1.3669e-01, 2.3700e-02, 3.1520e-01, 2.1574e-01, 9.4644e-02,\n",
      "        1.3155e-01, 5.2530e-02, 1.3596e-02, 2.6698e-02, 7.4711e-02, 1.1633e-02,\n",
      "        6.9442e-02, 4.0621e-02, 1.5020e-02, 7.1043e-02, 5.2739e-03, 6.2358e-02,\n",
      "        1.0041e-01, 1.3265e-01, 5.6652e-02, 1.0627e-01, 1.7710e-01, 3.0220e-02,\n",
      "        5.6917e-02, 1.2228e-01, 4.0635e-02, 8.5821e-02, 2.0622e-01, 4.9775e-02,\n",
      "        3.5347e-02, 4.3155e-02, 6.2056e-02, 3.8217e-02, 4.6522e-02, 3.4720e-01,\n",
      "        1.1955e-01, 5.0898e-02, 3.1241e-02, 3.5165e-01, 5.0857e-02, 1.0291e-01,\n",
      "        6.1290e-02, 5.9341e-03, 5.1405e-02, 5.3907e-03, 9.6058e-02, 1.0972e-01,\n",
      "        1.2295e-01, 5.5325e-02, 4.5526e-03, 7.4308e-03, 6.9570e-02, 5.0935e-02,\n",
      "        1.2976e-01, 7.8922e-01, 1.4426e-01, 2.3904e-01, 1.6923e-01, 1.4763e-01,\n",
      "        8.4007e-01, 5.5989e-02, 1.3502e-01, 4.4220e-04, 2.4523e-01, 1.7417e-02,\n",
      "        2.0191e-02, 1.5860e-01, 6.8835e-02, 1.1324e-01], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "mae =  0.15239854649928222\n"
     ]
    }
   ],
   "source": [
    "#let's try to impute the data\n",
    "test_data = torch.tensor(test_set[1][\"observed_data\"]).to(\"cuda\").unsqueeze(0)\n",
    "imputation_mask = diffusion_imputation.get_mask(diffusion_imputer, test_data.unsqueeze(-1), \"random\").to(\"cuda\")\n",
    "print(test_data[test_data * imputation_mask != 0])\n",
    "#imputation_mask =  torch.zeros_like(test_data.unsqueeze(3)).to(\"cuda\")\n",
    "#imputation_mask[:, 34:35, :, :] = 1\n",
    "#imputation_mask = imputation_mask.squeeze(3)\n",
    "given_points = test_data * (1-imputation_mask)\n",
    "eval_points = test_data * imputation_mask\n",
    "\n",
    "#impute the data\n",
    "imputed_samples = diffusion_imputation.eval(diffusion_imputer, test_data, imputation_mask)\n",
    "#print(imputed_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go back to non-standardized data to find actual MAEs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
