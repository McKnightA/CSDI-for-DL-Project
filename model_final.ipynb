{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 24 12:38:40 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    61W / 500W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#show nvidia card info\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import zipfile\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collecting and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alinezhad.f'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### downloading the data (should only need to do this once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(\"data_project/\", exist_ok=True)\n",
    "# url = \"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/STMVL-Release.zip\"\n",
    "# urlData = requests.get(url).content\n",
    "# filename = \"data_project/STMVL-Release.zip\"\n",
    "# with open(filename, mode=\"wb\") as f:\n",
    "#     f.write(urlData)\n",
    "# with zipfile.ZipFile(filename) as z:\n",
    "#     z.extractall(\"data_project/pm25\")\n",
    "        \n",
    "def create_normalizer_pm25():\n",
    "    df = pd.read_csv(\n",
    "        \"/home/alinezhad.f/data_project/pm25/STMVL-Release/Code/STMVL/SampleData/pm25_ground.txt\",\n",
    "        index_col=\"datetime\",\n",
    "        parse_dates=True,\n",
    "    )\n",
    "    test_month = [3, 6, 9, 12]\n",
    "    for i in test_month:\n",
    "        df = df[df.index.month != i]\n",
    "    mean = df.describe().loc[\"mean\"].values\n",
    "    std = df.describe().loc[\"std\"].values\n",
    "    path = \"./data_project/pm25/pm25_meanstd.pk\"\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump([mean, std], f)\n",
    "create_normalizer_pm25()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PM25_Dataset(Dataset):\n",
    "    def __init__(self, eval_length=36, target_dim=36, mode=\"train\", validindex=0):\n",
    "        self.eval_length = eval_length\n",
    "        self.target_dim = target_dim\n",
    "\n",
    "        path = \"./data_project/pm25/pm25_meanstd.pk\"\n",
    "        with open(path, \"rb\") as f:\n",
    "            self.train_mean, self.train_std = pickle.load(f)\n",
    "        if mode == \"train\":\n",
    "            month_list = [1, 2, 4, 5, 7, 8, 10, 11]\n",
    "            # 1st,4th,7th,10th months are excluded from histmask (since the months are used for creating missing patterns in test dataset)\n",
    "            flag_for_histmask = [0, 1, 0, 1, 0, 1, 0, 1] \n",
    "            month_list.pop(validindex)\n",
    "            flag_for_histmask.pop(validindex)\n",
    "        elif mode == \"valid\":\n",
    "            month_list = [1, 2, 4, 5, 7, 8, 10, 11]\n",
    "            month_list = month_list[validindex : validindex + 1]\n",
    "        elif mode == \"test\":\n",
    "            month_list = [3, 6, 9, 12]\n",
    "        self.month_list = month_list\n",
    "\n",
    "        # create data for batch\n",
    "        self.observed_data = []  # values (separated into each month)\n",
    "        self.observed_mask = []  # masks (separated into each month)\n",
    "        self.gt_mask = []  # ground-truth masks (separated into each month)\n",
    "        self.index_month = []  # indicate month\n",
    "        self.position_in_month = []  # indicate the start position in month (length is the same as index_month)\n",
    "        self.valid_for_histmask = []  # whether the sample is used for histmask\n",
    "        self.use_index = []  # to separate train/valid/test\n",
    "        self.cut_length = []  # excluded from evaluation targets\n",
    "\n",
    "        df = pd.read_csv(\n",
    "            \"./data_project/pm25/STMVL-Release/Code/STMVL/SampleData/pm25_ground.txt\",\n",
    "            index_col=\"datetime\",\n",
    "            parse_dates=True,\n",
    "        )\n",
    "        df_gt = pd.read_csv(\n",
    "            \"./data_project/pm25/STMVL-Release/Code/STMVL/SampleData/pm25_missing.txt\",\n",
    "            index_col=\"datetime\",\n",
    "            parse_dates=True,\n",
    "        )\n",
    "        for i in range(len(month_list)):\n",
    "            current_df = df[df.index.month == month_list[i]]\n",
    "            current_df_gt = df_gt[df_gt.index.month == month_list[i]]\n",
    "            current_length = len(current_df) - eval_length + 1\n",
    "\n",
    "            last_index = len(self.index_month)\n",
    "            self.index_month += np.array([i] * current_length).tolist()\n",
    "            self.position_in_month += np.arange(current_length).tolist()\n",
    "            if mode == \"train\":\n",
    "                self.valid_for_histmask += np.array(\n",
    "                    [flag_for_histmask[i]] * current_length\n",
    "                ).tolist()\n",
    "\n",
    "            # mask values for observed indices are 1\n",
    "            c_mask = 1 - current_df.isnull().values\n",
    "            c_gt_mask = 1 - current_df_gt.isnull().values\n",
    "            c_data = (\n",
    "                (current_df.fillna(0).values - self.train_mean) / self.train_std\n",
    "            ) * c_mask\n",
    "\n",
    "            self.observed_mask.append(c_mask)\n",
    "            self.gt_mask.append(c_gt_mask)\n",
    "            self.observed_data.append(c_data)\n",
    "\n",
    "            if mode == \"test\":\n",
    "                n_sample = len(current_df) // eval_length\n",
    "                # interval size is eval_length (missing values are imputed only once)\n",
    "                c_index = np.arange(\n",
    "                    last_index, last_index + eval_length * n_sample, eval_length\n",
    "                )\n",
    "                self.use_index += c_index.tolist()\n",
    "                self.cut_length += [0] * len(c_index)\n",
    "                if len(current_df) % eval_length != 0:  # avoid double-count for the last time-series\n",
    "                    self.use_index += [len(self.index_month) - 1]\n",
    "                    self.cut_length += [eval_length - len(current_df) % eval_length]\n",
    "\n",
    "        if mode != \"test\":\n",
    "            self.use_index = np.arange(len(self.index_month))\n",
    "            self.cut_length = [0] * len(self.use_index)\n",
    "\n",
    "        # masks for 1st,4th,7th,10th months are used for creating missing patterns in test data,\n",
    "        # so these months are excluded from histmask to avoid leakage\n",
    "        if mode == \"train\":\n",
    "            ind = -1\n",
    "            self.index_month_histmask = []\n",
    "            self.position_in_month_histmask = []\n",
    "\n",
    "            for i in range(len(self.index_month)):\n",
    "                while True:\n",
    "                    ind += 1\n",
    "                    if ind == len(self.index_month):\n",
    "                        ind = 0\n",
    "                    if self.valid_for_histmask[ind] == 1:\n",
    "                        self.index_month_histmask.append(self.index_month[ind])\n",
    "                        self.position_in_month_histmask.append(\n",
    "                            self.position_in_month[ind]\n",
    "                        )\n",
    "                        break\n",
    "        else:  # dummy (histmask is only used for training)\n",
    "            self.index_month_histmask = self.index_month\n",
    "            self.position_in_month_histmask = self.position_in_month\n",
    "\n",
    "    def __getitem__(self, org_index):\n",
    "        index = self.use_index[org_index]\n",
    "        c_month = self.index_month[index]\n",
    "        c_index = self.position_in_month[index]\n",
    "        hist_month = self.index_month_histmask[index]\n",
    "        hist_index = self.position_in_month_histmask[index]\n",
    "        s = {\n",
    "            \"observed_data\": self.observed_data[c_month][\n",
    "                c_index : c_index + self.eval_length\n",
    "            ],\n",
    "            \"observed_mask\": self.observed_mask[c_month][\n",
    "                c_index : c_index + self.eval_length\n",
    "            ],\n",
    "            \"gt_mask\": self.gt_mask[c_month][\n",
    "                c_index : c_index + self.eval_length\n",
    "            ],\n",
    "            \"hist_mask\": self.observed_mask[hist_month][\n",
    "                hist_index : hist_index + self.eval_length\n",
    "            ],\n",
    "            \"timepoints\": np.arange(self.eval_length),\n",
    "            \"cut_length\": self.cut_length[org_index],\n",
    "        }\n",
    "\n",
    "        return s\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.use_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size, device, validindex=0):\n",
    "    dataset = PM25_Dataset(mode=\"train\", validindex=validindex)\n",
    "    train_loader = DataLoader(\n",
    "        dataset, batch_size=batch_size, num_workers=3, shuffle=True\n",
    "    )\n",
    "    dataset_test = PM25_Dataset(mode=\"test\", validindex=validindex)\n",
    "    test_loader = DataLoader(\n",
    "        dataset_test, batch_size=batch_size, num_workers=1, shuffle=False\n",
    "    )\n",
    "    dataset_valid = PM25_Dataset(mode=\"valid\", validindex=validindex)\n",
    "    valid_loader = DataLoader(\n",
    "        dataset_valid, batch_size=batch_size, num_workers=1, shuffle=False\n",
    "    )\n",
    "\n",
    "    scaler = torch.from_numpy(dataset.train_std).to(device).float()\n",
    "    mean_scaler = torch.from_numpy(dataset.train_mean).to(device).float()\n",
    "\n",
    "    return train_loader, valid_loader, test_loader, scaler, mean_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moded Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesSeriesAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A module that computes multi-head attention given query, key, and value tensors for time series data of shape (b, t, f, e)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "        \n",
    "        Inputs:\n",
    "        - input_dim: Dimension of the input query, key, and value. We assume they all have\n",
    "          the same dimensions. This is basically the dimension of the embedding.\n",
    "        - num_heads: Number of attention heads\n",
    "        \"\"\"\n",
    "        super(TimesSeriesAttention, self).__init__()\n",
    "\n",
    "        assert embed_dim % num_heads == 0\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dim_per_head = embed_dim // num_heads\n",
    "\n",
    "\n",
    "        self.linear_query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_value = nn.Linear(embed_dim, (self.num_heads * self.dim_per_head * self.dim_per_head))\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.softmax = nn.Softmax2d()\n",
    "\n",
    "\n",
    "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Compute the attended feature representations.\n",
    "        \n",
    "        Inputs:\n",
    "        - query: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension, \n",
    "        and E is the embedding dimension\n",
    "        - key: Tensor of the shape BxTxFXE\n",
    "        - value: Tensor of the shape BxTxFXE\n",
    "        - mask: Tensor indicating where the attention should *not* be performed\n",
    "        \"\"\"\n",
    "        b = query.shape[0]\n",
    "        t = query.shape[1]\n",
    "        f = query.shape[2]\n",
    "        e = query.shape[3]\n",
    "        d = self.dim_per_head\n",
    "        h = self.num_heads\n",
    "\n",
    "\n",
    "        query_linear = self.linear_query(query)\n",
    "        key_linear = self.linear_key(key)\n",
    "        value_linear = self.linear_value(value)\n",
    "\n",
    "        query_reshaped = query_linear.reshape(b, t, f, self.num_heads, self.dim_per_head)\n",
    "        key_reshaped = key_linear.reshape(b, t, f, self.num_heads, self.dim_per_head)\n",
    "        value_reshaped = value_linear.reshape(b, t, f, self.num_heads, self.dim_per_head, self.dim_per_head)\n",
    "\n",
    "        query_reshaped = query_reshaped.permute(0, 3, 1, 2, 4) # BxHxTxFxD\n",
    "        key_reshaped = key_reshaped.permute(0, 3, 1, 2, 4) # BxHxTxFxD\n",
    "        value_reshaped = value_reshaped.permute(0, 3, 1, 2, 4, 5) # BxHxTxFxDxD\n",
    "\n",
    "\n",
    "        kq = torch.einsum(\"bhtfd,bhxyd->bhtfxy\", key_reshaped, query_reshaped)\n",
    "\n",
    "        dot_prod_scores = kq/math.sqrt(self.dim_per_head)\n",
    "\n",
    "\n",
    "        #softmax across last 2 features (use softmax2d)\n",
    "        dot_prod_scores = dot_prod_scores.reshape(b*h, t*f, t, f)\n",
    "        dot_prod_scores = self.softmax(dot_prod_scores)\n",
    "        dot_prod_scores = dot_prod_scores.reshape(b, h, t, f, t, f)\n",
    "\n",
    "        out = torch.einsum(\"bhtfxy,bhtfdc->bhtfd\",\n",
    "                           dot_prod_scores, value_reshaped)\n",
    "        out = out.permute(0, 2, 3, 1, 4).reshape(b, t, f, e)\n",
    "        out = self.output_linear(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single cell (unit) for the Transformer encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, dropout: float):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(TransformerEncoderCell, self).__init__()\n",
    "\n",
    "        self.time_series_attention = TimesSeriesAttention(embed_dim, num_heads)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.linear2 = nn.Linear(ff_dim, embed_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \"\"\"\n",
    "\n",
    "        attention2 = self.time_series_attention(x, x, x, mask)\n",
    "        attention = x + self.dropout1(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        attention2 = self.linear2(self.dropout(self.activation(self.linear1(attention))))\n",
    "        attention = attention + self.dropout2(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A full encoder consisting of a set of TransformerEncoderCell.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, num_cells: int, dropout: float=0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - num_cells: Number of time series attention cells in the encoder\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        \n",
    "        self.norm = None\n",
    "\n",
    "        self.encoder_modules = nn.ModuleList(TransformerEncoderCell(embed_dim, num_heads, ff_dim, dropout) for _ in range(num_cells))\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor=None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \n",
    "        Return:\n",
    "        - y: Tensor of the shape BxTxFXE\n",
    "        \"\"\"\n",
    "\n",
    "        #run encoder modules and add residual connections\n",
    "        for encoder_module in self.encoder_modules:\n",
    "            x = encoder_module(x, mask)\n",
    "\n",
    "        y = x\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch_trans(num_heads=8, num_cells=1, embed_dim=128, ff_dim=512, dropout=0.1):\n",
    "    encoder_layer = nn.TransformerEncoderLayer(\n",
    "        d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim, activation=\"gelu\", dropout=dropout\n",
    "    )\n",
    "    return nn.TransformerEncoder(encoder_layer, num_layers=num_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionEmbedding(nn.Module):\n",
    "    def __init__(self, num_steps, embedding_dim, projection_dim=None):\n",
    "        super(DiffusionEmbedding, self).__init__()\n",
    "        if projection_dim is None:\n",
    "            projection_dim = embedding_dim\n",
    "        self.register_buffer(\n",
    "            \"embedding\",\n",
    "            self._build_embedding(num_steps, embedding_dim / 2),\n",
    "            persistent=False,\n",
    "        )\n",
    "        self.projection1 = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.projection2 = nn.Linear(projection_dim, embedding_dim)        \n",
    "\n",
    "    def forward(self, diffusion_step, data, device=\"cpu\"):\n",
    "        x = self.embedding[diffusion_step]\n",
    "        x = self.projection1(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.projection2(x)\n",
    "        x = F.silu(x)\n",
    "        x = torch.zeros(data.shape).to(device) + x.unsqueeze(1).unsqueeze(1)\n",
    "        return x\n",
    "\n",
    "    def _build_embedding(self, num_steps, dim=64):\n",
    "        steps = torch.arange(num_steps).unsqueeze(1)  # (T,1)\n",
    "        frequencies = 10.0 ** (torch.arange(dim) / (dim - 1) * 4.0).unsqueeze(0)  # (1,dim)\n",
    "        table = steps * frequencies  # (T,dim)\n",
    "        table = torch.cat([torch.sin(table), torch.cos(table)], dim=1)  # (T,dim*2)\n",
    "        return table\n",
    "    \n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=10000.0):\n",
    "        super(TimeEmbedding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.learnable = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, data, device=\"cpu\"):\n",
    "        b, l, f, e = data.shape\n",
    "        pe = torch.arange(l).unsqueeze(0).unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "        pe = torch.zeros(data.shape).to(device) + pe\n",
    "        \n",
    "        div_term = 1 / torch.pow(\n",
    "            self.max_len, torch.arange(0, f, 2) / f\n",
    "        ).unsqueeze(-1).to(device)\n",
    "\n",
    "        pe[:, :, 0::2] = torch.sin(pe[:, :, 0::2] * div_term)\n",
    "        pe[:, :, 1::2] = torch.cos(pe[:, :, 1::2] * div_term)\n",
    "\n",
    "        return self.learnable(pe) \n",
    "    \n",
    "class FeatureEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=10000.0):\n",
    "        super(FeatureEmbedding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.learnable = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, data, device=\"cpu\"):\n",
    "        b, l, f, e = data.shape\n",
    "        pe = torch.arange(f).unsqueeze(0).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        pe = torch.zeros(data.shape).to(device) + pe\n",
    "\n",
    "        div_term = 1 / torch.pow(\n",
    "            self.max_len, torch.arange(0, e, 2) / e\n",
    "        ).to(device)\n",
    "\n",
    "        pe[:, :, :, 0::2] = torch.sin(pe[:, :, :, 0::2] * div_term)\n",
    "        pe[:, :, :, 1::2] = torch.cos(pe[:, :, :, 1::2] * div_term)\n",
    "\n",
    "        return self.learnable(pe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1d_with_init(in_channels, out_channels, kernel_size):\n",
    "    layer = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "    nn.init.kaiming_normal_(layer.weight)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_heads=8, num_cells=1, embed_dim=128, ff_dim=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_add = nn.Sequential(\n",
    "            nn.Linear(embed_dim*4, embed_dim*4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim*4, embed_dim)\n",
    "        )\n",
    "        \n",
    "        #self.output_projection = nn.Linear(embed_dim, embed_dim*2)\n",
    "\n",
    "        self.time_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "        self.feature_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "        self.linear_time = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_feature = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.feature_and_time_transformer = TransformerEncoder(embed_dim = embed_dim,\n",
    "                                              num_heads = num_heads,\n",
    "                                              ff_dim = ff_dim,\n",
    "                                              num_cells = num_cells,\n",
    "                                              dropout = dropout)\n",
    "        \n",
    "        self.mid_projection = Conv1d_with_init(embed_dim, 2 * embed_dim, 1)#nn.Linear(embed_dim, embed_dim*2)\n",
    "        self.output_projection = Conv1d_with_init(embed_dim, 2 * embed_dim, 1)\n",
    "        \n",
    "        \n",
    "    def forward_time(self, y, base_shape):\n",
    "        b, t, f, e = base_shape\n",
    "\n",
    "        y = y.permute(0, 2, 1, 3).reshape(b * f, t, e)\n",
    "        y = self.time_layer(y)\n",
    "        y = y.reshape(b, f, t, e).permute(0, 2, 1, 3)\n",
    "        return y\n",
    "\n",
    "    def forward_feature(self, y, base_shape):\n",
    "        b, t, f, e = base_shape\n",
    "\n",
    "        y = y.reshape(b * t, f, e)\n",
    "        y = self.feature_layer(y)\n",
    "        y = y.reshape(b, t, f, e)\n",
    "        return y        \n",
    "\n",
    "\n",
    "    def forward(self, noised_data, diffusion_emb, time_emb, feature_emb):\n",
    "        b, t, f, e = noised_data.shape\n",
    "        base_shape = noised_data.shape\n",
    "        \n",
    "        y = torch.stack((noised_data, diffusion_emb, time_emb, feature_emb), dim = -1)\n",
    "        y = y.reshape(b, t, f, -1)\n",
    "        y = self.embedding_add(y)\n",
    "        y_resid = y\n",
    "        y = self.forward_time(y, base_shape)\n",
    "        y = self.linear_time(y)\n",
    "        y = y + y_resid\n",
    "        y = (y + y_resid) / math.sqrt(2.0)\n",
    "        y = self.layer_norm(y)\n",
    "        y = self.forward_feature(y, base_shape) \n",
    "        y = self.linear_feature(y)\n",
    "        y = (y + y_resid) / math.sqrt(2.0)\n",
    "        y_resid = y\n",
    "        y = self.layer_norm(y)\n",
    "        y = self.feature_and_time_transformer(y)\n",
    "        y = self.linear_time_and_feature(y)\n",
    "        y = (y + y_resid) / math.sqrt(2.0)\n",
    "        y = self.layer_norm(y)\n",
    "        y = y.permute(0, 3, 1, 2).reshape(b, e, t*f)\n",
    "        y = self.mid_projection(y)\n",
    "        #y = y.permute(0, 3, 2, 1).reshape(b, 2*e, t*f)\n",
    "\n",
    "        gate, filter = torch.chunk(y, 2, dim=1)\n",
    "        y = torch.sigmoid(gate) * torch.tanh(filter)  # (b,e,f*t)\n",
    "        #y = y.permute(0, 2, 1)\n",
    "        y = self.output_projection(y)\n",
    "        #y = y.permute(0, 2, 1)\n",
    "\n",
    "        residual, skip = torch.chunk(y, 2, dim=1)\n",
    "        residual = residual.permute(0, 2, 1)\n",
    "        skip = skip.permute(0, 2, 1)\n",
    "        residual = residual.reshape(base_shape)\n",
    "        skip = skip.reshape(base_shape)\n",
    "        return (noised_data + residual) / math.sqrt(2.0), skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLoop(nn.Module):\n",
    "    def __init__(self, embed_dim=128, diffusion_steps = 1000, num_heads=8, num_cells=1, num_residual_layers = 4, ff_dim=512, dropout=0.1, device = \"cpu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.emb_dim = embed_dim\n",
    "\n",
    "        # self.data_embedding_linear = nn.Sequential(\n",
    "        #     nn.Linear(1, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        # ) \n",
    "        # self.x_embedding = nn.Sequential(\n",
    "        #     nn.Linear(1, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        # ) \n",
    "\n",
    "        self.data_embedding_linear = Conv1d_with_init(1, self.emb_dim, 1)\n",
    "        self.x_embedding = Conv1d_with_init(2, self.emb_dim, 1)\n",
    "        \n",
    "        self.output = Conv1d_with_init(self.emb_dim, 1, 1)\n",
    "        self.output_final = Conv1d_with_init(self.emb_dim, 1, 1)\n",
    "        \n",
    "        # self.x_add = nn.Sequential(\n",
    "        #     nn.Linear(embed_dim*num_residual_layers, embed_dim*num_residual_layers),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(embed_dim*num_residual_layers, embed_dim)\n",
    "        # )\n",
    "\n",
    "        \n",
    "        self.diffusion_embedding = DiffusionEmbedding(diffusion_steps, embed_dim)\n",
    "        self.time_embedding = TimeEmbedding(embed_dim)\n",
    "        self.feature_embedding = FeatureEmbedding(embed_dim)\n",
    "\n",
    "        self.residual_layers = nn.ModuleList(\n",
    "                ResidualBlock(\n",
    "                    num_heads=num_heads,\n",
    "                    num_cells=num_cells,\n",
    "                    embed_dim=embed_dim,\n",
    "                    ff_dim=ff_dim,\n",
    "                    dropout=dropout\n",
    "                ) for _ in range(num_residual_layers)\n",
    "        )\n",
    "    \n",
    "        # self.output = nn.Sequential(\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, 1)\n",
    "        # )\n",
    "\n",
    "        # self.output_final = nn.Sequential(\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, 1)\n",
    "        # )\n",
    "\n",
    "\n",
    "    def forward(self, noised_data, noise_mask, diffusion_t):\n",
    "\n",
    "        b, t, f, a = noised_data.shape\n",
    "        \n",
    "        noised_data_reshaped = noised_data.permute(0, 3, 1, 2).reshape(b, 1, t*f)\n",
    "        noised_data_embedded = self.data_embedding_linear(noised_data_reshaped).permute(0, 2, 1).reshape(b, t, f, self.emb_dim)\n",
    "        diffusion_embedding = self.diffusion_embedding(diffusion_t, noised_data_embedded, device = self.device)\n",
    "        time_embedding = self.time_embedding(noised_data_embedded, device = self.device)\n",
    "        feature_embedding = self.feature_embedding(noised_data_embedded, device = self.device)\n",
    "\n",
    "        x = noised_data_embedded\n",
    "        skip = []\n",
    "        for layer in self.residual_layers:\n",
    "            x, skip_connection = layer(x, diffusion_embedding, time_embedding, feature_embedding)\n",
    "            skip.append(skip_connection)\n",
    "            x = x.permute(0, 3, 1, 2).reshape(b, self.emb_dim, t*f)\n",
    "            x = self.output(x).permute(0, 2, 1).reshape(b, t, f)\n",
    "            x = torch.stack((x, noised_data.squeeze(-1)), dim = -1)\n",
    "            #x = x * noise_mask + noised_data * (1 - noise_mask)\n",
    "            x = x.permute(0, 3, 1, 2).reshape(b, 2, t*f)\n",
    "            x = self.x_embedding(x).permute(0, 2, 1).reshape(b, t, f, self.emb_dim)\n",
    "\n",
    "        x = torch.sum(torch.stack(skip, dim = -1), dim=-1)/ math.sqrt(len(self.residual_layers))\n",
    "        # x = torch.stack(skip, dim = -1).reshape(b, t, f, -1)\n",
    "        #x = self.x_add(x)\n",
    "        x = x.permute(0, 3, 1, 2).reshape(b, self.emb_dim, t*f)\n",
    "        x = self.output_final(x).permute(0, 2, 1).reshape(b, t, f, 1).squeeze(-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_beta_schedule(schedule_name, num_diffusion_timesteps):\n",
    "    \"\"\"\n",
    "    Get a pre-defined beta schedule for the given name.\n",
    "\n",
    "    The beta schedule library consists of beta schedules which remain similar\n",
    "    in the limit of num_diffusion_timesteps.\n",
    "    Beta schedules may be added, but should not be removed or changed once\n",
    "    they are committed to maintain backwards compatibility.\n",
    "    \"\"\"\n",
    "    if schedule_name == \"linear\":\n",
    "        # Linear schedule from Ho et al, extended to work for any number of\n",
    "        # diffusion steps.\n",
    "        scale = 1000 / num_diffusion_timesteps\n",
    "        beta_start = scale * 0.0001\n",
    "        beta_end = scale * 0.02\n",
    "        return torch.linspace(\n",
    "            beta_start, beta_end, num_diffusion_timesteps\n",
    "        )\n",
    "    elif schedule_name == \"cosine\":\n",
    "        return betas_for_alpha_bar(\n",
    "            num_diffusion_timesteps,\n",
    "            lambda t: math.cos((t + 0.008) / 1.008 * math.pi / 2) ** 2,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f\"unknown beta schedule: {schedule_name}\")\n",
    "\n",
    "\n",
    "def betas_for_alpha_bar(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n",
    "    \"\"\"\n",
    "    Create a beta schedule that discretizes the given alpha_t_bar function,\n",
    "    which defines the cumulative product of (1-beta) over time from t = [0,1].\n",
    "\n",
    "    :param num_diffusion_timesteps: the number of betas to produce.\n",
    "    :param alpha_bar: a lambda that takes an argument t from 0 to 1 and\n",
    "                      produces the cumulative product of (1-beta) up to that\n",
    "                      part of the diffusion process.\n",
    "    :param max_beta: the maximum beta to use; use values lower than 1 to\n",
    "                     prevent singularities.\n",
    "    \"\"\"\n",
    "    betas = []\n",
    "    for i in range(num_diffusion_timesteps):\n",
    "        t1 = i / num_diffusion_timesteps\n",
    "        t2 = (i + 1) / num_diffusion_timesteps\n",
    "        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n",
    "    return torch.tensor(betas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diffusion_imputation(nn.Module):\n",
    "    def __init__(self, emb_dim,\n",
    "                #vocab_size,\n",
    "                #pad_idx= None,\n",
    "                strategy = \"random\",\n",
    "                num_residual_layers = 4,\n",
    "                features_to_impute = None,\n",
    "                missing_prp = 0.1,\n",
    "                diffusion_steps = 1000,\n",
    "                diffusion_beta_schedule = \"cosine\",\n",
    "                num_heads = 8,\n",
    "                ff_dim = 512,\n",
    "                num_cells = 2,\n",
    "                dropout = 0.1,\n",
    "                device = \"cpu\"):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "        self.device = device\n",
    "        self.emb_dim = emb_dim\n",
    "        self.strategy = strategy\n",
    "        self.features_to_impute = features_to_impute\n",
    "        self.missing_prp = missing_prp\n",
    "        self.diffusion_steps = diffusion_steps\n",
    "\n",
    "        #set device to cuda if available\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda\"\n",
    "\n",
    "        \n",
    "        self.model_loop = ModelLoop(embed_dim = self.emb_dim,\n",
    "                                    diffusion_steps = diffusion_steps,\n",
    "                                    num_heads = num_heads,\n",
    "                                    ff_dim = ff_dim,\n",
    "                                    num_cells = num_cells,\n",
    "                                    dropout = dropout,\n",
    "                                    num_residual_layers = num_residual_layers,\n",
    "                                    device = self.device)\n",
    "        \n",
    "        self.beta = get_named_beta_schedule(diffusion_beta_schedule, \n",
    "                                            diffusion_steps)\n",
    "        \n",
    "        #self.beta = torch.linspace(0.0001, 0.5, diffusion_steps)\n",
    "\n",
    "        # self.beta = torch.linspace(\n",
    "        #         0.0001 ** 0.5, 0.5 ** 0.5, diffusion_steps\n",
    "        #     ) ** 2\n",
    "        \n",
    "        self.alpha_hat = 1 - self.beta \n",
    "        self.alpha = torch.cumprod(self.alpha_hat, dim=0)\n",
    "        self.alpha_torch = torch.tensor(self.alpha).float()\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "\n",
    "    def get_mask(self, data, strategy = \"random\"):\n",
    "        \n",
    "        b = data.shape[0]\n",
    "        t = data.shape[1]\n",
    "        f = data.shape[2]\n",
    "\n",
    "        if strategy == \"forecasting\":\n",
    "            forecasted_time = torch.randint(2, t, (b, 1, 1))\n",
    "            mask = torch.zeros_like(data)\n",
    "            for i in range(b):\n",
    "                mask[i, forecasted_time[i]:, :] = 1\n",
    "        \n",
    "        # if strategy == \"random_features\":\n",
    "        #     selected_features = torch.randint(0, f, (b, 1, 1, 1))\n",
    "        #     mask = torch.zeros_like(data)\n",
    "        #     mask[:, :, selected_features, :] = 1\n",
    "        \n",
    "        # if strategy == \"selected_features\":\n",
    "        #     mask = torch.zeros_like(data)\n",
    "        #     mask[:, :, self.features_to_impute, :] = 1\n",
    "        \n",
    "        # if strategy == \"selected_features_after_time\":\n",
    "        #     selected_time = torch.randint(1, t, (b, 1, 1))\n",
    "        #     mask = torch.zeros_like(data)\n",
    "        #     mask[:, selected_time:, self.features_to_impute, :] = 1\n",
    "        \n",
    "        if strategy == \"random\":\n",
    "            mask = torch.rand(size=(b, t, f))\n",
    "            mask = mask < self.missing_prp\n",
    "            mask = mask.float()\n",
    "        return mask\n",
    "    \n",
    "    def loss_func(self, predicted_noise, noise, noise_mask):\n",
    "\n",
    "        residual = noise - predicted_noise\n",
    "        num_obs = torch.sum(noise_mask)\n",
    "        loss = (residual**2).sum() / num_obs\n",
    "        return(loss)\n",
    "    \n",
    "    def forward(self, data):\n",
    "         \n",
    "        b, t, f = data.shape\n",
    "\n",
    "        noise_mask = self.get_mask(data, self.strategy).to(self.device)\n",
    "        noise = torch.randn((b, t, f)).to(self.device)\n",
    "        noise = (noise_mask * noise)\n",
    "\n",
    "        diffusion_t = torch.randint(0, self.diffusion_steps, (b,1)).squeeze(1)\n",
    "        alpha = self.alpha_torch[diffusion_t].unsqueeze(1).unsqueeze(2).to(self.device)\n",
    "\n",
    "        noised_data = data * noise_mask\n",
    "        noised_data = noised_data * (alpha**0.5) + noise * ((1 - alpha)**0.5)\n",
    "        conditional_data = data * (1 - noise_mask)\n",
    "        noised_data = noised_data + conditional_data\n",
    "        noised_data = noised_data.float()\n",
    "\n",
    "        predicted_noise = self.model_loop(noised_data.unsqueeze(3), noise_mask.unsqueeze(3), diffusion_t)\n",
    "        predicted_noise = predicted_noise * noise_mask\n",
    "\n",
    "        return (predicted_noise, noise, noise_mask)\n",
    "    \n",
    "    def eval(self, data, imputation_mask, verbose = True):\n",
    "        \n",
    "        conditional_data = data * (1 - imputation_mask)\n",
    "        random_noise = torch.randn_like(data)* imputation_mask\n",
    "        data_2 = (conditional_data + random_noise).unsqueeze(3)\n",
    "\n",
    "        b, ti, f, e = data_2.shape\n",
    "        imputed_samples = torch.zeros((b, ti, f)).to(self.device)\n",
    "        x = (conditional_data + random_noise)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for t in range(self.diffusion_steps - 1, -1, -1):\n",
    "\n",
    "                x = x.unsqueeze(3).float()\n",
    "                predicted_noise = self.model_loop(x, imputation_mask.unsqueeze(3), torch.tensor([t]).to(self.device))\n",
    "                predicted_noise = predicted_noise * imputation_mask\n",
    "\n",
    "                \n",
    "                coeff1 = 1 / self.alpha_hat[t] ** 0.5\n",
    "                coeff2 = (1 - self.alpha_hat[t]) / (1 - self.alpha[t]) ** 0.5\n",
    "                \n",
    "                x = x.squeeze(3)\n",
    "                x = coeff1 * (x - coeff2 * predicted_noise)\n",
    "                \n",
    "                if t > 0:\n",
    "                    noise = torch.randn_like(x)\n",
    "                    sigma = (\n",
    "                        (1.0 - self.alpha[t - 1]) / (1.0 - self.alpha[t]) * self.beta[t]\n",
    "                    ) ** 0.5\n",
    "                    x += sigma * noise\n",
    "                \n",
    "                x = data_2.squeeze(3) * (1 - imputation_mask) + x * imputation_mask\n",
    "            \n",
    "\n",
    "            imputed_samples = x.detach()\n",
    "\n",
    "        if verbose == True:\n",
    "            print(\"mae = \", torch.mean(torch.abs(data[imputation_mask !=0] - imputed_samples[imputation_mask !=0])).item())\n",
    "        # data_to_print = data[imputation_mask !=0]\n",
    "        # imputed_samples_to_print = imputed_samples[imputation_mask !=0]\n",
    "        # print(\"data:\", data_to_print)\n",
    "        # print(\"imputed:\", imputed_samples_to_print)\n",
    "        # print(\"absolute difference in the first 100 : \", torch.abs(data_to_print - imputed_samples_to_print)[:100])\n",
    "        # print(\"mae = \", torch.mean(torch.abs(data_to_print - imputed_samples_to_print)).item())\n",
    "\n",
    "        return(imputed_samples, data, imputation_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a train function that also shows a dynamic loss plot. It should also be batched. \n",
    "#the plot should be dynamic and show the loss for each epoch.\n",
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def train(model, data_loader, epochs, lr, loss_func, device = \"cuda\", verbose = True):\n",
    "\n",
    "    model = model.to(device)\n",
    "    #annealing for the learning rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    epoch_loss = 0\n",
    "    epoch_loss_list = []\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            predicted_noise, noise, noise_mask = model(batch[\"observed_data\"].to(device))\n",
    "            loss = loss_func(predicted_noise, noise, noise_mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "            if i % 2 == 0:       \n",
    "                ax.clear()\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.plot(loss_list)\n",
    "                #ax.text(len(loss_list) - 1, loss_list[-1], str(round(loss_list[-1], 3)))\n",
    "                #add a smooth line to the plot every 100 steps\n",
    "                if len(loss_list) > 100:\n",
    "                    ax.plot(np.convolve(loss_list, np.ones((100,))/100, mode='valid'))\n",
    "                    #show the last loss value on the plot\n",
    "                    ax.text(len(loss_list) - 1, np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1],\n",
    "                             str(round(np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1], 3)))\n",
    "                ax.text(0.1, 0.1, \"Epoch: \" + str(epoch) + \" Loss: \" + str(round(epoch_loss, 3)))\n",
    "                display(fig)\n",
    "                clear_output(wait=True)\n",
    "            #print(\"Epoch: \", epoch, \"Loss: \", loss.item())\n",
    "        end = time.time()    \n",
    "        if verbose:\n",
    "            #add the epoch average loss to the plot\n",
    "            #find the number of batches in the epoch\n",
    "            num_batches = len(data_loader)\n",
    "            #find the average loss for the epoch\n",
    "            epoch_loss = sum(loss_list[-num_batches:]) / num_batches\n",
    "            epoch_loss_list.append(epoch_loss)\n",
    "        \n",
    "        #annealing for the learning rate (if the loss has not decreased by at least 0.1% in the last 2 epochs, divide the learning rate by 2)\n",
    "        if epoch > 2:\n",
    "            if epoch_loss >= min(epoch_loss_list[-2:]):\n",
    "                for g in optimizer.param_groups:\n",
    "                    g['lr'] = g['lr'] / 2\n",
    "                    #print the last learning rate on the plot\n",
    "                    ax.text(0.1, 0.2, \"Learning rate: \" + str(round(g['lr'], 5)))\n",
    "            \n",
    "\n",
    "\n",
    "    return(model, loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['observed_data', 'observed_mask', 'gt_mask', 'hist_mask', 'timepoints', 'cut_length'])\n",
      "dict_keys(['observed_data', 'observed_mask', 'gt_mask', 'hist_mask', 'timepoints', 'cut_length'])\n",
      "4842\n",
      "709\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "data_loader_model = get_dataloader(20, \"cuda\")\n",
    "len(data_loader_model[0])\n",
    "for i, thing in enumerate(data_loader_model[0]):\n",
    "    print(thing.keys())\n",
    "    if i > 0:\n",
    "        break\n",
    "\n",
    "train_set = PM25_Dataset(mode=\"train\")\n",
    "valid_set = PM25_Dataset(mode=\"valid\")\n",
    "test_set  = PM25_Dataset(mode=\"test\")\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(valid_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50167/16752756.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.alpha_torch = torch.tensor(self.alpha).float()\n"
     ]
    }
   ],
   "source": [
    "diffusion_imputer = diffusion_imputation(emb_dim = 128,\n",
    "                                         strategy='forecasting',\n",
    "                                         num_residual_layers=4,\n",
    "                                         missing_prp= 0.1,\n",
    "                                         diffusion_steps= 50,\n",
    "                                         diffusion_beta_schedule= \"linear\",\n",
    "                                         num_heads=8,\n",
    "                                         ff_dim=4096,\n",
    "                                         num_cells = 2,\n",
    "                                         dropout=0.0,\n",
    "                                         device=\"cuda\")\n",
    "\n",
    "# data = torch.ones((10,10,10)).to(\"cuda\")\n",
    "# diffusion_imputer(data, strategy='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(diffusion_imputer, data_loader_model[\u001b[39m0\u001b[39;49m], epochs \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, lr \u001b[39m=\u001b[39;49m \u001b[39m0.00001\u001b[39;49m, loss_func \u001b[39m=\u001b[39;49m diffusion_imputer\u001b[39m.\u001b[39;49mloss_func)\n",
      "Cell \u001b[0;32mIn[33], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, epochs, lr, loss_func, device, verbose)\u001b[0m\n\u001b[1;32m     27\u001b[0m loss_list\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:       \n\u001b[0;32m---> 29\u001b[0m     ax\u001b[39m.\u001b[39;49mclear()\n\u001b[1;32m     30\u001b[0m     ax\u001b[39m.\u001b[39mset_ylim(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     31\u001b[0m     ax\u001b[39m.\u001b[39mplot(loss_list)\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axes/_base.py:1341\u001b[0m, in \u001b[0;36m_AxesBase.clear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1339\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcla()\n\u001b[1;32m   1340\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1341\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__clear()\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axes/_base.py:1231\u001b[0m, in \u001b[0;36m_AxesBase.__clear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     axis\u001b[39m.\u001b[39mclear()  \u001b[39m# Also resets the scale to linear.\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m \u001b[39mfor\u001b[39;00m spine \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspines\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m-> 1231\u001b[0m     spine\u001b[39m.\u001b[39;49mclear()\n\u001b[1;32m   1233\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignore_existing_data_limits \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mCallbackRegistry(\n\u001b[1;32m   1235\u001b[0m     signals\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mxlim_changed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mylim_changed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mzlim_changed\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/spines.py:224\u001b[0m, in \u001b[0;36mSpine.clear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_position \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# clear position\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis\u001b[39m.\u001b[39;49mclear()\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axis.py:890\u001b[0m, in \u001b[0;36mAxis.clear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_major_tick_kw[\u001b[39m'\u001b[39m\u001b[39mgridOn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (\n\u001b[1;32m    885\u001b[0m         mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39maxes.grid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mand\u001b[39;00m\n\u001b[1;32m    886\u001b[0m         mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39maxes.grid.which\u001b[39m\u001b[39m'\u001b[39m] \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmajor\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m    887\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_minor_tick_kw[\u001b[39m'\u001b[39m\u001b[39mgridOn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (\n\u001b[1;32m    888\u001b[0m         mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39maxes.grid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mand\u001b[39;00m\n\u001b[1;32m    889\u001b[0m         mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39maxes.grid.which\u001b[39m\u001b[39m'\u001b[39m] \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mminor\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m--> 890\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_ticks()\n\u001b[1;32m    892\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconverter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axis.py:913\u001b[0m, in \u001b[0;36mAxis.reset_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 913\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_clip_path(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes\u001b[39m.\u001b[39;49mpatch)\n\u001b[1;32m    914\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axis.py:1012\u001b[0m, in \u001b[0;36mAxis.set_clip_path\u001b[0;34m(self, clippath, transform)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_clip_path\u001b[39m(\u001b[39mself\u001b[39m, clippath, transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1011\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mset_clip_path(clippath, transform)\n\u001b[0;32m-> 1012\u001b[0m     \u001b[39mfor\u001b[39;00m child \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmajorTicks \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mminorTicks:\n\u001b[1;32m   1013\u001b[0m         child\u001b[39m.\u001b[39mset_clip_path(clippath, transform)\n\u001b[1;32m   1014\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axis.py:599\u001b[0m, in \u001b[0;36m_LazyTickList.__get__\u001b[0;34m(self, instance, cls)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_major:\n\u001b[1;32m    598\u001b[0m     instance\u001b[39m.\u001b[39mmajorTicks \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 599\u001b[0m     tick \u001b[39m=\u001b[39m instance\u001b[39m.\u001b[39;49m_get_tick(major\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    600\u001b[0m     instance\u001b[39m.\u001b[39mmajorTicks\u001b[39m.\u001b[39mappend(tick)\n\u001b[1;32m    601\u001b[0m     \u001b[39mreturn\u001b[39;00m instance\u001b[39m.\u001b[39mmajorTicks\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axis.py:1483\u001b[0m, in \u001b[0;36mAxis._get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1480\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe Axis subclass \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must define \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_tick_class or reimplement _get_tick()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1482\u001b[0m tick_kw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_major_tick_kw \u001b[39mif\u001b[39;00m major \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_minor_tick_kw\n\u001b[0;32m-> 1483\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tick_class(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes, \u001b[39m0\u001b[39;49m, major\u001b[39m=\u001b[39;49mmajor, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtick_kw)\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axis.py:489\u001b[0m, in \u001b[0;36mYTick.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\n\u001b[1;32m    486\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtick1line\u001b[39m.\u001b[39mset(\n\u001b[1;32m    487\u001b[0m     data\u001b[39m=\u001b[39m([\u001b[39m0\u001b[39m], [\u001b[39m0\u001b[39m]), transform\u001b[39m=\u001b[39max\u001b[39m.\u001b[39mget_yaxis_transform(\u001b[39m\"\u001b[39m\u001b[39mtick1\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    488\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtick2line\u001b[39m.\u001b[39mset(\n\u001b[0;32m--> 489\u001b[0m     data\u001b[39m=\u001b[39m([\u001b[39m1\u001b[39m], [\u001b[39m0\u001b[39m]), transform\u001b[39m=\u001b[39max\u001b[39m.\u001b[39;49mget_yaxis_transform(\u001b[39m\"\u001b[39;49m\u001b[39mtick2\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgridline\u001b[39m.\u001b[39mset(\n\u001b[1;32m    491\u001b[0m     data\u001b[39m=\u001b[39m([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m], [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]), transform\u001b[39m=\u001b[39max\u001b[39m.\u001b[39mget_yaxis_transform(\u001b[39m\"\u001b[39m\u001b[39mgrid\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    492\u001b[0m \u001b[39m# the y loc is 3 points below the min of y axis\u001b[39;00m\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axes/_base.py:971\u001b[0m, in \u001b[0;36m_AxesBase.get_yaxis_transform\u001b[0;34m(self, which)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspines\u001b[39m.\u001b[39mleft\u001b[39m.\u001b[39mget_spine_transform()\n\u001b[1;32m    969\u001b[0m \u001b[39melif\u001b[39;00m which \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtick2\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    970\u001b[0m     \u001b[39m# for cartesian projection, this is top spine\u001b[39;00m\n\u001b[0;32m--> 971\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspines\u001b[39m.\u001b[39;49mright\u001b[39m.\u001b[39;49mget_spine_transform()\n\u001b[1;32m    972\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    973\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39munknown value for which: \u001b[39m\u001b[39m{\u001b[39;00mwhich\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/spines.py:333\u001b[0m, in \u001b[0;36mSpine.get_spine_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_spine_transform\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    332\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the spine transform.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_position_is_set()\n\u001b[1;32m    335\u001b[0m     position \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_position\n\u001b[1;32m    336\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(position, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/spines.py:205\u001b[0m, in \u001b[0;36mSpine._ensure_position_is_set\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_position \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[39m# default position\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_position \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39moutward\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.0\u001b[39m)  \u001b[39m# in points\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_position(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_position)\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/spines.py:323\u001b[0m, in \u001b[0;36mSpine.set_position\u001b[0;34m(self, position)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_transform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_spine_transform())\n\u001b[1;32m    322\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 323\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis\u001b[39m.\u001b[39;49mreset_ticks()\n\u001b[1;32m    324\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axis.py:913\u001b[0m, in \u001b[0;36mAxis.reset_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 913\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_clip_path(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes\u001b[39m.\u001b[39;49mpatch)\n\u001b[1;32m    914\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axis.py:1012\u001b[0m, in \u001b[0;36mAxis.set_clip_path\u001b[0;34m(self, clippath, transform)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_clip_path\u001b[39m(\u001b[39mself\u001b[39m, clippath, transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1011\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mset_clip_path(clippath, transform)\n\u001b[0;32m-> 1012\u001b[0m     \u001b[39mfor\u001b[39;00m child \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmajorTicks \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mminorTicks:\n\u001b[1;32m   1013\u001b[0m         child\u001b[39m.\u001b[39mset_clip_path(clippath, transform)\n\u001b[1;32m   1014\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axis.py:604\u001b[0m, in \u001b[0;36m_LazyTickList.__get__\u001b[0;34m(self, instance, cls)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    603\u001b[0m     instance\u001b[39m.\u001b[39mminorTicks \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 604\u001b[0m     tick \u001b[39m=\u001b[39m instance\u001b[39m.\u001b[39;49m_get_tick(major\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    605\u001b[0m     instance\u001b[39m.\u001b[39mminorTicks\u001b[39m.\u001b[39mappend(tick)\n\u001b[1;32m    606\u001b[0m     \u001b[39mreturn\u001b[39;00m instance\u001b[39m.\u001b[39mminorTicks\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axis.py:1483\u001b[0m, in \u001b[0;36mAxis._get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1480\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe Axis subclass \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must define \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_tick_class or reimplement _get_tick()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1482\u001b[0m tick_kw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_major_tick_kw \u001b[39mif\u001b[39;00m major \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_minor_tick_kw\n\u001b[0;32m-> 1483\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tick_class(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes, \u001b[39m0\u001b[39;49m, major\u001b[39m=\u001b[39;49mmajor, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtick_kw)\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axis.py:483\u001b[0m, in \u001b[0;36mYTick.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 483\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    484\u001b[0m     \u001b[39m# x in axes coords, y in data coords\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/axis.py:161\u001b[0m, in \u001b[0;36mTick.__init__\u001b[0;34m(self, axes, loc, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation, grid_color, grid_linestyle, grid_linewidth, grid_alpha, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m grid_kw \u001b[39m=\u001b[39m {k[\u001b[39m5\u001b[39m:]: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtick1line \u001b[39m=\u001b[39m mlines\u001b[39m.\u001b[39mLine2D(\n\u001b[1;32m    157\u001b[0m     [], [],\n\u001b[1;32m    158\u001b[0m     color\u001b[39m=\u001b[39mcolor, linestyle\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m, zorder\u001b[39m=\u001b[39mzorder, visible\u001b[39m=\u001b[39mtick1On,\n\u001b[1;32m    159\u001b[0m     markeredgecolor\u001b[39m=\u001b[39mcolor, markersize\u001b[39m=\u001b[39msize, markeredgewidth\u001b[39m=\u001b[39mwidth,\n\u001b[1;32m    160\u001b[0m )\n\u001b[0;32m--> 161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtick2line \u001b[39m=\u001b[39m mlines\u001b[39m.\u001b[39;49mLine2D(\n\u001b[1;32m    162\u001b[0m     [], [],\n\u001b[1;32m    163\u001b[0m     color\u001b[39m=\u001b[39;49mcolor, linestyle\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnone\u001b[39;49m\u001b[39m\"\u001b[39;49m, zorder\u001b[39m=\u001b[39;49mzorder, visible\u001b[39m=\u001b[39;49mtick2On,\n\u001b[1;32m    164\u001b[0m     markeredgecolor\u001b[39m=\u001b[39;49mcolor, markersize\u001b[39m=\u001b[39;49msize, markeredgewidth\u001b[39m=\u001b[39;49mwidth,\n\u001b[1;32m    165\u001b[0m )\n\u001b[1;32m    166\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgridline \u001b[39m=\u001b[39m mlines\u001b[39m.\u001b[39mLine2D(\n\u001b[1;32m    167\u001b[0m     [], [],\n\u001b[1;32m    168\u001b[0m     color\u001b[39m=\u001b[39mgrid_color, alpha\u001b[39m=\u001b[39mgrid_alpha, visible\u001b[39m=\u001b[39mgridOn,\n\u001b[1;32m    169\u001b[0m     linestyle\u001b[39m=\u001b[39mgrid_linestyle, linewidth\u001b[39m=\u001b[39mgrid_linewidth, marker\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    170\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgrid_kw,\n\u001b[1;32m    171\u001b[0m )\n\u001b[1;32m    172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgridline\u001b[39m.\u001b[39mget_path()\u001b[39m.\u001b[39m_interpolation_steps \u001b[39m=\u001b[39m \\\n\u001b[1;32m    173\u001b[0m     GRIDLINE_INTERPOLATION_STEPS\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m name_idx:\n\u001b[1;32m    449\u001b[0m     warn_deprecated(\n\u001b[1;32m    450\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing the \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(obj_type)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpositionally is deprecated since Matplotlib \u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m; the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameter will become keyword-only \u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    453\u001b[0m         name\u001b[39m=\u001b[39mname, obj_type\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 454\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/lines.py:412\u001b[0m, in \u001b[0;36mLine2D.__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, gapcolor, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_subslice \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_x_filled \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# used in subslicing; only x is needed\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_data(xdata, ydata)\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/lines.py:650\u001b[0m, in \u001b[0;36mLine2D.set_data\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    648\u001b[0m     x, y \u001b[39m=\u001b[39m args\n\u001b[0;32m--> 650\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_xdata(x)\n\u001b[1;32m    651\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_ydata(y)\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/lines.py:1281\u001b[0m, in \u001b[0;36mLine2D.set_xdata\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_xorig \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(x)\n\u001b[1;32m   1280\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalidx \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m-> 1281\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstale \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_env/lib/python3.9/site-packages/matplotlib/artist.py:289\u001b[0m, in \u001b[0;36mArtist.stale\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[39m    Whether the artist is 'stale' and needs to be re-drawn for the output\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[39m    to match the internal state of the artist.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stale\n\u001b[0;32m--> 289\u001b[0m \u001b[39m@stale\u001b[39m\u001b[39m.\u001b[39msetter\n\u001b[1;32m    290\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstale\u001b[39m(\u001b[39mself\u001b[39m, val):\n\u001b[1;32m    291\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stale \u001b[39m=\u001b[39m val\n\u001b[1;32m    293\u001b[0m     \u001b[39m# if the artist is animated it does not take normal part in the\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     \u001b[39m# draw stack and is not expected to be drawn as part of the normal\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     \u001b[39m# draw loop (when not saving) so do not propagate this change\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(diffusion_imputer, data_loader_model[0], epochs = 100, lr = 0.00001, loss_func = diffusion_imputer.loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the entire model for further training\n",
    "torch.save(diffusion_imputer, \"diffusion_imputer_forecast.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_imputer = torch.load(\"diffusion_imputer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae =  0.09226078136392447\n"
     ]
    }
   ],
   "source": [
    "#let's try to impute the data\n",
    "test_data = torch.tensor(test_set[1][\"observed_data\"]).to(\"cuda\").unsqueeze(0)\n",
    "imputation_mask = diffusion_imputation.get_mask(diffusion_imputer, test_data, \"forecasting\").to(\"cuda\")\n",
    "#print(test_data[test_data * imputation_mask != 0])\n",
    "#imputation_mask =  torch.zeros_like(test_data.unsqueeze(3)).to(\"cuda\")\n",
    "#imputation_mask[:, 34:35, :, :] = 1\n",
    "#imputation_mask = imputation_mask.squeeze(3)\n",
    "given_points = test_data * (1-imputation_mask)\n",
    "eval_points = test_data * imputation_mask\n",
    "\n",
    "#impute the data\n",
    "imputed_samples = diffusion_imputation.eval(diffusion_imputer, test_data, imputation_mask)\n",
    "#print(imputed_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go back to non-standardized data to find actual MAEs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
